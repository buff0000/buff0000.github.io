<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[GO-HPB源码解读--work.go]]></title>
    <url>%2F2019%2F07%2F21%2FGO-HPB%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB-work-go%2F</url>
    <content type="text"><![CDATA[#GO-HPB源码解读–work.go在了解HPB持久化区块的时候，在levelDB的put方法中打印了一下调用栈，发现一共调用了5次，日志如下： 12345678910INFO [01-27|22:54:54] HPB : Successfully sealed new block number -&gt; =2 hash -&gt; =8060c5…80af4c difficulty -&gt; =1ERROR[01-27|22:54:54] HPB : mdatabase %s=&quot;goroutine 56 [running]:\nruntime/debug.Stack(0xc001ad3940, 0x41167f, 0x10)/usr/local/go/src/runtime/debug/stack.go:24 +0xa7\ngithub.com/hpb-project/go-hpb/blockchain/storage.(*LMDBDatabase).Put(0xc0001452b0, 0xc0018ab7a0, 0x2a, 0x30, 0xc0017f9c20, 0x1, 0x1, 0x0, 0x0)/home/buff/workspace/goland/src/github.com/hpb-project/go-hpb/build/workspace/src/github.com/hpb-project/go-hpb/blockchain/storage/mdatabase.go:65 +0x42\ngithub.com/hpb-project/go-hpb/blockchain.WriteTd(0x7fd9a9b5cbf0, 0xc0001452b0, 0x7eef19c735c56080, 0x558872de29feac8, 0x69fb026f2a700595, 0x4caf80c4389aafac, 0x2, 0xc001ac7de0, 0x0, 0x0)/home/buff/workspace/goland/src/github.com/hpb-project/go-hpb/build/workspace/src/github.com/hpb-project/go-hpb/blockchain/database_util.go:481 +0x212\ngithub.com/hpb-project/go-hpb/blockchain.(*HeaderChain).WriteTd(0xc00012a400, 0x7eef19c735c56080, 0x558872de29feac8, 0x69fb026f2a700595, 0x4caf80c4389aafac, 0x2, 0xc001ac7de0, 0x0, 0x0)/home/buff/workspace/goland/src/github.com/hpb-project/go-hpb/build/workspace/src/github.com/hpb-project/go-hpb/blockchain/headerchain.go:333 +0xa5\ngithub.com/hpb-project/go-hpb/blockchain.(*BlockChain).WriteBlockAndState(0xc000056e00, 0xc001a83680, 0x0, 0x0, 0x0, 0xc001cc4690, 0x0, 0x0, 0x0)/home/buff/workspace/goland/src/github.com/hpb-project/go-hpb/build/workspace/src/github.com/hpb-project/go-hpb/blockchain/blockchain.go:846 +0x381\ngithub.com/hpb-project/go-hpb/worker.(*worker).handlerSelfMinedBlock(0xc0000ec360)/home/buff/workspace/goland/src/github.com/hpb-project/go-hpb/build/workspace/src/github.com/hpb-project/go-hpb/worker/worker.go:345 +0x22e\ncreated by github.com/hpb-project/go-hpb/worker.newWorker/home/buff/workspace/goland/src/github.com/hpb-project/go-hpb/build/workspace/src/github.com/hpb-project/go-hpb/worker/worker.go:165 +0x385\n&quot;ERROR[01-27|22:54:54] HPB : mdatabase put=1 123456789ERROR[01-27|22:54:54] HPB : mdatabase %s=&quot;goroutine 56 [running]:\nruntime/debug.Stack(0x479eae, 0x41167f, 0x431301)/usr/local/go/src/runtime/debug/stack.go:24 +0xa7\ngithub.com/hpb-project/go-hpb/blockchain/storage.(*LMDBDatabase).Put(0xc0001452b0, 0xc0017f9dd0, 0xa, 0x10, 0xc001a6df60, 0x20, 0x20, 0x0, 0x0)/home/buff/workspace/goland/src/github.com/hpb-project/go-hpb/build/workspace/src/github.com/hpb-project/go-hpb/blockchain/storage/mdatabase.go:65 +0x42\ngithub.com/hpb-project/go-hpb/blockchain.WriteCanonicalHash(0x7fd9a9b5cbf0, 0xc0001452b0, 0x7eef19c735c56080, 0x558872de29feac8, 0x69fb026f2a700595, 0x4caf80c4389aafac, 0x2, 0x30, 0xc0017f9d98)/home/buff/workspace/goland/src/github.com/hpb-project/go-hpb/build/workspace/src/github.com/hpb-project/go-hpb/blockchain/database_util.go:406 +0x156\ngithub.com/hpb-project/go-hpb/blockchain.(*BlockChain).insert(0xc000056e00, 0xc001a83680)/home/buff/workspace/goland/src/github.com/hpb-project/go-hpb/build/workspace/src/github.com/hpb-project/go-hpb/blockchain/blockchain.go:501 +0x1db\ngithub.com/hpb-project/go-hpb/blockchain.(*BlockChain).WriteBlockAndState(0xc000056e00, 0xc001a83680, 0x0, 0x0, 0x0, 0xc001cc4690, 0x1, 0x0, 0x0)/home/buff/workspace/goland/src/github.com/hpb-project/go-hpb/build/workspace/src/github.com/hpb-project/go-hpb/blockchain/blockchain.go:890 +0x80e\ngithub.com/hpb-project/go-hpb/worker.(*worker).handlerSelfMinedBlock(0xc0000ec360)/home/buff/workspace/goland/src/github.com/hpb-project/go-hpb/build/workspace/src/github.com/hpb-project/go-hpb/worker/worker.go:345 +0x22e\ncreated by github.com/hpb-project/go-hpb/worker.newWorker/home/buff/workspace/goland/src/github.com/hpb-project/go-hpb/build/workspace/src/github.com/hpb-project/go-hpb/worker/worker.go:165 +0x385\n&quot;ERROR[01-27|22:54:54] HPB : mdatabase put=32 123456789ERROR[01-27|22:54:54] HPB : mdatabase %s=&quot;goroutine 56 [running]:\nruntime/debug.Stack(0x20, 0x0, 0x0)/usr/local/go/src/runtime/debug/stack.go:24 +0xa7\ngithub.com/hpb-project/go-hpb/blockchain/storage.(*LMDBDatabase).Put(0xc0001452b0, 0x1983068, 0x9, 0x9, 0xc001a6dfc0, 0x20, 0x20, 0x0, 0x0)/home/buff/workspace/goland/src/github.com/hpb-project/go-hpb/build/workspace/src/github.com/hpb-project/go-hpb/blockchain/storage/mdatabase.go:65 +0x42\ngithub.com/hpb-project/go-hpb/blockchain.WriteHeadBlockHash(0x7fd9a9b5cbf0, 0xc0001452b0, 0x7eef19c735c56080, 0x558872de29feac8, 0x69fb026f2a700595, 0x4caf80c4389aafac, 0x2, 0x0)/home/buff/workspace/goland/src/github.com/hpb-project/go-hpb/build/workspace/src/github.com/hpb-project/go-hpb/blockchain/database_util.go:422 +0x9f\ngithub.com/hpb-project/go-hpb/blockchain.(*BlockChain).insert(0xc000056e00, 0xc001a83680)/home/buff/workspace/goland/src/github.com/hpb-project/go-hpb/build/workspace/src/github.com/hpb-project/go-hpb/blockchain/blockchain.go:504 +0x2f0\ngithub.com/hpb-project/go-hpb/blockchain.(*BlockChain).WriteBlockAndState(0xc000056e00, 0xc001a83680, 0x0, 0x0, 0x0, 0xc001cc4690, 0x1, 0x0, 0x0)/home/buff/workspace/goland/src/github.com/hpb-project/go-hpb/build/workspace/src/github.com/hpb-project/go-hpb/blockchain/blockchain.go:890 +0x80e\ngithub.com/hpb-project/go-hpb/worker.(*worker).handlerSelfMinedBlock(0xc0000ec360)/home/buff/workspace/goland/src/github.com/hpb-project/go-hpb/build/workspace/src/github.com/hpb-project/go-hpb/worker/worker.go:345 +0x22e\ncreated by github.com/hpb-project/go-hpb/worker.newWorker/home/buff/workspace/goland/src/github.com/hpb-project/go-hpb/build/workspace/src/github.com/hpb-project/go-hpb/worker/worker.go:165 +0x385\n&quot;ERROR[01-27|22:54:54] HPB : mdatabase put=32 12345678910ERROR[01-27|22:54:54] HPB : mdatabase %s=&quot;goroutine 56 [running]:\nruntime/debug.Stack(0xc001ad3868, 0x563c36, 0xc001d4e060)/usr/local/go/src/runtime/debug/stack.go:24 +0xa7\ngithub.com/hpb-project/go-hpb/blockchain/storage.(*LMDBDatabase).Put(0xc0001452b0, 0x1983098, 0xa, 0xa, 0xc001d4e080, 0x20, 0x20, 0x0, 0x0)/home/buff/workspace/goland/src/github.com/hpb-project/go-hpb/build/workspace/src/github.com/hpb-project/go-hpb/blockchain/storage/mdatabase.go:65 +0x42\ngithub.com/hpb-project/go-hpb/blockchain.WriteHeadHeaderHash(0x7fd9a9b5cbf0, 0xc0001452b0, 0x7eef19c735c56080, 0x558872de29feac8, 0x69fb026f2a700595, 0x4caf80c4389aafac, 0x9ca0cf, 0xc001cd65d0)/home/buff/workspace/goland/src/github.com/hpb-project/go-hpb/build/workspace/src/github.com/hpb-project/go-hpb/blockchain/database_util.go:414 +0x9f\ngithub.com/hpb-project/go-hpb/blockchain.(*HeaderChain).SetCurrentHeader(0xc00012a400, 0xc001245400)/home/buff/workspace/goland/src/github.com/hpb-project/go-hpb/build/workspace/src/github.com/hpb-project/go-hpb/blockchain/headerchain.go:396 +0xaa\ngithub.com/hpb-project/go-hpb/blockchain.(*BlockChain).insert(0xc000056e00, 0xc001a83680)/home/buff/workspace/goland/src/github.com/hpb-project/go-hpb/build/workspace/src/github.com/hpb-project/go-hpb/blockchain/blockchain.go:511 +0x3da\ngithub.com/hpb-project/go-hpb/blockchain.(*BlockChain).WriteBlockAndState(0xc000056e00, 0xc001a83680, 0x0, 0x0, 0x0, 0xc001cc4690, 0x1, 0x0, 0x0)/home/buff/workspace/goland/src/github.com/hpb-project/go-hpb/build/workspace/src/github.com/hpb-project/go-hpb/blockchain/blockchain.go:890 +0x80e\ngithub.com/hpb-project/go-hpb/worker.(*worker).handlerSelfMinedBlock(0xc0000ec360)/home/buff/workspace/goland/src/github.com/hpb-project/go-hpb/build/workspace/src/github.com/hpb-project/go-hpb/worker/worker.go:345 +0x22e\ncreated by github.com/hpb-project/go-hpb/worker.newWorker/home/buff/workspace/goland/src/github.com/hpb-project/go-hpb/build/workspace/src/github.com/hpb-project/go-hpb/worker/worker.go:165 +0x385\n&quot;ERROR[01-27|22:54:54] HPB : mdatabase put=32 123456789ERROR[01-27|22:54:54] HPB : mdatabase %s=&quot;goroutine 56 [running]:\nruntime/debug.Stack(0xc001d4e100, 0xc001d35500, 0xc001d4e0e0)/usr/local/go/src/runtime/debug/stack.go:24 +0xa7\ngithub.com/hpb-project/go-hpb/blockchain/storage.(*LMDBDatabase).Put(0xc0001452b0, 0x1982cb0, 0x8, 0x8, 0xc001d4e120, 0x20, 0x20, 0x0, 0x0)/home/buff/workspace/goland/src/github.com/hpb-project/go-hpb/build/workspace/src/github.com/hpb-project/go-hpb/blockchain/storage/mdatabase.go:65 +0x42\ngithub.com/hpb-project/go-hpb/blockchain.WriteHeadFastBlockHash(0x7fd9a9b5cbf0, 0xc0001452b0, 0x7eef19c735c56080, 0x558872de29feac8, 0x69fb026f2a700595, 0x4caf80c4389aafac, 0x0, 0x0)/home/buff/workspace/goland/src/github.com/hpb-project/go-hpb/build/workspace/src/github.com/hpb-project/go-hpb/blockchain/database_util.go:430 +0x9f\ngithub.com/hpb-project/go-hpb/blockchain.(*BlockChain).insert(0xc000056e00, 0xc001a83680)/home/buff/workspace/goland/src/github.com/hpb-project/go-hpb/build/workspace/src/github.com/hpb-project/go-hpb/blockchain/blockchain.go:513 +0x455\ngithub.com/hpb-project/go-hpb/blockchain.(*BlockChain).WriteBlockAndState(0xc000056e00, 0xc001a83680, 0x0, 0x0, 0x0, 0xc001cc4690, 0x1, 0x0, 0x0)/home/buff/workspace/goland/src/github.com/hpb-project/go-hpb/build/workspace/src/github.com/hpb-project/go-hpb/blockchain/blockchain.go:890 +0x80e\ngithub.com/hpb-project/go-hpb/worker.(*worker).handlerSelfMinedBlock(0xc0000ec360)/home/buff/workspace/goland/src/github.com/hpb-project/go-hpb/build/workspace/src/github.com/hpb-project/go-hpb/worker/worker.go:345 +0x22e\ncreated by github.com/hpb-project/go-hpb/worker.newWorker/home/buff/workspace/goland/src/github.com/hpb-project/go-hpb/build/workspace/src/github.com/hpb-project/go-hpb/worker/worker.go:165 +0x385\n&quot;ERROR[01-27|22:54:54] HPB : mdatabase put=32 11’atom-workspace’: ‘ctrl-v’: ‘markdown-img-paste:paste’ !ls../images/SubscribeTxPreEvent.png 通过日志发现入口都是worker.go这个文件中的]]></content>
      <categories>
        <category>HPB源码解读</category>
      </categories>
      <tags>
        <tag>HPB</tag>
        <tag>区块链</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GO-HPB源码解读--PRC服务启动]]></title>
    <url>%2F2019%2F07%2F21%2FGO-HPB%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB-PRC%E6%9C%8D%E5%8A%A1%E5%90%AF%E5%8A%A8%2F</url>
    <content type="text"><![CDATA[#GO-HPB源码解读–PRC服务启动RPC服务是在节点启动的时候通过参数–rpcaddr 0.0.0.0 –rpcport 8541来指定的，启动代码是： 12hpbnode.SetNodeAPI()hpbnode.Hpbrpcmanager.Start(hpbnode.RpcAPIs) 其中SetNodeAPI是把所有的API定义以[]rpc.API的数据类型保存hpbnode.RpcAPIs，然后再传给Start方法。API的结构如下，其中public为false的话是不会发布出去了。 123456type API struct &#123; Namespace string // namespace under which the rpc methods of Service are exposed Version string // api version for DApp's Service interface&#123;&#125; // receiver instance which holds the methods Public bool // indication if the methods must be considered safe for public use&#125; 然后启动RPC服务，可以看到一共指定了三种形式的服务参数，分别是ipc、http、ws，ipc是进程间通信，在同一机器上进行的内存共享方式通信，由于不经过网卡转输数据，所以可以节省网络资源；http就是我们通过web3接口调用的通信服务，ws是WebService是一种严格定义报文格式的协议，底层也是基于http的，这里我们主要看下http服务。如果后启动的服务出现异常，则需要把所有已启动的服务停止掉，并返回。 1234567891011121314151617181920212223242526func (prm *RpcManager)Start(apis []API ) error &#123; config :=config.GetHpbConfigInstance() // for-test log.Debug("Para from config.","IpcEndpoint",config.Network.IpcEndpoint,"HttpEndpoint",config.Network.HttpEndpoint,"WsEndpoint",config.Network.WsEndpoint) prm.rpcmgr = &amp;RpcMgr&#123; ipcEndpoint: config.Network.IpcEndpoint, httpEndpoint: config.Network.HttpEndpoint, wsEndpoint: config.Network.WsEndpoint, httpCors: config.Network.HTTPCors, httpModules: config.Network.HTTPModules, httpVirtualHosts:config.Network.HTTPVirtualHosts, httpTimeouts: config.Network.HTTPTimeouts, wsOrigins: config.Network.WSOrigins, wsModules: config.Network.WSModules, wsExposeAll: config.Network.WSExposeAll, &#125; if err := prm.rpcmgr.startRPC(apis); err != nil &#123; log.Error("start rpc error","reason",err) &#125; return nil&#125; startRPC方法中按照先后顺序分别启动了四种形式的服务，多了一种InProc，这个是进程内通信（具体使用还没研究）。这里我们就看一下startHTTP的启动过程。 1234567891011121314151617181920212223242526272829// startRPC is a helper method to start all the various RPC endpoint during node// startup. It's not meant to be called at any time afterwards as it makes certain// assumptions about the state of the node.func (n *RpcMgr) startRPC(apis []API) error &#123; // Gather all the possible APIs to surface n.rpcAPIs = apis // Start the various API endpoints, terminating all in case of errors if err := n.startInProc(apis); err != nil &#123; return err &#125; if err := n.startIPC(apis); err != nil &#123; n.stopInProc() return err &#125; if err := n.startHTTP(n.httpEndpoint, apis, n.httpModules, n.httpCors, n.httpVirtualHosts, n.httpTimeouts); err != nil &#123; n.stopIPC() n.stopInProc() return err &#125; if err := n.startWS(n.wsEndpoint, apis, n.wsModules, n.wsOrigins, n.wsExposeAll); err != nil &#123; n.stopHTTP() n.stopIPC() n.stopInProc() return err &#125; // All API endpoints started successfully return nil&#125; 在StartHTTPEndpoint方法中，modules就是在启动的时候通过参数–rpcapi hpb,web3,admin,txpool,debug,personal,net指定的，表示启动的模块，RPC在启动的时候会检查程序所定的API是否在modules中，只有在的才会启动，另外还有个条件就是api是Public的。NewHTTPServer方法启动服务，其中cors参数是跨域域名 12345678910111213141516171819202122232425262728// StartHTTPEndpoint starts the HTTP RPC endpoint, configured with cors/vhosts/modulesfunc StartHTTPEndpoint(endpoint string, apis []API, modules []string, cors []string, vhosts []string, timeouts config.HTTPTimeouts) (net.Listener, *Server, error) &#123; // Generate the whitelist based on the allowed modules whitelist := make(map[string]bool) for _, module := range modules &#123; whitelist[module] = true &#125; // Register all the APIs exposed by the services handler := NewServer() for _, api := range apis &#123; if whitelist[api.Namespace] || (len(whitelist) == 0 &amp;&amp; api.Public) &#123; if err := handler.RegisterName(api.Namespace, api.Service); err != nil &#123; return nil, nil, err &#125; log.Debug("HTTP registered", "namespace", api.Namespace) &#125; &#125; // All APIs registered, start the HTTP listener var ( listener net.Listener err error ) if listener, err = net.Listen("tcp", endpoint); err != nil &#123; return nil, nil, err &#125; go NewHTTPServer(cors, vhosts, timeouts, handler).Serve(listener) return listener, handler, err&#125;]]></content>
      <categories>
        <category>HPB源码解读</category>
      </categories>
      <tags>
        <tag>HPB</tag>
        <tag>区块链</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GO-HPB源码解读--P2P启动]]></title>
    <url>%2F2019%2F07%2F21%2FGO-HPB%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB-P2P%E5%90%AF%E5%8A%A8%2F</url>
    <content type="text"><![CDATA[#GO-HPB源码解读–P2P启动P2P启动是在节点启动的时候进行的，启动代码是hpbnode.Hpbpeermanager.Start(hpbnode.hpberbase) 123456789101112131415161718192021222324252627282930func (hpbnode *Node) Start(conf *config.HpbConfig) error &#123; if config.GetHpbConfigInstance().Node.TestCodeParam == 1 &#123; consensus.SetTestParam() &#125; hpbnode.startBloomHandlers() err := hpbnode.WorkerInit(conf) if err != nil &#123; log.Error("Worker init failed", ":", err) return err &#125; if hpbnode.Hpbsyncctr == nil &#123; log.Error("syncctrl is nil") return errors.New("synctrl is nil") &#125; hpbnode.Hpbsyncctr.Start() retval := hpbnode.Hpbpeermanager.Start(hpbnode.hpberbase) if retval != nil &#123; log.Error("Start hpbpeermanager error") return errors.New(`start peermanager error ".ipc"`) &#125; hpbnode.SetNodeAPI() hpbnode.Hpbrpcmanager.Start(hpbnode.RpcAPIs) hpbnode.Hpbtxpool.Start() return nil&#125; 在Start方法中 配置网络启动参数信息 注册NodeMsg消息处理函数 设置本地节点的类型分别是候选节点、引导节点、同步节点 启动服务(prm.server.Start()) 检查本地节点是不是在BootstrapNodes列表中，也就是程序首次安装的时候连接的节点。 启动iperf带宽测试服务，该端口是peer的端口加100。iperf的启动是通过调用shell命令来启来的，iperf应用包就在ghpb-bin安装目录下。命令是：bin/bash iperf3 -s -p port 如果是挖矿节点的话，异步启动iperf带宽测试客户端 如果boot节点的话，需要解析一下binding.json文件，这个用来指定启动时可以连接的peer地址1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677func (prm *PeerManager) Start(coinbase common.Address) error &#123; config := config.GetHpbConfigInstance() prm.server.Config = Config&#123; NAT: config.Network.NAT, Name: config.Network.Name, TestMode: config.Node.TestMode == 1, PrivateKey: config.Node.PrivateKey, NetworkId: config.Node.NetworkId, ListenAddr: config.Network.ListenAddr, NetRestrict: config.Network.NetRestrict, NodeDatabase: config.Network.NodeDatabase, BootstrapNodes: config.Network.BootstrapNodes, EnableMsgEvents: config.Network.EnableMsgEvents, Protocols: prm.hpbpro.Protocols(), &#125; prm.server.Config.CoinBase = coinbase log.Info("Set coinbase address by start", "address", coinbase.String()) if coinbase.String() == "0x0000000000000000000000000000000000000000" &#123; panic("coinbase address is nil.") &#125; prm.hpbpro.networkId = prm.server.NetworkId prm.hpbpro.regMsgProcess(ReqNodesMsg, HandleReqNodesMsg) prm.hpbpro.regMsgProcess(ResNodesMsg, HandleResNodesMsg) prm.hpbpro.regMsgProcess(ReqBWTestMsg, prm.HandleReqBWTestMsg) prm.hpbpro.regMsgProcess(ResBWTestMsg, prm.HandleResBWTestMsg) copy(prm.server.Protocols, prm.hpbpro.Protocols()) localType := discover.PreNode if config.Network.RoleType == "bootnode" &#123; localType = discover.BootNode &#125; else if config.Network.RoleType == "synnode" &#123; localType = discover.SynNode &#125; prm.SetLocalType(localType) log.Info("Set Init Local Type by p2p", "type", localType.ToString()) if err := prm.server.Start(); err != nil &#123; log.Error("Hpb protocol", "error", err) return err &#125; //////////////////////////////////////////////////////////////////////////////////////// //for bootnode check self := prm.server.Self() for _, n := range config.Network.BootstrapNodes &#123; if self.ID == n.ID &amp;&amp; prm.server.localType != discover.BootNode &#123; panic("Need BOOTNODE flag.") &#125; &#125; ///////////////////////////////////////////////////////////////////////////////////////// add, _ := net.ResolveUDPAddr("udp", prm.server.ListenAddr) prm.iport = add.Port + 100 log.Debug("Iperf server start", "port", prm.iport) prm.startServerBW(strconv.Itoa(prm.iport)) if prm.server.localType != discover.BootNode &amp;&amp; prm.server.localType != discover.SynNode &#123; go prm.startClientBW() &#125; ///////////////////////////////////////////////////////////////////////////////////////// //for bing info if prm.server.localType == discover.BootNode &#123; filename := filepath.Join(config.Node.DataDir, bindInfoFileName) log.Debug("bootnode load bindings", "filename", filename) prm.parseBindInfo(filename) &#125; return nil&#125; prm.server.Start()方法是用来启动P2P服务的。 判断服务是否启动 创建RLPX，实现网络数据传输加密，这里有个翻译文档可以详细了解下 初始化一些Server的属性 启动UDP服务，主要是用来发现节点的 设置boot节点地址，添加到table中 指定自己的握手协议 srv.startListening()启动TCP服务 创建newDialState对象，并异步运行123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172// Start starts running the server.// Servers can not be re-used after stopping.func (srv *Server) Start() (err error) &#123; srv.lock.Lock() defer srv.lock.Unlock() if srv.running &#123; return errors.New("server already running") &#125; srv.running = true log.Info("Starting P2P networking") rand.Seed(time.Now().Unix()) // static fields if srv.PrivateKey == nil &#123; return fmt.Errorf("Server.PrivateKey must be set to a non-nil key") &#125; if srv.newTransport == nil &#123; srv.newTransport = newRLPX &#125; srv.quit = make(chan struct&#123;&#125;) srv.addpeer = make(chan *conn) srv.delpeer = make(chan peerDrop) srv.posthandshake = make(chan *conn) srv.addstatic = make(chan *discover.Node) srv.removestatic = make(chan *discover.Node) srv.peerOp = make(chan peerOpFunc) srv.peerOpDone = make(chan struct&#123;&#125;) srv.peerEvent = event.NewEvent() srv.delHist = new(dialHistory) srv.dialer = TCPDialer&#123;&amp;net.Dialer&#123;Timeout: defaultDialTimeout&#125;&#125; // node table ntab, ourend, err := discover.ListenUDP(srv.PrivateKey, srv.localType, srv.ListenAddr, srv.NAT, srv.NodeDatabase, srv.NetRestrict) if err != nil &#123; return err &#125; if err := ntab.SetFallbackNodes(srv.BootstrapNodes); err != nil &#123; return err &#125; srv.ntab = ntab // handshake srv.ourHandshake = &amp;protoHandshake&#123;Version: MsgVersion, Name: srv.Name, ID: discover.PubkeyID(&amp;srv.PrivateKey.PublicKey), End:ourend&#125; for _, p := range srv.Protocols &#123; srv.ourHandshake.Caps = append(srv.ourHandshake.Caps, p.cap()) &#125; srv.ourHandshake.CoinBase = srv.CoinBase if srv.ListenAddr == "" &#123; log.Error("P2P server start, listen address is nil") &#125; if err := srv.startListening(); err != nil &#123; return err &#125; ////////////////////////////////////////////////////////////////////////////////////////////// if srv.TestMode &#123; srv.parseSynnode() &#125; ////////////////////////////////////////////////////////////////////////////////////////////// log.Info("Server start with type.","NodeType",srv.localType.ToString()) dialer := newDialState(srv.StaticNodes, srv.BootstrapNodes, srv.ntab, srv.NetRestrict) srv.loopWG.Add(1) go srv.run(dialer) srv.running = true return nil&#125; 在startListening方法中，首先开始监听端口，然后进行接收连接处理，主要看下srv.listenLoop()方法，另外还进行了NAT转换。 maxAcceptConns=100参数表示的是最大可握手连接数，并不是实际连接数，比如节点可以同时和200个peer建立连接，但在同一时间点，只能和100peer进行握手。所以看到代码创建了100个slot“信号”，接着for不断的取slot“信号”，相当于消耗了一个，但是在创建完连接之的又创建了一个slot“信号” for循环中主要是获取了连接，然后判断一下是不是受限地址（黑名单），如果不是就异步进行SetupConn1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980func (srv *Server) startListening() error &#123; // Launch the TCP listener. listener, err := net.Listen("tcp", srv.ListenAddr) if err != nil &#123; return err &#125; laddr := listener.Addr().(*net.TCPAddr) srv.ListenAddr = laddr.String() srv.listener = listener srv.loopWG.Add(1) go srv.listenLoop() // Map the TCP listening port if NAT is configured. if !laddr.IP.IsLoopback() &amp;&amp; srv.NAT != nil &#123; srv.loopWG.Add(1) go func() &#123; nat.Map(srv.NAT, srv.quit, "tcp", laddr.Port, laddr.Port, "hpb p2p") srv.loopWG.Done() &#125;() &#125; return nil&#125;// listenLoop runs in its own goroutine and accepts// inbound connections.func (srv *Server) listenLoop() &#123; defer srv.loopWG.Done() //log.Info("RLPx listener up", "self", srv.makeSelf(srv.listener)) // This channel acts as a semaphore limiting // active inbound connections that are lingering pre-handshake. // If all slots are taken, no further connections are accepted. tokens := maxAcceptConns slots := make(chan struct&#123;&#125;, tokens) for i := 0; i &lt; tokens; i++ &#123; slots &lt;- struct&#123;&#125;&#123;&#125; &#125; for &#123; // Wait for a handshake slot before accepting. &lt;-slots var ( fd net.Conn err error ) for &#123; fd, err = srv.listener.Accept() if tempErr, ok := err.(tempError); ok &amp;&amp; tempErr.Temporary() &#123; log.Debug("Temporary read error", "err", err) continue &#125; else if err != nil &#123; log.Debug("Read error", "err", err) return &#125; break &#125; // Reject connections that do not match NetRestrict. if srv.NetRestrict != nil &#123; if tcp, ok := fd.RemoteAddr().(*net.TCPAddr); ok &amp;&amp; !srv.NetRestrict.Contains(tcp.IP) &#123; log.Debug("Rejected conn (not whitelisted in NetRestrict)", "addr", fd.RemoteAddr()) fd.Close() slots &lt;- struct&#123;&#125;&#123;&#125; continue &#125; &#125; fd = newMeteredConn(fd, true) log.Info("Accepted connection", "addr", fd.RemoteAddr()) // Spawn the handler. It will give the slot back when the connection // has been established. go func() &#123; srv.SetupConn(fd, inboundConn, nil) slots &lt;- struct&#123;&#125;&#123;&#125; &#125;() &#125;&#125; 在SetupConn中 判断服务是不是启动 这行代码中c := &amp;conn{fd: fd, transport: srv.newTransport(fd), flags: flags, cont: make(chan error)}可以看到srv.newTransport这个参数的传入，其实就是上边的RLPX。 c.doEncHandshake进行ENC握手，具体实现都是RLPX做的 c.doProtoHandshake进行协议握手，具体实现都是RLPX做的 之的的有关BOE的逻辑没太看明白 最后srv.checkpoint是将连接对象conn发送给通道stage123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131// SetupConn runs the handshakes and attempts to add the connection// as a peer. It returns when the connection has been added as a peer// or the handshakes have failed.func (srv *Server) SetupConn(fd net.Conn, flags connFlag, dialDest *discover.Node) &#123; // Prevent leftover pending conns from entering the handshake. srv.lock.Lock() running := srv.running srv.lock.Unlock() c := &amp;conn&#123;fd: fd, transport: srv.newTransport(fd), flags: flags, cont: make(chan error)&#125; if !running &#123; c.close(errServerStopped) return &#125; srv.setupLock.Lock() defer srv.setupLock.Unlock() // Run the encryption handshake. var err error var ourRand, theirRand []byte if c.id, ourRand, theirRand, err = c.doEncHandshake(srv.PrivateKey, dialDest); err != nil &#123; log.Debug("Failed RLPx handshake", "addr", c.fd.RemoteAddr(), "conn", c.flags, "reason", err) c.close(err) return &#125; clog := log.New("id", c.id, "addr", c.fd.RemoteAddr(), "conn", c.flags) // For dialed connections, check that the remote public key matches. if dialDest != nil &amp;&amp; c.id != dialDest.ID &#123; c.close(DiscUnexpectedIdentity) clog.Error("Dialed identity mismatch", "want", c, dialDest.ID) return &#125; if err := srv.checkpoint(c, srv.posthandshake); err != nil &#123; clog.Trace("Rejected peer before protocol handshake", "err", err) c.close(err) return &#125; log.Debug("Do enc handshake OK.","id",c.id) ///////////////////////////////////////////////////////////////////////////////// // Run the protocol handshake c.our = *srv.ourHandshake c.our.RandNonce = ourRand if c.our.Sign, err = boe.BoeGetInstance().HW_Auth_Sign(theirRand); err!=nil&#123; clog.Debug("Do hardware sign error.","err",err) //todo close and return &#125; clog.Debug("Hardware has signed remote rand.","rand",theirRand,"sign",c.our.Sign) their, err := c.doProtoHandshake(&amp;c.our) if err != nil &#123; clog.Debug("Failed proto handshake", "err", err) c.close(err) return &#125; if their.ID != c.id &#123; clog.Error("Wrong devp2p handshake identity", "err", their.ID) c.close(DiscUnexpectedIdentity) return &#125; c.their = *their clog.Debug("Do protocol handshake OK.","id",c.id) clog.Trace("Do protocol handshake.","our",c.our,"their",c.their) ///////////////////////////////////////////////////////////////////////////////// isRemoteBoot := false hdtab := srv.getHdtab() for _, n := range srv.BootstrapNodes &#123; if c.id == n.ID &#123; clog.Info("Remote node is boot.","id",c.id) c.isboe = true isRemoteBoot = true &#125; &#125; if !c.isboe &#123; remoteCoinbase := strings.ToLower(c.their.CoinBase.String()) clog.Trace("Remote coinbase","address",remoteCoinbase) if len(hdtab) == 0 &#123; clog.Debug("Do not ready for connected.","id",c.id.TerminalString()) c.close(DiscHwSignError) return &#125; for _,hw := range hdtab &#123; if hw.Adr == remoteCoinbase &#123; clog.Debug("Input to boe paras","rand",c.our.RandNonce,"hid",hw.Hid,"cid",hw.Cid,"sign",c.their.Sign) c.isboe = boe.BoeGetInstance().HW_Auth_Verify(c.our.RandNonce,hw.Hid,hw.Cid,c.their.Sign) clog.Info("Boe verify the remote.","id",c.id.TerminalString(),"result",c.isboe) &#125; &#125; &#125; clog.Info("Verify the remote hardware.","id",c.id.TerminalString(),"result",c.isboe) if !srv.TestMode &amp;&amp; srv.localType == discover.SynNode &amp;&amp; c.isboe == false &#123; clog.Debug("SynNode peer SynNode, dorp peer.") c.close(DiscHwSignError) return &#125; if isRemoteBoot || srv.localType == discover.BootNode &#123; ourHdtable := &amp;hardwareTable&#123;Version:0x00,Hdtab:hdtab&#125; theirHdtable, err := c.doHardwareTable(ourHdtable) if err != nil &#123; clog.Debug("Failed hardware table handshake", "reason", err) c.close(err) return &#125; clog.Trace("Exchange hardware table.","our",ourHdtable, "their",theirHdtable) if isRemoteBoot&#123; srv.updateHdtab(theirHdtable.Hdtab,true) clog.Trace("Update hardware table from boot.","srv hdtab", srv.getHdtab() ) &#125; &#125; ///////////////////////////////////////////////////////////////////////////////// if err := srv.checkpoint(c, srv.addpeer); err != nil &#123; clog.Warn("Rejected peer", "err", err, "dialDest",dialDest) c.close(err) return &#125;&#125; 当接收到的连接发送到stage通道后，那么通道的处理是在srv.run进行处理的，也就是prm.server.Start()最后一步代码srv.run。其中分支case c := &lt;-srv.addpeer:中的go srv.runPeer(p)方法开启了对连接的心跳检测，同时进行了节点广播。上边分析的都是本节点作为服务监听者被动接收建立的连接，而节点主动连接其他节点的动作是在也是在srv.run(dialer)中进行的，其参数dialer包含有对方节点连接信息，包括boot节点地址。 首先创建了三个任务方法delTask、startTasks和scheduleTasks，同时创建了两个数组，一个是保存正在运行的task，一个缓存将被运行的task。删除的时候只能从正在运行的数组中删除，运行的时候最大运行个数不能超过maxActiveDialTasks=16个，其中scheduleTasks用来创建待运行的task，主动连接的节点分boot节点、静态节点和动态节点，其中静态节点就是手动配置的，动态节点是程序KAD算法计算得到的。 在startTasks方法中通过t.Do(srv)进行节点的连接操作，最终还是会执行srv.SetupConn方法，也就是上边分析的建立连接的过程。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166func (srv *Server) run(dialstate dialer) &#123; defer srv.loopWG.Done() var ( peers = make(map[discover.NodeID]*PeerBase) taskdone = make(chan task, maxActiveDialTasks) runningTasks []task queuedTasks []task // tasks that can't run yet ) // removes t from runningTasks delTask := func(t task) &#123; for i := range runningTasks &#123; if runningTasks[i] == t &#123; runningTasks = append(runningTasks[:i], runningTasks[i+1:]...) break &#125; &#125; &#125; // starts until max number of active tasks is satisfied startTasks := func(ts []task) (rest []task) &#123; i := 0 for ; len(runningTasks) &lt; maxActiveDialTasks &amp;&amp; i &lt; len(ts); i++ &#123; t := ts[i] go func() &#123; //log.Error("###### start task.","task",t) //time.Sleep(time.Second*time.Duration(rand.Intn(3))) t.Do(srv) //time.Sleep(time.Second*time.Duration(rand.Intn(3))) //log.Error("###### task done.") taskdone &lt;- t &#125;() runningTasks = append(runningTasks, t) &#125; return ts[i:] &#125; scheduleTasks := func() &#123; // Start from queue first. queuedTasks = append(queuedTasks[:0], startTasks(queuedTasks)...) // Query dialer for new tasks and start as many as possible now. if len(runningTasks) &lt; maxActiveDialTasks &#123; var nt []task if srv.localType == discover.BootNode &#123; nt = append(nt, &amp;waitExpireTask&#123;time.Second&#125;) &#125;else&#123; nt = dialstate.newTasks(len(runningTasks)+len(queuedTasks), peers, time.Now()) &#125; queuedTasks = append(queuedTasks, startTasks(nt)...) &#125; &#125;running: for &#123; scheduleTasks() srv.delHist.expire(time.Now()) log.Trace("###### Server running: expire node from history.","DelHist",srv.delHist.Len()) select &#123; case &lt;-srv.quit: // The server was stopped. Run the cleanup logic. break running case n := &lt;-srv.addstatic: // This channel is used by AddPeer to add to the // ephemeral static peer list. Add it to the dialer, // it will keep the node connected. log.Debug("Adding static node", "node", n) dialstate.addStatic(n) case n := &lt;-srv.removestatic: // This channel is used by RemovePeer to send a // disconnect request to a peer and begin the // stop keeping the node connected log.Debug("Removing static node", "node", n) dialstate.removeStatic(n) if p, ok := peers[n.ID]; ok &#123; p.Disconnect(DiscRequested) &#125; case op := &lt;-srv.peerOp: // This channel is used by Peers and PeerCount. op(peers) srv.peerOpDone &lt;- struct&#123;&#125;&#123;&#125; case t := &lt;-taskdone: // A task got done. Tell dialstate about it so it // can update its state and remove it from the active // tasks list. //log.Error("###### Dial task done", "task", t) dialstate.taskDone(t, time.Now()) delTask(t) case c := &lt;-srv.posthandshake: // A connection has passed the encryption handshake so // the remote identity is known (but hasn't been verified yet). // TODO: track in-progress inbound node IDs (pre-Peer) to avoid dialing them. select &#123; case c.cont &lt;- srv.encHandshakeChecks(peers, c): case &lt;-srv.quit: break running &#125; case c := &lt;-srv.addpeer: // At this point the connection is past the protocol handshake. // Its capabilities are known and the remote identity is verified. err := srv.protoHandshakeChecks(peers, c) if err == nil &#123; // The handshakes are done and it passed all checks. p := newPeerBase(c, srv.Protocols[0], srv.ntab) // If message events are enabled, pass the peerFeed // to the peer if srv.EnableMsgEvents &#123; p.events = srv.peerEvent &#125; p.beatStart = time.Now() srv.setPeerInitType(p, c.isboe) ////////////////////////////////////////////////////////// log.Debug("Server add peer base to run.", "id", c.id, "raddr", c.fd.RemoteAddr()) peers[c.id] = p go srv.runPeer(p) &#125; // The dialer logic relies on the assumption that // dial tasks complete after the peer has been added or // discarded. Unblock the task last. select &#123; case c.cont &lt;- err: case &lt;-srv.quit: break running &#125; case pd := &lt;-srv.delpeer: // A peer disconnected. nid := pd.ID() d := common.PrettyDuration(mclock.Now() - pd.created) pd.log.Info("Removing p2p peer", "duration", d) pd.log.Debug("Removing p2p peer", "duration", d, "req", pd.requested, "err", pd.err) delete(peers, nid) shortid := fmt.Sprintf("%x", nid[0:8]) if err := PeerMgrInst().unregister(shortid); err != nil &#123; log.Debug("Peer removal failed", "peer", shortid, "err", err) &#125; srv.ntab.RemoveNode(nid) expire := time.Second*time.Duration(10+rand.Intn(20)) srv.delHist.add(nid, time.Now().Add(expire)) log.Debug("Server running: add node to history.","expire",expire) &#125; &#125; log.Debug("P2P networking is spinning down") // Terminate discovery. If there is a running lookup it will terminate soon. if srv.ntab != nil &#123; srv.ntab.Close() &#125; // Disconnect all peers. for _, p := range peers &#123; p.Disconnect(DiscQuitting) &#125; // Wait for peers to shut down. Pending connections and tasks are // not handled here and will terminate soon-ish because srv.quit // is closed. for len(peers) &gt; 0 &#123; p := &lt;-srv.delpeer p.log.Trace("&lt;-delpeer (spindown)", "remainingTasks", len(runningTasks)) delete(peers, p.ID()) &#125;&#125; 这块代码挺复杂的，各种go routine和chan的使用。😂😂😂😂😂😂😂😂]]></content>
      <categories>
        <category>HPB源码解读</category>
      </categories>
      <tags>
        <tag>HPB</tag>
        <tag>区块链</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GO-HPB源码解读--交易入池（二）]]></title>
    <url>%2F2019%2F07%2F21%2FGO-HPB%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB-%E4%BA%A4%E6%98%93%E5%85%A5%E6%B1%A0%EF%BC%88%E4%BA%8C%EF%BC%89%2F</url>
    <content type="text"><![CDATA[#GO-HPB源码解读–交易入池（二）上一节看到交易通过pool.promoteTx(addr, hash, tx)方法进行了传递，在该方法的最后一步通过pool.txFeed.Send(bc.TxPreEvent{tx})，将交易封装成bc.TxPreEvent发送了出去。而这个Feed实现了订阅发布模式，Send方法是发布消息，SubscribeTxPreEvent是订阅消息，订单的时候只需要把订单者的chan发进来就可以了。 （Feed通过反射包reflect中的selectcase、trySend和tryReceive方法进行的，操作包装在Feed文件中，golang的源码包中有all_test.go测试文件可以详细看下）订阅这个消费的一共有三个地方，分中在api_backend.go、synctrl.go、worker.go中。这里主要看一下广播和evn执行。 api_backend.go中只是订单并没处理 synctrl.go中进行消费的广播 worker.go中进行了evn执行 123func (pool *TxPool) SubscribeTxPreEvent(ch chan&lt;-bc.TxPreEvent) sub.Subscription &#123; return pool.scope.Track(pool.txFeed.Subscribe(ch))&#125; 在synctrl.go的调用顺序是–&gt;main–&gt;ghpb–&gt;startNode–&gt;–&gt;utils.StartNode(stack)–&gt;hpbnode.Start()–&gt;–&gt;hpbnode.Hpbsyncctr.Start() 在Start方法中初始化this.txCh，并进行消息订单 消息的消费是在txRoutingLoop协程中 在routTx方法中，找出不知道该交易的peer，然后逐个发出去了123456789101112131415161718192021222324func (this *SynCtrl) Start() &#123; // broadcast transactions this.txCh = make(chan bc.TxPreEvent, txChanSize) this.txSub = this.txpool.SubscribeTxPreEvent(this.txCh) go this.txRoutingLoop() // broadcast mined blocks this.minedBlockSub = this.newBlockMux.Subscribe(bc.NewMinedBlockEvent&#123;&#125;) go this.minedRoutingLoop() // start sync handlers go this.sync() go this.txsyncLoop()&#125;func (this *SynCtrl) txRoutingLoop() &#123; for &#123; select &#123; case event := &lt;-this.txCh: routTx(event.Tx.Hash(), event.Tx) &#125; &#125;&#125; 在worker.go的调用顺序是–&gt;main–&gt;ghpb–&gt;startNode–&gt;–&gt;hpbnode.WorkerInit–&gt;worker.New–&gt;newWorker在newWorker中初始化worker.txCh，并订阅消息，消息的处理是在协程worker.eventListener()中进行的。在系统没有挖矿的状态下，把消息发送到commitTransactions进行处理。commitTransactions会把交易提交到evm进行执行，这个单独解析下吧。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768func newWorker(config *config.ChainConfig, engine consensus.Engine, coinbase common.Address, /*eth Backend,*/ mux *sub.TypeMux) *worker &#123; worker := &amp;worker&#123; config: config, engine: engine, mux: mux, /*txCh: make(chan bc.TxPreEvent, txChanSize),*/ chainHeadCh: make(chan bc.ChainHeadEvent, chainHeadChanSize), chainSideCh: make(chan bc.ChainSideEvent, chainSideChanSize), chainDb: nil,//hpbdb.ChainDbInstance(), recv: make(chan *Result, resultQueueSize), chain: bc.InstanceBlockChain(), proc: bc.InstanceBlockChain().Validator(), possibleUncles: make(map[common.Hash]*types.Block), coinbase: coinbase, producers: make(map[Producer]struct&#123;&#125;), unconfirmed: newUnconfirmedBlocks(bc.InstanceBlockChain(), miningLogAtDepth), &#125; worker.pool = txpool.GetTxPool() worker.txCh = make(chan bc.TxPreEvent, txChanSize) worker.txSub = worker.pool.SubscribeTxPreEvent(worker.txCh) worker.chainHeadSub = bc.InstanceBlockChain().SubscribeChainHeadEvent(worker.chainHeadCh) worker.chainSideSub = bc.InstanceBlockChain().SubscribeChainSideEvent(worker.chainSideCh) //对以上事件的监听 go worker.eventListener() go worker.handlerSelfMinedBlock() return worker&#125;func (self *worker) eventListener() &#123; defer self.txSub.Unsubscribe() defer self.chainHeadSub.Unsubscribe() defer self.chainSideSub.Unsubscribe() for &#123; // A real event arrived, process interesting content select &#123; // Handle ChainHeadEvent case &lt;-self.chainHeadCh: self.startNewMinerRound() // Handle ChainSideEvent case ev := &lt;-self.chainSideCh: self.uncleMu.Lock() self.possibleUncles[ev.Block.Hash()] = ev.Block self.uncleMu.Unlock() // Handle TxPreEvent case ev := &lt;-self.txCh: // Apply transaction to the pending state if we're not mining if atomic.LoadInt32(&amp;self.mining) == 0 &amp;&amp; self.current != nil &#123; self.currentMu.Lock() acc, _ := types.Sender(self.current.signer, ev.Tx) txs := map[common.Address]types.Transactions&#123;acc: &#123;ev.Tx&#125;&#125; txset := types.NewTransactionsByPriceAndNonce(self.current.signer, txs) self.current.commitTransactions(self.mux, txset, self.coinbase) self.currentMu.Unlock() &#125; case &lt;-self.chainHeadSub.Err(): return case &lt;-self.chainSideSub.Err(): return &#125; &#125;&#125;]]></content>
      <categories>
        <category>HPB源码解读</category>
      </categories>
      <tags>
        <tag>HPB</tag>
        <tag>区块链</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GO-HPB源码解读--交易入池（一）]]></title>
    <url>%2F2019%2F07%2F21%2FGO-HPB%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB-%E4%BA%A4%E6%98%93%E5%85%A5%E6%B1%A0%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[#GO-HPB源码解读–交易入池（一）在本地启动节点后，通过控制台输入命令hpb.sendTransaction({from:&quot;db3cf5c98af974d3cccdc8662f1ab3c27c6e47ee&quot;,to:&quot;742c8a59152a397ad09f7fb280c4fc378598a4ba&quot;,value:web3.toWei(10000,&quot;hpb&quot;)})来完成转账交易。交易内容最初始会进入到SendTransaction。 打印了一下传进来的参数args{From:[219 60 245 201 138 249 116 211 204 205 200 102 47 26 179 194 124 110 71 238] To:[116 44 138 89 21 42 57 122 208 159 127 178 128 196 252 55 133 152 164 186] Gas: GasPrice: Value:0x21e19e0c9bab2400000 Data:0x Nonce:} 首先检查一下from地址是不是存在钱包中，如果不存在就返回错误 锁定交易的nonce，因为nonce是唯一的，防止交易的重播攻击 对交易需要的其他参数进行设置，Gas默认值为90000，GasPrice和Nonce经由计算获得，这个后续再分析 创建一个交易对象，将以上参数进行赋值 使用from的帐户钱包对交易进行签名，来证明这签交易确实是from发出的。签名过程：(1). 首先使用from的私钥对nonce、price、gaslimit、recipient、amount、payload进行secp256k1签名(2). 然后签名结果分解成R、S、V，并赋给交易对象，注意这个时候交易对象中并没有from地址 最后提交交易 123456789101112131415161718192021222324252627282930313233343536// SendTransaction creates a transaction for the given argument, sign it and submit it to the// transaction pool.func (s *PublicTransactionPoolAPI) SendTransaction(ctx context.Context, args SendTxArgs) (common.Hash, error) &#123; // Look up the wallet containing the requested signer account := accounts.Account&#123;Address: args.From&#125; wallet, err := s.b.AccountManager().Find(account) if err != nil &#123; return common.Hash&#123;&#125;, err &#125; if args.Nonce == nil &#123; // Hold the addresse's mutex around signing to prevent concurrent assignment of // the same nonce to multiple accounts. s.nonceLock.LockAddr(args.From) defer s.nonceLock.UnlockAddr(args.From) &#125; // Set some sanity defaults and terminate on failure if err := args.setDefaults(ctx, s.b); err != nil &#123; return common.Hash&#123;&#125;, err &#125; // Assemble the transaction and sign with the wallet tx := args.toTransaction() var chainID *big.Int if config := s.b.ChainConfig(); true &#123; chainID = config.ChainId &#125; signed, err := wallet.SignTx(account, tx, chainID) if err != nil &#123; return common.Hash&#123;&#125;, err &#125; return submitTransaction(ctx, s.b, signed)&#125; submitTransaction方法把交易提交到交易池txpool 首先计算交易的hash，这个交易在输入交易命令后显示的那个hash值 判断交易池中是否包含该交易，包含的话就直接回退失败 验证交易 锁定交易，也就是把交易保存到交易池的过程123456789101112131415161718// AddTx attempts to queue a transactions if valid.func (pool *TxPool) AddTx(tx *types.Transaction) error &#123; pool.mu.Lock() defer pool.mu.Unlock() hash := tx.Hash() if pool.all[hash] != nil &#123; log.Trace("Discarding already known transaction", "hash", hash) return fmt.Errorf("known transaction: %x", hash) &#125; // If the transaction fails basic validation, discard it if err := pool.validateTx(tx); err != nil &#123; log.Trace("Discarding invalid transaction", "hash", hash, "err", err) return err &#125; return pool.addTxLocked(tx)&#125; validateTx对交易进行验证 交易的大小是否超过32k，其中的tx.Size主要计算的是交易的data部分的数据大小 交易金额不能小于0 当前交易的gasLimit是否大于当前区块的最大gas值，每个区块块都有一个总的gas限制，也就是一个区块中的所有交易的gas总和不能超过区块的gas限制 验证签名是否有效，并还原出地址from（这块没细看，之后再看下） 交易给出的gas价格必须大于txpool的最低价格，要不然挖工收益会少 当前交易的nonce必须要大于上一次的交易nonce。帐户信息直接保存在stateDB中，可以从中获取 交易花费gasprice*gasLimit必须大于帐户余额 如果交易是创建合约或者调用合约，需要计算一下需要多少gas，如果交易支付的最大gas不够多也是拒绝的（这块没细看，之后再看下）123456789101112131415161718192021222324252627282930313233343536373839404142434445464748// validateTx checks whether a transaction is valid according to the consensus// rules and adheres to some heuristic limits of the local node (price and size).func (pool *TxPool) validateTx(tx *types.Transaction) error &#123; // Heuristic limit, reject transactions over 32KB to prevent DOS attacks if tx.Size() &gt; maxTransactionSize &#123; log.Trace("ErrOversizedData maxTransactionSize", "ErrOversizedData",ErrOversizedData) return ErrOversizedData &#125; // Transactions can't be negative. This may never happen using RLP decoded // transactions but may occur if you create a transaction using the RPC. if tx.Value().Sign() &lt; 0 &#123; log.Trace("ErrNegativeValue", "ErrNegativeValue",ErrNegativeValue) return ErrNegativeValue &#125; // Ensure the transaction doesn't exceed the current block limit gas. if pool.currentMaxGas.Cmp(tx.Gas()) &lt; 0 &#123; log.Trace("ErrGasLimit", "ErrGasLimit",ErrGasLimit) return ErrGasLimit &#125; // Call BOE recover sender. from, err := types.Sender(pool.signer, tx) if err != nil &#123; log.Trace("ErrInvalidSender", "ErrInvalidSender",ErrInvalidSender) return ErrInvalidSender &#125; // Check gasPrice. if pool.gasPrice.Cmp(tx.GasPrice()) &gt; 0 &#123; log.Trace("ErrUnderpriced", "ErrUnderpriced",ErrUnderpriced) return ErrUnderpriced &#125; // Ensure the transaction adheres to nonce ordering if pool.currentState.GetNonce(from) &gt; tx.Nonce() &#123; log.Trace("ErrNonceTooLow", "tx.Nonce()",tx.Nonce()) return ErrNonceTooLow &#125; // Transactor should have enough funds to cover the costs // cost == V + GP * GL if pool.currentState.GetBalance(from).Cmp(tx.Cost()) &lt; 0 &#123; log.Trace("ErrInsufficientFunds", "ErrInsufficientFunds",ErrInsufficientFunds) return ErrInsufficientFunds &#125; intrGas := types.IntrinsicGas(tx.Data(), tx.To() == nil) if tx.Gas().Cmp(intrGas) &lt; 0 &#123; log.Trace("ErrIntrinsicGas", "ErrIntrinsicGas",ErrIntrinsicGas) return ErrIntrinsicGas &#125; return nil&#125; 1234567891011121314// addTx enqueues a single transaction into the pool if it is valid.func (pool *TxPool) addTxLocked(tx *types.Transaction) error &#123; // Try to inject the transaction and update any state replace, err := pool.add(tx) if err != nil &#123; return err &#125; // If we added a new transaction, run promotion checks and return if !replace &#123; from, _ := types.Sender(pool.signer, tx) // already validated pool.promoteExecutables([]common.Address&#123;from&#125;) &#125; return nil&#125; pool.add方法中 首先计算交易的hash，并获取from地址 判断交易池是否满了，如果满了就返回失败。这里需要注意一下交易池维护着两个集合一个是pending，一个是queue，pending存放的是可以处理的交易，queue存放的是不可以处理的交易。 把交易池中pending所有from地址的交易都取出来赋到list，看看是不是包含相同的nonce的交易。（上边在创建交易的时候判断了nonce大于当前的，什么情况下会重复呢？）如果包含的话就往list里插入，但是插入的时候要判断一下这笔交易值不值替换上一笔相同nonce的交易。交易池有个参数priceBump，表示上浮价格，比如是20，当旧交易的old_gasprice*(100+20)/100=1.2倍的old_gaspreice，如果当前交易的价格大于1.2倍的old_gaspreice，则进行替换。同时list也会更新一下最大交易额和最大gas这时txpool才会把当前交易缓存起来 如果list也就是pending中没有重复的交易，那么对于queue也做同样的替换操作。注意如果queue中不存在该交易是会插入的，pending是不会的。（txpool.queue是个map，key是from地址，value是个list，保存着所有from地址的交易信息，也就是上边提到的list） 12345678910111213141516171819202122232425262728293031323334353637383940414243func (pool *TxPool) add(tx *types.Transaction) (bool, error) &#123; // If the transaction is already known, discard it hash := tx.Hash() from, _ := types.Sender(pool.signer, tx) // already validated // If the transaction pool is full, reject if uint64(len(pool.all)) &gt;= pool.config.GlobalSlots+pool.config.GlobalQueue &#123; log.Warn("TxPool is full, reject tx", "current size", len(pool.all), "max size", pool.config.GlobalSlots+pool.config.GlobalQueue, "hash", hash, "from", from, "to", tx.To()) return false, ErrTxPoolFull &#125; // If the transaction is replacing an already pending one, do directly if list := pool.pending[from]; list != nil &amp;&amp; list.Overlaps(tx) &#123; // Nonce already pending, check if required price bump is met inserted, old := list.Add(tx, pool.config.PriceBump) if !inserted &#123; return false, ErrReplaceUnderpriced &#125; // New transaction is better, replace old one if old != nil &#123; delete(pool.all, old.Hash()) &#125; pool.all[tx.Hash()] = tx pool.tmpqueue[tx.Hash()] = tx log.Trace("Pooled new executable transaction", "hash", hash, "from", from, "to", tx.To()) // We've directly injected a replacement transaction, notify subsystems //TODO why inject event here //event.FireEvent(&amp;event.Event&#123;Trigger: pool.txPreTrigger, Payload: event.TxPreEvent&#123;tx&#125;, Topic: event.TxPreTopic&#125;) return old != nil, nil &#125; // New transaction isn't replacing a pending one, push into queue replace, err := pool.enqueueTx(hash, tx) if err != nil &#123; return false, err &#125; log.Trace("Pooled new future transaction", "hash", hash, "from", from, "to", tx.To()) return replace, nil&#125; 如果交易池中的queue插入成功的话，queue数据发生变化，接下来promoteExecutables方法就是要把queue中某些交易移到pending中，从不可以处理的状态变成可处理的状态 删除所有nonce太低的交易 删除帐户余额太低或gas超过交易池限制的交易 将queue交易添加到pending中，同时会把交易发送到chan通道，chan接收之后广播到网络中的其他peer节点 删除超过queue容量限制的交易 最后keepFit处理超过pending容量限制的交易123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263func (pool *TxPool) promoteExecutables(accounts []common.Address) &#123; // Gather all the accounts potentially needing updates if accounts == nil &#123; accounts = make([]common.Address, 0, len(pool.queue)) for addr := range pool.queue &#123; accounts = append(accounts, addr) &#125; &#125; // Iterate over all accounts and promote any executable transactions for _, addr := range accounts &#123; list := pool.queue[addr] if list == nil &#123; continue // Just in case someone calls with a non existing account &#125; // Drop all transactions that are deemed too old (low nonce) for _, tx := range list.Forward(pool.currentState.GetNonce(addr)) &#123; hash := tx.Hash() log.Trace("Removed old queued transaction", "hash", hash) delete(pool.all, hash) &#125; // Drop all transactions that are too costly (low balance or out of gas) drops, _ := list.Filter(pool.currentState.GetBalance(addr), pool.currentMaxGas) for _, tx := range drops &#123; hash := tx.Hash() log.Trace("Removed unpayable queued transaction", "hash", hash) delete(pool.all, hash) &#125; // Gather all executable transactions and promote them for _, tx := range list.Ready(pool.pendingState.GetNonce(addr)) &#123; hash := tx.Hash() log.Trace("Promoting queued transaction", "hash", hash,"pool.pendingState.GetNonce(addr)",pool.pendingState.GetNonce(addr)) pool.promoteTx(addr, hash, tx) // Delete a single queue transaction if list != nil &#123; list.Remove(tx) &#125; &#125; // Drop all transactions over the allowed limit for _, tx := range list.Cap(int(pool.config.AccountQueue)) &#123; hash := tx.Hash() delete(pool.all, hash) log.Trace("Removed cap-exceeding queued transaction", "hash", hash) &#125; // Delete the entire queue entry if it became empty. if list.Empty() &#123; log.Trace("promoteExecutables list.Empty()") delete(pool.queue, addr) &#125; &#125; pool.keepFit()&#125;]]></content>
      <categories>
        <category>HPB源码解读</category>
      </categories>
      <tags>
        <tag>HPB</tag>
        <tag>区块链</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GO-HPB源码解读--投票机制]]></title>
    <url>%2F2019%2F07%2F21%2FGO-HPB%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB-%E6%8A%95%E7%A5%A8%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[#GO-HPB源码解读–投票机制在挖矿流程的最近一节中，提到了voting.GetHpbNodeSnap的投票机制。投票的目的就是来计算出本节点是否能够签名区块，所以每次在组装区块的时候都会获取上一次的投票结果，如果出现异常或者投票周期到了，则重新计算投票结果。投票结果是通过结构体进行保存的。CandAddress 节点地址(当前的授权用户)VoteNumbers 获得票数VoteIndexs 获胜者的指标总和VotePercent 占比 12345678910111213141516171819type Tally struct &#123; CandAddress common.Address `json:"candAddress"` // 通过投票的个数 VoteNumbers *big.Int `json:"voteNumbers"` // 通过投票的个数 VoteIndexs *big.Int `json:"voteIndexs"` // 通过投票的个数 VotePercent *big.Int `json:"votePercent"` // 通过投票的个数&#125;&lt;!-- more --&gt;type HpbNodeSnap struct &#123; config *config.PrometheusConfig sigcache *lru.ARCCache //Number uint64 `json:"number"` // 生成快照的时间点 CheckPointNum uint64 `json:"checkPointNum"` // 最近的检查点 CheckPointHash common.Hash `json:"checkPointHash"` // 生成快照的Block hash Signers map[common.Address]struct&#123;&#125; `json:"signers"` // 当前的授权用户 Recents map[uint64]common.Address `json:"recents"` // 最近签名者 spam Tally map[common.Address]Tally `json:"tally"` // 目前的计票情况&#125; 接下来看一下代码实现，其中HpbNodeCheckpointInterval==200 如果number==0，就先生成一个初始快照并返回 如果number&lt;200，就从缓存/数据库中取出初始快照，如果取出失败，则生成一个初始快照并返回 其他情况就是number&gt;=200，如果number正好是200的整数倍数的话，则生成快照，否则从缓存/数据库中获取上一次的快照，如果获取失败则重新生成上一次的快照。举个栗子，number=666，则获取number=600的快照，如果number=800，则生成新的快照。很明显间隔相当于从0开始算的，并不是最近的200个块。但是。。。往下看number是怎么使用的12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364func GetHpbNodeSnap(db hpbdb.Database, recents *lru.ARCCache, signatures *lru.ARCCache, config *config.PrometheusConfig, chain consensus.ChainReader, number uint64, hash common.Hash, parents []*types.Header) (*snapshots.HpbNodeSnap, error) &#123; // 首次要创建 if number == 0 &#123; if snapg, err := GenGenesisSnap(db, recents, signatures, config, chain); err == nil &#123; return snapg, err &#125; &#125; //前十轮不会进行投票，前10轮采用区块0时候的数据 //先获取缓存，如果缓存中没有则获取数据库，为了提升速度 //if(true)&#123; if number &lt; consensus.HpbNodeCheckpointInterval &#123; genesis := chain.GetHeaderByNumber(0) hash := genesis.Hash() // 从缓存中获取 if snapcd, err := GetDataFromCacheAndDb(db, recents, signatures, config, hash); err == nil &#123; log.Debug("HPB_VOTING： Loaded voting Hpb Node Snap form cache and db", "number", number, "hash", hash) return snapcd, err &#125; else &#123; if snapg, err := GenGenesisSnap(db, recents, signatures, config, chain); err == nil &#123; log.Debug("HPB_VOTING： Loaded voting Hpb Node Snap form genesis snap", "number", number, "hash", hash) return snapg, err &#125; &#125; &#125; // 开始考虑10轮之后的情况，往前回溯3轮，以保证一致性。 // 开始计算最后一次的确认区块 latestCheckPointNumber := uint64(math.Floor(float64(number/consensus.HpbNodeCheckpointInterval))) * consensus.HpbNodeCheckpointInterval //log.Error("Current latestCheckPointNumber in hpb voting:",strconv.FormatUint(latestCheckPointNumber, 10)) header := chain.GetHeaderByNumber(uint64(latestCheckPointNumber)) latestCheckPointHash := header.Hash() if number%consensus.HpbNodeCheckpointInterval != 0 &#123; if snapcd, err := GetDataFromCacheAndDb(db, recents, signatures, config, latestCheckPointHash); err == nil &#123; //log.Info("##########################HPB_VOTING： Loaded voting Hpb Node Snap form cache and db", "number", number, "latestCheckPointNumber", latestCheckPointNumber) return snapcd, err &#125; else &#123; if snapa, err := snapshots.CalculateHpbSnap(uint64(1), signatures, config, number, latestCheckPointNumber, latestCheckPointHash, chain); err == nil &#123; //log.Info("@@@@@@@@@@@@@@@@@@@@@@@@HPB_VOTING： CalculateHpbSnap", "number", number, "latestCheckPointNumber", latestCheckPointNumber) if err := StoreDataToCacheAndDb(recents, db, snapa, latestCheckPointHash); err != nil &#123; return nil, err &#125; return snapa, err &#125; &#125; &#125; else &#123; if snapa, err := snapshots.CalculateHpbSnap(uint64(1), signatures, config, number, latestCheckPointNumber, latestCheckPointHash, chain); err == nil &#123; //log.Info("@@@@@@@@@@@@@@@@@@@@@@@@HPB_VOTING： CalculateHpbSnap", "number", number, "latestCheckPointNumber", latestCheckPointNumber) //新轮次计算完高性能节点立即更新节点类型 //prometheus.SetNetNodeType(snapa) if err := StoreDataToCacheAndDb(recents, db, snapa, latestCheckPointHash); err != nil &#123; return nil, err &#125; return snapa, err &#125; else &#123; return nil, err &#125; &#125; return nil, nil&#125; 具体生成快照的算法是在CalculateHpbSnap中实现的，也就是区块链核的共识算法。先看一下参数含意：字段|类型|含义|备注-|-|-|-index | |投票轮次，CalculateHpbSnap调用时是第一次，所以传1 |*lru | |最近的签名，使用ARC算法实现 |config | |共识配置，Prometheus的属性 |number | |区块序号 |latestCheckPointNum |最近应该生成快照对应的区块序号，也就是200的整数倍 | |latestCheckPointHash |最近应该生成快照对应的区块哈希 | |chain |区块链指针 | | 快照生成主要通过number参数选举出一定的区块生成节点，这块要主算法实现，为了方便理解，假设在生成区块时的number为210、650、1875，也就是调用GetHpbNodeSnap方法传入的number，表示为{210|650|1875}，最后计算得到latestCheckPointNum是{200|600|1800}，将这两个参数传入CalculateHpbSnap，注意此时index传入的是1 选出一定范围内的区块头集合，区间界线为from到latestCheckPointNum-100，from计算方法是latestCheckPointNum - index*consensus.HpbNodeCheckpointInterval，所以可以得到的范围是{0-100|400-500|1600-1700} 通过chain取出{0-100|400-500|1600-1700}范围内所有区块头，赋给headers变量，一共100个区块头（理想情况下）。如果在获取头的时候累计出了20次没取到，直接返回异常errors.New(“get hpb snap but missing header”) 对区块头集合headers进行连续性检查，也就是所有区块头的number必须是连续的，否则返回异常 初始化快照对象snap，并填装snap的Tally属性，注意snap的Tally是map[common.Address]Tally类型的，key是add，value是Tally，而value的类型Tally本身又是一个结构体。填装过程就是把header对应的所有address作为键put到map中，value是Tally结构体。 *Tally初始值是VoteNumbers: 1, VoteIndexs: header.VoteIndex, VotePercent: header.VoteIndex, *如果key重复出现，则需要把VoteNumbers和VoteIndexs对应的新旧值进行累加，重新计算VotePercent=VoteIndexs/VoteNumbers并赋值这样就得到了100一个header对应的address的Tally，当然结果可能会少于100个，因为有重复的。 将map再复制到临时变量tallytemp中，分别按照CandAddress和百分比VotePercent从小到大进行排序，排序结果保存到变更finaltally中 接下来通过当前高性能节点数量来解决是否需要再次进行获取一些headers来进行投票计算，也就是上边1-5步骤 系统默认的高性能节点个数是consensus.HpbNodenumber=31个，如果finaltally长度大等于31，则把排序后的后边的31个节点地址添加到snap.Signers中，即授权用户，表示可以进行挖矿。 如果finaltally小于31，而且已经进行了4次投票计算（1-5步骤），就把finaltally中所有的地址进行授权 如果finaltally小于31，而且进行了不到4次投票计算，则往前回溯再取出一些区块头（地址）进行投票。但是往前回溯有个条件，就是前边有足够的区块头可以获取，如果前边的区块头不够充足了，则只能把当前finaltally的地址全部授权了。是否可以往前回溯的判断条件是index&lt;number/200，比如第一轮投票的时候number={210|650|1875}，投了{0-100|400-500|1600-1700}区间的节点地址，最终结果不够31个高性能节点，那么进行第二轮投票。2&lt;210/200为false，这种情况就不能往前回溯了；2&lt;650/200为true，则可以回溯，然后递归调用CalculateHpbSnap方法，这时传入的index=2，number和latestCheckPointNum分别向前移200个单位，即number={-|450|1675}，latestCheckPointNum={-|400|1600}，递归后可得范围为 {-|200-300|1400-1500}。可以发现每次中间隔100个单位。 在进行了下一投票计算（递归调用）之后，得到新的节点地址集合，把其中已经存在于上一次finaltally中的地址删除掉，此时如果新的节点地址一个也没有，则结束投票，如果还有的话就对新的节点地址集合进行排序 排序完了之后，如果新旧集合的长度和小等于31，就把新旧集合合并一下，否则的话把新集合的数据补充到旧集合中，直到旧集合够31个节点了。 最后把zeroaddr地址删除掉。（不是很清楚，什么情况下会有存在zeroaddr地址） 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179func CalculateHpbSnap(index uint64, signatures *lru.ARCCache, config *config.PrometheusConfig, number uint64, latestCheckPointNum uint64, latestCheckPointHash common.Hash, chain consensus.ChainReader) (*HpbNodeSnap, error) &#123; // Allow passing in no headers for cleaner code var headers []*types.Header // 开始获取之前的所有header var from = latestCheckPointNum - index*consensus.HpbNodeCheckpointInterval if from == 0 &#123; from = from + 1 &#125; for i := from; i &lt; latestCheckPointNum-100; i++ &#123; loopcount := 0 GETCOUNT: header := chain.GetHeaderByNumber(uint64(i)) if header != nil &#123; headers = append(headers, header) &#125; else &#123; if loopcount &gt; 20 &#123; return nil, errors.New("get hpb snap but missing header") &#125; loopcount += 1 goto GETCOUNT //log.Error("get hpb snap but missing header", "number", i) &#125; &#125; // 如果头部为空，直接返回 if len(headers) == 0 &#123; return nil, errors.New("Calculate Hpb Snap headers is 0 ") &#125; // 检查所有的头部，检查连续性 for i := 0; i &lt; len(headers)-1; i++ &#123; if headers[i+1].Number.Uint64() != headers[i].Number.Uint64()+1 &#123; return nil, consensus.ErrInvalidVotingChain &#125; &#125; //signers := make([]common.Address, 0, consensus.HpbNodenumber) snap := NewHistorysnap(config, signatures, number, latestCheckPointNum, latestCheckPointHash, nil) snap.Tally = make(map[common.Address]Tally) for _, header := range headers &#123; VoteNumberstemp := big.NewInt(0) VoteIndexstemp := big.NewInt(0) VotePercenttemp := big.NewInt(0) //票的数量与性能之间的关系，获取票的数量表示在线时间长度，所以应该选择在线时间长性能又好的节点。 if old, ok := snap.Tally[header.CandAddress]; ok &#123; VoteNumberstemp.Add(old.VoteNumbers, big.NewInt(1)) VoteIndexstemp.Add(old.VoteIndexs, header.VoteIndex) VotePercenttemp.Div(VoteIndexstemp, VoteNumberstemp) snap.Tally[header.CandAddress] = Tally&#123; VoteNumbers: VoteNumberstemp, VoteIndexs: VoteIndexstemp, VotePercent: VotePercenttemp, CandAddress: header.CandAddress, &#125; &#125; else &#123; snap.Tally[header.CandAddress] = Tally&#123; VoteNumbers: big.NewInt(1), VoteIndexs: header.VoteIndex, VotePercent: header.VoteIndex, CandAddress: header.CandAddress, &#125; &#125; &#125; var tallytemp []Tally for _, v := range snap.Tally &#123; tallytemp = append(tallytemp, v) &#125; for i := 0; i &lt; len(snap.Tally); i++ &#123; for j := 0; j &lt; len(snap.Tally)-i-1; j++ &#123; if bytes.Compare(tallytemp[j].CandAddress[:], tallytemp[j+1].CandAddress[:]) &gt; 0 &#123; tallytemp[j], tallytemp[j+1] = tallytemp[j+1], tallytemp[j] &#125; &#125; &#125; for i := 0; i &lt; len(snap.Tally); i++ &#123; for j := 0; j &lt; len(snap.Tally)-i-1; j++ &#123; if tallytemp[j].VotePercent.Cmp(tallytemp[j+1].VotePercent) &gt; 0 &#123; tallytemp[j], tallytemp[j+1] = tallytemp[j+1], tallytemp[j] &#125; else if (tallytemp[j].VotePercent.Cmp(tallytemp[j+1].VotePercent) == 0) &amp;&amp; (bytes.Compare(tallytemp[j].CandAddress[:], tallytemp[j+1].CandAddress[:]) &gt; 0) &#123; tallytemp[j], tallytemp[j+1] = tallytemp[j+1], tallytemp[j] &#125; &#125; &#125; finaltally := make([]common.Address, 0, len(tallytemp)) for _, v := range tallytemp &#123; finaltally = append(finaltally, v.CandAddress) &#125; var hpnodeNO int if len(finaltally) &gt;= consensus.HpbNodenumber &#123; hpnodeNO = consensus.HpbNodenumber goto END &#125; else &#123; if index == consensus.Hpcalclookbackround+1 &#123; //look back round is consensus.Hpcalclookbackround hpnodeNO = len(finaltally) goto END &#125; index = index + 1 if index &lt; uint64(math.Floor(float64(number/consensus.HpbNodeCheckpointInterval))) &#123; // 往前回溯 //log.Error("-------- go back for last snap------------", "index", index) header := chain.GetHeaderByNumber(uint64(latestCheckPointNum - consensus.HpbNodeCheckpointInterval)) latestCheckPointHash := header.Hash() snaptemp, err := CalculateHpbSnap(index, signatures, config, number-consensus.HpbNodeCheckpointInterval, latestCheckPointNum-consensus.HpbNodeCheckpointInterval, latestCheckPointHash, chain) if err != nil &#123; log.Debug("recursive call CalculateHpbSnap fail", "err", err) hpnodeNO = len(finaltally) goto END &#125; //get last snap hp nodes, set in map hpsmaptemp := make(map[common.Address]struct&#123;&#125;) lastsnap := snaptemp.GetHpbNodes() for _, v := range lastsnap &#123; hpsmaptemp[v] = struct&#123;&#125;&#123;&#125; &#125; //delete tallytemp.CandAddress in the map for _, v := range finaltally &#123; if _, ok := hpsmaptemp[v]; ok &#123; delete(hpsmaptemp, v) &#125; &#125; if 0 == len(hpsmaptemp) &#123; hpnodeNO = len(finaltally) goto END &#125; //order the hpsmaptemp by put it into []common.address delhpsmap := make([]common.Address, len(hpsmaptemp)) for key, _ := range hpsmaptemp &#123; delhpsmap = append(delhpsmap, key) &#125; //sort by addr if 1 &lt; len(delhpsmap) &#123; for i := 0; i &lt; len(delhpsmap); i++ &#123; for j := 0; j &lt; len(delhpsmap)-i-1; j++ &#123; if bytes.Compare(delhpsmap[j][:], delhpsmap[j+1][:]) &gt; 0 &#123; delhpsmap[j], delhpsmap[j+1] = delhpsmap[j+1], delhpsmap[j] &#125; &#125; &#125; &#125; //calc how many last snap hps needing to add the latest snap if len(finaltally)+len(delhpsmap) &gt; consensus.HpbNodenumber &#123; for i := 0; i &lt; consensus.HpbNodenumber-len(finaltally); i++ &#123; finaltally = append(finaltally, delhpsmap[i]) &#125; &#125; else &#123; for i := 0; i &lt; len(delhpsmap); i++ &#123; finaltally = append(finaltally, delhpsmap[i]) &#125; &#125; &#125; hpnodeNO = len(finaltally) &#125;END: for i := len(finaltally) - 1; i &gt; len(finaltally)-hpnodeNO-1; i-- &#123; snap.Signers[finaltally[i]] = struct&#123;&#125;&#123;&#125; &#125; zeroaddr := common.HexToAddress("0x0000000000000000000000000000000000000000") if _, ok := snap.Signers[zeroaddr]; ok &#123; delete(snap.Signers, zeroaddr) &#125; return snap, nil&#125; 在确定节点地址区间的逻辑比较简单,就是从前往后，隔100,标记100个为可取的,然后从后往前取倒数第一个100，去重后够31个就可以了，不够了再取倒数第2个100。代码算法写的复杂了，还用了递归。。。。。VoteIndexs这个是从区块头中取出来的，没找到最初是在哪儿set进去的。真累人………]]></content>
      <categories>
        <category>HPB源码解读</category>
      </categories>
      <tags>
        <tag>HPB</tag>
        <tag>区块链</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GO-HPB源码解读--挖矿流程（四）]]></title>
    <url>%2F2019%2F07%2F21%2FGO-HPB%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB-%E6%8C%96%E7%9F%BF%E6%B5%81%E7%A8%8B%EF%BC%88%E5%9B%9B%EF%BC%89%2F</url>
    <content type="text"><![CDATA[#GO-HPB源码解读–挖矿流程（四）接着上一章，我们看到了这章来看了go self.mine(work, self.quitCurrentOp)这部分代码，现在来看下具体挖矿算法的流程。mine方法中调用engine.GenBlockWithSig方法，返回的result结果传递给returnCh通道，而returnCh通道的获取工作是在worker中进行处理的。上一节我们理了一下producer绑定CpuAgent的流程，在worker.New的时候，通过go worker.handlerSelfMinedBlock()这行代码启了一个协程去获取通道里的挖矿结果。 1234567891011func (self *CpuAgent) mine(work *Work, stop &lt;-chan struct&#123;&#125;) &#123; if result, err := self.engine.GenBlockWithSig(self.chain, work.Block, stop); result != nil &#123; log.Info("Successfully sealed new block", "number -&gt; ", result.Number(), "hash -&gt; ", result.Hash(),"difficulty -&gt; ",result.Difficulty()) self.returnCh &lt;- &amp;Result&#123;work, result&#125; &#125; else &#123; if err != nil &#123; log.Warn("Block sealing failed", "err", err) &#125; self.returnCh &lt;- nil &#125;&#125; 生成区块的过程： 数据合法性校验 获取签名者signer和签名方法signFn，这两个数据是在挖矿流程（二）中的StartMining方法中设置的，代码是promeengine.Authorize(eb, wallet.SignHash)，即signer是当前节点的挖矿地址coinbase，signFn是对应钱包的签名方法，即keystoreWallet类的签名方法 voting.GetHpbNodeSnap是获取高性能节点列表，其中有重新投票节点的过程，投票这个机制单独解读，这里就先不说了。 设置本地节点类型，是高性能节点还是候选节点 如果自己的当前节点不是包含在高性能节点中，则返回错误consensus.ErrUnauthorized 接着要判断一下自己当前节点是否轮到进行签名（挖矿），如果没轮到，需要通过高性能节点列表中自己的位置和正在挖矿的位置两个关键参数计算出自己需要等待的一个时间段， 时间到了的话就进行签名，签名方法为signFn,这个方法直接使用coinbase对应的私钥进行ECDSA签名 签名完了之后，把签名结果放置到header.Extra里，并返回最终block 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182//生成区块func (c *Prometheus) GenBlockWithSig(chain consensus.ChainReader, block *types.Block, stop &lt;-chan struct&#123;&#125;) (*types.Block, error) &#123; header := block.Header() log.Info("HPB Prometheus Seal is starting") number := header.Number.Uint64() if number == 0 &#123; return nil, consensus.ErrUnknownBlock &#125; // For 0-period chains, refuse to seal empty blocks (no reward but would spin sealing) if c.config.Period == 0 &amp;&amp; len(block.Transactions()) == 0 &#123; return nil, consensus.ErrWaitTransactions &#125; c.lock.RLock() signer, signFn := c.signer, c.signFn log.Debug("GenBlockWithSig-------------+++++ signer's address", "signer", signer.Hex(), "number", number) c.lock.RUnlock() snap, err := voting.GetHpbNodeSnap(c.db, c.recents, c.signatures, c.config, chain, number, header.ParentHash, nil) SetNetNodeType(snap) if err != nil &#123; return nil, err &#125; if _, authorized := snap.Signers[signer]; !authorized &#123; return nil, consensus.ErrUnauthorized &#125; // 轮到我们的签名 delay := time.Unix(header.Time.Int64(), 0).Sub(time.Now()) if delay &lt; 0 &#123; delay = 0 header.Time = big.NewInt(time.Now().Unix()) &#125; // 比较难度值，确定是否为适合的时间 if header.Difficulty.Cmp(diffNoTurn) == 0 &#123; // // It's not our turn explicitly to sign, delay it a bit wiggle := time.Duration(len(snap.Signers)/2+1) * wiggleTime currentminer := new(big.Int).SetBytes(header.HardwareRandom).Uint64() % uint64(len(snap.Signers)) //miner position //log.Error("-----genblocksig---------test for waiting 8 minutes--------------", "primemineraddr", primemineraddr, "primeoffset", currentminer, "number", number) myoffset := snap.GetOffset(header.Number.Uint64(), signer) distance := int(math.Abs(float64(int64(myoffset) - int64(currentminer)))) if distance &gt; len(snap.Signers)/2 &#123; distance = len(snap.Signers) - distance &#125; if distance &gt; len(snap.Signers)/consensus.StepLength &#123; //if signers length is smaller than 3, it means myoffset smaller than currentminer have high priority delay += time.Duration(len(snap.Signers)-distance+10+rand.Intn(5)) * wiggleTime &#125; else &#123; wiggle = time.Duration(1000+rand.Intn(len(snap.Signers))) * wiggleTime delay += wiggle &#125; &#125; log.Debug("Waiting for slot to sign and propagate", "delay", common.PrettyDuration(delay), "number", number) select &#123; case &lt;-stop: return nil, nil case &lt;-time.After(delay): &#125; // 地址赋值 header.Coinbase = signer // 签名交易，signFn为回掉函数 sighash, err := signFn(accounts.Account&#123;Address: signer&#125;, consensus.SigHash(header).Bytes()) if err != nil &#123; return nil, err &#125; //将签名后的结果返给到Extra中 copy(header.Extra[len(header.Extra)-consensus.ExtraSeal:], sighash) return block.WithSeal(header), nil&#125; 整个挖矿流程就到此结束了，当然其中会涉及一些其他的功能点，比如P2P，投票机制等，后续单独解读。这段代码读了很久，被投票那块搞死了，说好的POW呢？怎么没看到呢😭😭😭😭😭😭😭😭😭😭😭😭😭😭😭😭😭😭😭😭😭😭😭😭😭😭😭😭]]></content>
      <categories>
        <category>HPB源码解读</category>
      </categories>
      <tags>
        <tag>HPB</tag>
        <tag>区块链</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GO-HPB源码解读--挖矿流程（三）]]></title>
    <url>%2F2019%2F07%2F21%2FGO-HPB%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB-%E6%8C%96%E7%9F%BF%E6%B5%81%E7%A8%8B%EF%BC%88%E4%B8%89%EF%BC%89%2F</url>
    <content type="text"><![CDATA[#GO-HPB源码解读–挖矿流程（三）在挖矿流程（三）的最后，看到在go self.mine(work, self.quitCurrentOp)中要传递一个work对象进去。因为挖矿流程需要使用到大量的work数据，所以单独分析一下work的数据结构和初始化流程 1234567891011121314151617181920// Work is the workers current environment and holds// all of the current state informationtype Work struct &#123; config *config.ChainConfig signer types.Signer state *state.StateDB // apply state changes here ancestors *set.Set // ancestor set (used for checking uncle parent validity) family *set.Set // family set (used for checking uncle invalidity) uncles *set.Set // uncle set tcount int // tx count in cycle Block *types.Block // the new block header *types.Header txs []*types.Transaction receipts []*types.Receipt createdAt time.Time&#125; 字段 类型 含义 备注 config *config.ChainConfig chain的配置参数 signer types.Signer 签名 state *state.StateDB ancestors *set.Set 祖先哈希集合，也就是最近的7个区块的哈希， family *set.Set 家族哈希集合，也就是最近的7个区块的哈希以及每个区块的叔区块集合的哈希 uncles *set.Set 叔块集合 tcount int 交易周期内的交易数量 Block *types.Block header *types.Header txs []*types.Transaction receipts []*types.Receipt createdAt time.Time startNewMinerRound()方法主要是创建了一个work并push到workch通道中，大至流程是： 确定区块的时间戳，因为上一区块可能来自节点同步，所以时间可能存在差异，这里确保了两个点，一是新块的时间一定要比上一区块的时间大，至少1；二是新块的时间和自己系统时间差不要超过1，也就是说计算出来的新块时间戳比当前时间加1s还大，那就只能等一会儿再执行了。比如当前时间是1，新区时间戳是8，那么就需要等7s了。 组织新块的header 初始化当前work对象 把appending的交易打包进来 使用共识引擎组装成一个完整的区块 提交挖矿任务work1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495func (self *worker) startNewMinerRound() &#123; self.mu.Lock() defer self.mu.Unlock() self.uncleMu.Lock() defer self.uncleMu.Unlock() self.currentMu.Lock() defer self.currentMu.Unlock() tstart := time.Now() parent := self.chain.CurrentBlock() tstamp := tstart.Unix() if parent.Time().Cmp(new(big.Int).SetInt64(tstamp)) &gt;= 0 &#123; tstamp = parent.Time().Int64() + 1 &#125; // this will ensure we're not going off too far in the future if now := time.Now().Unix(); tstamp &gt; now+1 &#123; wait := time.Duration(tstamp-now) * time.Second log.Info("Mining too far in the future", "wait", common.PrettyDuration(wait)) time.Sleep(wait) &#125; num := parent.Number() header := &amp;types.Header&#123; ParentHash: parent.Hash(), Number: num.Add(num, common.Big1), GasLimit: bc.CalcGasLimit(parent), GasUsed: new(big.Int), Extra: self.extra, Time: big.NewInt(tstamp), &#125; // Only set the coinbase if we are mining (avoid spurious block rewards) if atomic.LoadInt32(&amp;self.mining) == 1 &#123; header.Coinbase = self.coinbase &#125; pstate, _ := self.chain.StateAt(parent.Root()) if err := self.engine.PrepareBlockHeader(self.chain, header,pstate); err != nil &#123; log.Error("Failed to prepare header for mining", "err", err) return &#125; err := self.makeCurrent(parent, header) if err != nil &#123; log.Error("Failed to create mining context", "err", err) return &#125; // Create the current work task and check any fork transitions needed work := self.current //if self.config.DAOForkSupport &amp;&amp; self.config.DAOForkBlock != nil &amp;&amp; self.config.DAOForkBlock.Cmp(header.Number) == 0 &#123; // misc.ApplyDAOHardFork(work.state) //&#125; pending, err := txpool.GetTxPool().Pending() if err != nil &#123; log.Error("Failed to fetch pending transactions", "err", err) return &#125; //log.Error("----read tx from pending is ", "number is", len(pending)) txs := types.NewTransactionsByPriceAndNonce(self.current.signer, pending) work.commitTransactions(self.mux, txs, self.coinbase) // compute uncles for the new block. var ( uncles []*types.Header badUncles []common.Hash ) for hash, uncle := range self.possibleUncles &#123; if len(uncles) == 2 &#123; break &#125; if err := self.commitUncle(work, uncle.Header()); err != nil &#123; log.Trace("Bad uncle found and will be removed", "hash", hash) log.Trace(fmt.Sprint(uncle)) badUncles = append(badUncles, hash) &#125; else &#123; log.Debug("Committing new uncle to block", "hash", hash) uncles = append(uncles, uncle.Header()) &#125; &#125; for _, hash := range badUncles &#123; delete(self.possibleUncles, hash) &#125; // Create the new block to seal with the consensus engine if work.Block, err = self.engine.Finalize(self.chain, header, work.state, work.txs, uncles, work.receipts); err != nil &#123; log.Error("Failed to finalize block for sealing", "err", err) return &#125; // We only care about logging if we're actually mining. if atomic.LoadInt32(&amp;self.mining) == 1 &#123; log.Info("Commit new mining work", "number", work.Block.Number(), "txs", work.tcount, "uncles", len(uncles), "elapsed", common.PrettyDuration(time.Since(tstart))) self.unconfirmed.Shift(work.Block.NumberU64() - 1) &#125; self.push(work)&#125; 1234567891011121314151617181920212223242526272829303132makeCurrent(...)方法即初始化了一个work对象，之后会设置work的tcount、uncles等其他属性// makeCurrent creates a new environment for the current cycle.func (self *worker) makeCurrent(parent *types.Block, header *types.Header) error &#123; state, err := self.chain.StateAt(parent.Root()) if err != nil &#123; return err &#125; work := &amp;Work&#123; config: self.config, signer: types.NewBoeSigner(self.config.ChainId), state: state, ancestors: set.New(), family: set.New(), uncles: set.New(), header: header, createdAt: time.Now(), &#125; // when 08 is processed ancestors contain 07 (quick block) for _, ancestor := range self.chain.GetBlocksFromHash(parent.Hash(), 7) &#123; for _, uncle := range ancestor.Uncles() &#123; work.family.Add(uncle.Hash()) &#125; work.family.Add(ancestor.Hash()) work.ancestors.Add(ancestor.Hash()) &#125; // Keep track of transactions which return errors so they can be removed work.tcount = 0 self.current = work return nil&#125;]]></content>
      <categories>
        <category>HPB源码解读</category>
      </categories>
      <tags>
        <tag>HPB</tag>
        <tag>区块链</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GO-HPB源码解读--挖矿流程（二）]]></title>
    <url>%2F2019%2F07%2F21%2FGO-HPB%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB-%E6%8C%96%E7%9F%BF%E6%B5%81%E7%A8%8B%EF%BC%88%E4%BA%8C%EF%BC%89%2F</url>
    <content type="text"><![CDATA[#GO-HPB源码解读–挖矿流程（二）这章来看下HPB的挖矿流程。在节点启动的时候通过flag参数mine指定是否进行挖矿，当然也可以在节点启动后通过API来调用，启动流程代码调用顺序是go-hpb/cmd/ghpb/main.go-main-&gt;ghpb-&gt;startNode`。在startNode方法最后部署代码可以看到，首先判断MiningEnabledFlag和RoleType两个参数后，设置交易的GasPrice后（系统默认为defaultGasPrice = 50 * config.Shannon），开启挖矿。 123456if ctx.GlobalBool(utils.MiningEnabledFlag.Name) &amp;&amp; (conf.Network.RoleType == "") &#123; stack.TxPool().SetGasPrice(utils.GlobalBig(ctx, utils.GasPriceFlag.Name)) if err := stack.StartMining(true); err != nil &#123; utils.Fatalf("Failed to start mining: %v", err) &#125; &#125; 在StartMining方法中 设置挖矿地址coinbase，这个地址是在HpbConfig初始化的时候设置的，取的是钱包中第一个帐户地址 获挖矿引擎Prometheus，并把coinbase和所在钱包的签名方法传递给引擎。这个操作主要是为了从wallet中取出coinbase的私钥，然后进行挖矿签名 开启接收交易的flag miner协程启动12345if wallets := hpbnode.AccountManager().Wallets(); len(wallets) &gt; 0 &#123; if account := wallets[0].Accounts(); len(account) &gt; 0 &#123; hpbnode.hpberbase = account[0].Address &#125; &#125; 123456789101112131415161718192021222324func (s *Node) StartMining(local bool) error &#123; //read coinbase from node eb := s.hpberbase if promeengine, ok := s.Hpbengine.(*prometheus.Prometheus); ok &#123; wallet, err := s.accman.Find(accounts.Account&#123;Address: eb&#125;) if wallet == nil || err != nil &#123; log.Error("Hpberbase account unavailable locally", "err", err) return fmt.Errorf("signer missing: %v", err) &#125; promeengine.Authorize(eb, wallet.SignHash) &#125; else &#123; log.Error("Cannot start mining without prometheus", "err", s.Hpbengine) &#125; if local &#123; // If local (CPU) mining is started, we can disable the transaction rejection // mechanism introduced to speed sync times. CPU mining on mainnet is ludicrous // so noone will ever hit this path, whereas marking sync done on CPU mining // will ensure that private networks work in single miner mode too. atomic.StoreUint32(&amp;s.Hpbsyncctr.AcceptTxs, 1) &#125; go s.miner.Start(eb) return nil&#125; 在Start方法中， 执行miner.update()方法 设置状态为shouldStart==1，表示不允许再次挖矿了，因为已经开始了。 设置挖矿地址coinbase 判断能否进行挖矿，如果不能则返回，不启动挖矿 worker.start()开使用挖矿，worker.startNewMinerRound()尝试再次启动挖工worker123456789101112131415161718func (self *Miner) Start(coinbase common.Address) &#123; // go self.update() atomic.StoreInt32(&amp;self.shouldStart, 1) self.worker.setHpberbase(coinbase) self.coinbase = coinbase if atomic.LoadInt32(&amp;self.canStart) == 0 &#123; log.Info("Network syncing, will start miner afterwards") return &#125; atomic.StoreInt32(&amp;self.mining, 1) log.Info("Starting mining operation") self.worker.start() self.worker.startNewMinerRound()&#125; 在miner.update()方法中，miner.mux订阅了三个事件，分别是下载开始事件，下载结束事件，下载失败事件，这个和以太坊的源码有些不同，以太坊是downloader.StartEvent{}, downloader.DoneEvent{}, downloader.FailedEvent{}，作用的是一样，在HPB源码中可以看下三个事件的发出都是和信息同步有关的,比如在synfast.go、synfull.go、synlight.go中的syncWithPeer方法中进行事件发布 如果收到下载开始事件，则停止当前的挖矿工作 如查收到下载完成或失败事件，则开启挖矿工作，同时取消事件订阅可以看到update中也有可能启动挖矿行为的，所以使用atomic来进行状态管理，实现线程安全。 12345678910111213141516171819202122232425262728293031// update keeps track of the synctrl events. Please be aware that this is a one shot type of update loop.// It's entered once and as soon as `Done` or `Failed` has been broadcasted the events are unregistered and// the loop is exited. This to prevent a major security vuln where external parties can DOS you with blocks// and halt your mining operation for as long as the DOS continues.func (self *Miner) update() &#123; events := self.mux.Subscribe(synctrl.StartEvent&#123;&#125;, synctrl.DoneEvent&#123;&#125;, synctrl.FailedEvent&#123;&#125;)out: for ev := range events.Chan() &#123; switch ev.Data.(type) &#123; case synctrl.StartEvent: atomic.StoreInt32(&amp;self.canStart, 0) if self.Mining() &#123; self.Stop() atomic.StoreInt32(&amp;self.shouldStart, 1) log.Info("Mining aborted due to sync") &#125; case synctrl.DoneEvent, synctrl.FailedEvent: shouldStart := atomic.LoadInt32(&amp;self.shouldStart) == 1 atomic.StoreInt32(&amp;self.canStart, 1) atomic.StoreInt32(&amp;self.shouldStart, 0) if shouldStart &#123; self.Start(self.coinbase) &#125; // unsubscribe. we're only interested in this event once events.Unsubscribe() // stop immediately and ignore all further pending events break out &#125; &#125;&#125; 在worker.start()方法中，首先设置了worker的状态，然后再启动producer.Start()。这里producer是接口类，其实现类只有一个，是CpuAgent。producer绑定CpuAgent是通过这行代码进行注册的miner.Register(NewCpuAgent(bc.InstanceBlockChain(), engine))。代码调用顺序是–&gt;ghpb–&gt;startNode–&gt;utils.StartNode(stack)–&gt;stack.Start(stack.Hpbconfig)–&gt;hpbnode.WorkerInit(conf)–&gt;hpbnode.miner = worker.New(&amp;conf.BlockChain, hpbnode.NewBlockMux(), hpbnode.Hpbengine, hpbnode.hpberbase)–&gt;miner.Register(NewCpuAgent(bc.InstanceBlockChain(), engine)) 1234567891011func (self *worker) start() &#123; self.mu.Lock() defer self.mu.Unlock() atomic.StoreInt32(&amp;self.mining, 1) // spin up agents for producer := range self.producers &#123; producer.Start() &#125;&#125; 接下来直接看下CpuAgent.Start()方法 首先进行CAS状态判断 协程启动update方法，这个类似于miner的update方法 123456func (self *CpuAgent) Start() &#123; if !atomic.CompareAndSwapInt32(&amp;self.isMining, 0, 1) &#123; return // producer already started &#125; go self.update()&#125; update方法中，在死循环中不断从chan中获取数据，如果数据类型是stop，则退出循环，如果是workCh则开始挖矿。stop事件是在miner.update方法中会传递。work的传递是在miner.Start()方法中startNewMinerRound()&lt;-makeCurrent()传递进去的。 123456789101112131415161718192021222324func (self *CpuAgent) update() &#123;out: for &#123; select &#123; case work := &lt;-self.workCh: self.mu.Lock() if self.quitCurrentOp != nil &#123; close(self.quitCurrentOp) &#125; self.quitCurrentOp = make(chan struct&#123;&#125;) go self.mine(work, self.quitCurrentOp) self.mu.Unlock() case &lt;-self.stop: self.mu.Lock() if self.quitCurrentOp != nil &#123; close(self.quitCurrentOp) self.quitCurrentOp = nil &#125; self.mu.Unlock() break out &#125; &#125;&#125; go self.mine(work, self.quitCurrentOp)才开始真正的挖矿计算，，下一章节再详细分析。]]></content>
      <categories>
        <category>HPB源码解读</category>
      </categories>
      <tags>
        <tag>HPB</tag>
        <tag>区块链</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GO-HPB源码解读--挖矿流程（一）]]></title>
    <url>%2F2019%2F07%2F21%2FGO-HPB%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB-%E6%8C%96%E7%9F%BF%E6%B5%81%E7%A8%8B%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[#GO-HPB源码解读–挖矿流程（一）在开析流程前先看下主要的数据结构，挖矿工作主要由三个对象来完成的，miner、worker、cpuAgent，其中cpuAgent实现Producer接口类 miner是入口，负责与外部交互，控制挖矿流程的启停操作 worker管理Work任务，他代理着Producer接口类，也就是代理着具体挖矿执行着 cpuAgent负责具体挖矿计算工作 1234567891011// Miner creates blocks and searches for proof-of-work values.type Miner struct &#123; mux *sub.TypeMux worker *worker coinbase common.Address mining int32 engine consensus.Engine canStart int32 // can start indicates whether we can start the mining operation shouldStart int32 // should start indicates whether we should start after sync&#125; 字段 类型 含义 备注 mux *sub.TypeMux 接收来自同步模块的StartEvent DoneEvent FailedEvent事件通知。在网络中，不可能只有一个矿工节点,当节点开始从其他节点同步Block时，我们就没有必要再继续挖矿了 worker *worker 具体执行挖矿的工人 coinbase common.Address 挖矿地址，挖矿所得的收入将计入该账户 mining int32 挖矿状态 engine consensus.Engine 共识引擎 canStart int32 是否可以开始挖矿 shouldStart int32 quitCurrentOp 1234567891011121314151617181920212223242526272829303132// worker is the main object which takes care of applying messages to the new statetype worker struct &#123; config *config.ChainConfig engine consensus.Engine mu sync.Mutex // update loop mux *sub.TypeMux pool *txpool.TxPool txCh chan bc.TxPreEvent txSub sub.Subscription //txSub sub.Subscription chainHeadCh chan bc.ChainHeadEvent chainHeadSub sub.Subscription chainSideCh chan bc.ChainSideEvent chainSideSub sub.Subscription wg sync.WaitGroup producers map[Producer]struct&#123;&#125; recv chan *Result chain *bc.BlockChain proc bc.Validator chainDb hpbdb.Database coinbase common.Address extra []byte currentMu sync.Mutex current *Work uncleMu sync.Mutex possibleUncles map[common.Hash]*types.Block unconfirmed *unconfirmedBlocks // set of locally mined blocks pending canonicalness confirmations // atomic status counters mining int32 atWork int32&#125; 字段 类型 含义 备注 config *config.ChainConfig engine consensus.Engine mu sync.Mutex mux *sub.TypeMux 注意与miner.mux属性不同，这里是向外部发布已经挖到新Block pool *txpool.TxPool txCh chan bc.TxPreEvent 接收txPool中tx的通道 txSub sub.Subscription chainHeadCh chan bc.ChainHeadEvent 接收区块头的通道 chainHeadSub sub.Subscription chainSideCh chan bc.ChainSideEvent 接收主备链变更通道 chainSideSub sub.Subscription wg sync.WaitGroup producers map[Producer]struct{} worker拥有一个Producer的map集合 recv chan *Result Producer结果发送通道，每个管理的Producer都可能将挖出的Block发到该Channel,也就是说,这个收方向Channel是一对多的 chain *bc.BlockChain proc bc.Validator chainDb hpbdb.Database 存储数据库 coinbase common.Address 挖矿地址 extra []byte currentMu sync.Mutex current *Work uncleMu sync.Mutex possibleUncles map[common.Hash]*types.Block unconfirmed *unconfirmedBlocks 本地挖出的待确认的块 mining int32 atWork int32 1234567// Agent can register themself with the workertype Producer interface &#123; Work() chan&lt;- *Work SetReturnCh(chan&lt;- *Result) Stop() Start()&#125; Producer是个接口类，主要定义了一些操作方法，在HPB中，该接口类只有CpuAgent这一个实现类 12345678910111213type CpuAgent struct &#123; mu sync.Mutex workCh chan *Work stop chan struct&#123;&#125; quitCurrentOp chan struct&#123;&#125; returnCh chan&lt;- *Result chain consensus.ChainReader engine consensus.Engine isMining int32 // 正在挖矿&#125; 字段 类型 含义 备注 mu sync.Mutex workCh chan *Work 接收来自worker下发的工作任务Work stop chan struct{} 使该CpuAgent停止工作的信号 quitCurrentOp chan struct{} 退出当前操作通道 returnCh chan&lt;- *Result 向worker反馈工作任务的完成情况,实际上就是挖出的新Block chain consensus.ChainReader 用于访问本地节点BlockChain数据的接口 engine consensus.Engine 计算所采用的共识引擎 isMining int32 是否正在挖矿]]></content>
      <categories>
        <category>HPB源码解读</category>
      </categories>
      <tags>
        <tag>HPB</tag>
        <tag>区块链</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GO-HPB源码解读--LevelDB操作]]></title>
    <url>%2F2019%2F07%2F21%2FGO-HPB%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB-LevelDB%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[#GO-HPB源码解读–LevelDB操作HPB使用LevelDB存储数据。go-hpb/blockchain/database_util.go文件封装了LevelDB的操作。因为LevelDB是&lt;k, v&gt;数据库，所以所有数据的存储都需要指定k。以下代码列出了所有需要保存的数据的k或者k的前缀。 ··· voteResultKey = []byte(“vote-result-key”) headHeaderKey = []byte(&quot;LastHeader&quot;) headBlockKey = []byte(&quot;LastBlock&quot;) headFastKey = []byte(&quot;LastFast&quot;) // Data item prefixes (use single byte to avoid mixing data types, avoid `i`). headerPrefix = []byte(&quot;h&quot;) // headerPrefix + num (uint64 big endian) + hash -&gt; header tdSuffix = []byte(&quot;t&quot;) // headerPrefix + num (uint64 big endian) + hash + tdSuffix -&gt; td numSuffix = []byte(&quot;n&quot;) // headerPrefix + num (uint64 big endian) + numSuffix -&gt; hash blockHashPrefix = []byte(&quot;H&quot;) // blockHashPrefix + hash -&gt; num (uint64 big endian) bodyPrefix = []byte(&quot;b&quot;) // bodyPrefix + num (uint64 big endian) + hash -&gt; block body blockReceiptsPrefix = []byte(&quot;r&quot;) // blockReceiptsPrefix + num (uint64 big endian) + hash -&gt; block receipts lookupPrefix = []byte(&quot;l&quot;) // lookupPrefix + hash -&gt; transaction/receipt lookup metadata bloomBitsPrefix = []byte(&quot;B&quot;) // bloomBitsPrefix + bit (uint16 big endian) + section (uint64 big endian) + hash -&gt; bloom bits randomPrefix = []byte(&quot;random&quot;) // randomPrefix + num (uint64 big endian) + hash -&gt; header preimagePrefix = &quot;secure-key-&quot; // preimagePrefix + hash -&gt; preimage configPrefix = []byte(&quot;hpb-config-&quot;) // config prefix for the db BloomBitsIndexPrefix = []byte(&quot;iB&quot;) // BloomBitsIndexPrefix is the data table of a chain indexer to track its progress oldReceiptsPrefix = []byte(&quot;receipts-&quot;) oldTxMetaSuffix = []byte{0x01} 这里对主要数据的k前缀整理下,其中hash指的是区块的hash，等于header中的hash，代码中称canonical hash。num是指区块的高度或者位置，表示第几个区块 key|Value -|- h+num+hash|header h+num+hash+t|tdh+num+n |hashH+hash | numb+num+hash |block bodyr+num+hash |block receiptsl+hash | transaction/receipt lookup metadataB+bit+section+hash |bloom bits database_util.go文件大部分内容是write和get方法，以前对前缀的拼接 以下内容转自网络，作个备注 StateObject: 是一个账号(地址)的状态信息 对于普通账号，这个对象保存了balance, nonce等信息 对于智能合约账号，还额外保留了智能合约的状态，这个状态就是智能合约里的定义的各种变量的值。以太坊虚拟机的变量是以&lt;k, v&gt;存储的，所以这个状态就是大量&lt;k, v&gt;对象。]]></content>
      <categories>
        <category>HPB源码解读</category>
      </categories>
      <tags>
        <tag>HPB</tag>
        <tag>区块链</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GO-HPB源码解读--多帐号解锁]]></title>
    <url>%2F2019%2F07%2F21%2FGO-HPB%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB-%E5%A4%9A%E5%B8%90%E5%8F%B7%E8%A7%A3%E9%94%81%2F</url>
    <content type="text"><![CDATA[#GO-HPB源码解读–多帐号解锁在启动节点时，解锁参数可以同时指定多个帐号，格式为--unlock &quot;addr1,addr2,addr3...&quot; --password &quot;pwd&quot;,其中unlock参数为多个帐号的地址，用逗号分隔；password参数为口令文件，文件中的口令每行一个口令。在创建帐号时，命令./ghpb --datadir node/data account init可以多次执行，每次执行后，会在路径node/data/keystore下生成多个帐号文件，比如UTC–2018-11-29T08-21-25.565157387Z–3e8aadb68222c70b309e87cd5c27e97950879076。当节点启动指定多个帐号时，会加载对应的帐号文件，并解锁。下边看一下解锁的代码。 启动节点入口main.go的init方法，调用过程为init()–&gt;ghpb–&gt;startNode() 1234567func init() &#123; // Initialize the CLI app and start Geth app.Action = ghpb app.HideVersion = true // we have a command to print the version app.Copyright = "Copyright 2013-2018 The go-hpb Authors " app.Commands = []cli.Command&#123; ...省略... 1234567891011121314// ghpb is the main entry point into the system if no special subcommand is ran.// It creates a default node based on the command line arguments and runs it in// blocking mode, waiting for it to be shut down.func ghpb(ctx *cli.Context) error &#123; cfg := MakeConfigNode(ctx) hpbnode, err := createNode(cfg) if err != nil &#123; utils.Fatalf("Failed to create node") return err &#125; startNode(ctx, hpbnode, cfg) hpbnode.Wait() return nil&#125; 在startNode方法中 首先获取keyStore的指针 MakePasswordList方法解析–password参数指定的口令文件，文件中的内容每一行对应一个口令 获取帐号列表，进行遍历解锁 后边是启动节点，并启动一个协程，开启钱包事件监听。这部分内容后续章节中再进行解读。下边看下遍历时，每个帐号是怎么使用口令解锁的。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667// startNode boots up the system node and all registered protocols, after which// it unlocks any requested accounts, and starts the RPC/IPC interfaces and the// miner.func startNode(ctx *cli.Context, stack *node.Node, conf *config.HpbConfig) &#123; // Unlock any account specifically requested ks := stack.AccountManager().KeyStore().(*keystore.KeyStore) passwords := utils.MakePasswordList(ctx) unlocks := strings.Split(ctx.GlobalString(utils.UnlockedAccountFlag.Name), ",") for i, account := range unlocks &#123; if trimmed := strings.TrimSpace(account); trimmed != "" &#123; unlockAccount(ctx, ks, trimmed, i, passwords) &#125; &#125; if unlocks[0] != "" &#123; account, err := utils.MakeAddress(ks, strings.TrimSpace(unlocks[0])) if err != nil &#123; utils.Fatalf("Could not list accounts: %v", err) &#125; conf.Node.DefaultAddress = account.Address &#125; //set rpc aii //utils.SetNodeAPI(&amp;conf.Node, stack) // Start up the node itself utils.StartNode(stack) // Register wallet event handlers to open and auto-derive wallets events := make(chan accounts.WalletEvent, 16) stack.AccountManager().Subscribe(events) go func() &#123; // Open any wallets already attached for _, wallet := range stack.AccountManager().Wallets() &#123; if err := wallet.Open(""); err != nil &#123; log.Warn("Failed to open wallet", "url", wallet.URL(), "err", err) &#125; &#125; // Listen for wallet event till termination for event := range events &#123; switch event.Kind &#123; case accounts.WalletArrived: if err := event.Wallet.Open(""); err != nil &#123; log.Warn("New wallet appeared, failed to open", "url", event.Wallet.URL(), "err", err) &#125; case accounts.WalletOpened: status, _ := event.Wallet.Status() log.Info("New wallet appeared", "url", event.Wallet.URL(), "status", status) case accounts.WalletDropped: log.Info("Old wallet dropped", "url", event.Wallet.URL()) event.Wallet.Close() &#125; &#125; &#125;() // Start auxiliary services if enabled if ctx.GlobalBool(utils.MiningEnabledFlag.Name) &amp;&amp; (conf.Network.RoleType == "") &#123; // Set the gas price to the limits from the CLI and start mining stack.TxPool().SetGasPrice(utils.GlobalBig(ctx, utils.GasPriceFlag.Name)) if err := stack.StartMining(true); err != nil &#123; utils.Fatalf("Failed to start mining: %v", err) &#125; &#125;&#125; 在unlockAccount方法中，每个帐号会进行尝试3次解锁。每次会从口令列表中取出一个口令进行解锁帐号，如果解锁成功则返回，失败则继续。方法getPassPhrase每次从众多口令中取一个口令的方式是以下部分代码实现的 ，如果口令个数大于3个的话，则每次都会取最后一个。不是很理解为何要这样做，按理说应该每个帐号对应一个口令的。😂😂😂 123456if len(passwords) &gt; 0 &#123; if i &lt; len(passwords) &#123; return passwords[i] &#125; return passwords[len(passwords)-1] &#125;]]></content>
      <categories>
        <category>HPB源码解读</category>
      </categories>
      <tags>
        <tag>HPB</tag>
        <tag>区块链</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GO-HPB源码解读--数据结构]]></title>
    <url>%2F2019%2F07%2F21%2FGO-HPB%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[#GO-HPB源码解读–数据结构区块链本身就是通过特定的机制来生成和维护数据，使数据具有极高的稳定性和可靠性。所以了解区块链，首先要必须熟悉其数据结构，然后才能更好的理解数据运算机制也就是区块链的运行原理。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849// BlockChain represents the canonical chain given a database with a genesis// block. The Blockchain manages chain imports, reverts, chain reorganisations.//// Importing blocks in to the block chain happens according to the set of rules// defined by the two stage Validator. Processing of blocks is done using the// Processor which processes the included transaction. The validation of the state// is done in the second part of the Validator. Failing results in aborting of// the import.//// The BlockChain also helps in returning blocks from **any** chain included// in the database as well as blocks that represents the canonical chain. It's// important to note that GetBlock can return any block and does not need to be// included in the canonical one where as GetBlockByNumber always represents the// canonical chain.&lt;!-- more --&gt;type BlockChain struct &#123; config *config.ChainConfig // chain &amp; network configuration hc *HeaderChain chainDb hpbdb.Database rmLogsFeed sub.Feed chainFeed sub.Feed chainSideFeed sub.Feed chainHeadFeed sub.Feed logsFeed sub.Feed scope sub.SubscriptionScope genesisBlock *types.Block mu sync.RWMutex // global mutex for locking chain operations chainmu sync.RWMutex // blockchain insertion lock procmu sync.RWMutex // block processor lock checkpoint int // checkpoint counts towards the new checkpoint currentBlock *types.Block // Current head of the block chain currentFastBlock *types.Block // Current head of the fast-sync chain (may be above the block chain!) stateCache state.Database // State database to reuse between imports (contains state cache) bodyCache *lru.Cache // Cache for the most recent block bodies bodyRLPCache *lru.Cache // Cache for the most recent block bodies in RLP encoded format blockCache *lru.Cache // Cache for the most recent entire blocks futureBlocks *lru.Cache // future blocks are blocks added for later processing quit chan struct&#123;&#125; // blockchain quit channel running int32 // running must be called atomically // procInterrupt must be atomically called procInterrupt int32 // interrupt signaler for block processing wg sync.WaitGroup // chain processing wait group for shutting down engine consensus.Engine processor Processor // block processor interface validator Validator // block and state validator interface badBlocks *lru.Cache // Bad block cache&#125; 字段 类型 含义 备注 config *config.ChainConfig 定义了chainID和监控参数 hc *HeaderChain 区块头组成的链 chainDb hpbdb.Database 数据库 rmLogsFeed sub.Feed chainFeed sub.Feed chainSideFeed sub.Feed chainHeadFeed sub.Feed logsFeed sub.Feed scope sub.SubscriptionScope genesisBlock *types.Block mu sync.RWMutex 区块链的全局锁 chainmu sync.RWMutex 区块链插入锁 procmu sync.RWMutex 区块处理的锁 checkpoint int currentBlock *types.Block 主链的头区块 currentFastBlock *types.Block 快速同步模式下链的头区块，这种情况下可能比主链长 stateCache state.Database bodyCache *lru.Cache 最近区块体的缓存信息 bodyRLPCache *lru.Cache 最近区块体的RLP格式的缓存信息 blockCache *lru.Cache 最近区块的缓存 futureBlocks *lru.Cache 将来等待上链的区块 quit chan struct{} running int32 procInterrupt int32 wg sync.WaitGroup engine consensus.Engine 验证区块的引擎 processor Processor 执行区块交易的接口 validator Validator 验证区块和state有效性的接口 badBlocks *lru.Cache 验证失败的区块缓存，来自DAO事件 关键的元素： db：连接到底层数据储存，即leveldb； hc：headerchain区块头链，由blockchain额外维护的另一条链，由于Header和Block的储存空间是有很大差别的，但同时Block的Hash值就是Header（RLP）的Hash值，所以维护一个headerchain可以用于快速延长链，验证通过后再下载blockchain，或者可以与blockchain进行相互验证； genesisBlock：创始区块； currentBlock：当前区块，blockchain中并不是储存链所有的block，而是通过currentBlock向前回溯直到genesisBlock，这样就构成了区块链。 bodyCache、bodyRLPCache、blockCache、futureBlocks：区块链中的缓存结构，用于加快区块链的读取和构建； engine：是consensus模块中的接口，用来验证block的接口； processor：执行区块链交易的接口，收到一个新的区块时，要对区块中的所有交易执行一遍，一方面是验证，一方面是更新worldState； validator：验证数据有效性的接口 futureBlocks：收到的区块时间大于当前头区块时间15s而小于30s的区块，可作为当前节点待处理的区块。 下边是区块的数据结构 12345678910111213141516171819// Block represents an entire block in the Hpb blockchain.type Block struct &#123; header *Header uncles []*Header transactions Transactions // caches hash atomic.Value size atomic.Value // Td is used by package core to store the total difficulty // of the chain up to and including the block. td *big.Int // These fields are used by package eth to track // inter-peer block relay. ReceivedAt time.Time ReceivedFrom interface&#123;&#125;&#125; 字段 类型 含义 备注 header *Header 当前区块头 uncles []*Header 叔区块，因出块速度快，导致分叉概率高，为了增加矿工挖矿积极性，对于分叉后的无用区块也进行打包，奖励矿工，那么这些无用区块就是叔区块。同时为了为了抵消整个Ethereum网络中那些计算能力特别强大的节点会对区块的产生有过大的影响力，防止这些节点破坏“去中心化”这个根本宗旨 transactions Transactions 交易集合 hash atomic.Value 区块的哈希，是从Header中缓存下来的，等于Header中的哈希值，是header中除nonce和mixDigest数据外的rlp的hash，这样相同的交易内容的相同该区块hash是一样，哪怕是由不同的节点创建出来的。区块的header和body是分开存储的，key都是前缀加上当前hash size atomic.Value td *big.Int td是totalDifficulty的缩写，表示从创世区块到当前区块的所有Difficulty之和，而每个区块的Difficulty是保存在header中的 ReceivedAt time.Time 区块生成时间 ReceivedFrom interface{} 区块生成来源 12345678910111213141516171819202122// Header represents a block header in the Hpb blockchain.type Header struct &#123; ParentHash common.Hash `json:"parentHash" ` UncleHash common.Hash `json:"sha3Uncles" ` Coinbase common.Address `json:"miner" ` CandAddress common.Address `json:"candAddress" ` ComdAddress common.Address `json:"comdAddress" ` VoteIndex *big.Int `json:"voteIndex" ` Root common.Hash `json:"stateRoot" ` TxHash common.Hash `json:"transactionsRoot" ` ReceiptHash common.Hash `json:"receiptsRoot" ` Bloom Bloom `json:"logsBloom" ` Difficulty *big.Int `json:"difficulty" ` Number *big.Int `json:"number" ` GasLimit *big.Int `json:"gasLimit" ` GasUsed *big.Int `json:"gasUsed" ` Time *big.Int `json:"timestamp" ` Extra []byte `json:"extraData" ` MixDigest common.Hash `json:"mixHash" ` Nonce BlockNonce `json:"nonce" ` HardwareRandom []byte `json:"hardwareRandom" `&#125; 字段 类型 含义 备注 ParentHash common.Hash 父区块的hash UncleHash common.Hash 叔区块的hash Coinbase common.Address 挖矿生成该区块的地址，挖矿是由节点来完成的，每个full节点都个默认的Coinbase地址，用来接收挖矿（矿工费和打包区块的奖金）奖励 CandAddress common.Address ？ ComdAddress common.Address ？ VoteIndex *big.Int 投票索引 Root common.Hash 存储账户（合约帐户和用户帐户）状态的Merkle树的根节点的哈希,StateDB中的“state Trie”的根节点的RLP哈希值。Block中，每个账户以stateObject对象表示，账户以Address为唯一标示，其信息在相关交易(Transaction)的执行中被修改。所有账户对象可以逐个插入一个Merkle-PatricaTrie(MPT)结构里，形成“state Trie”。 TxHash common.Hash Block中交易树 “tx Trie”的根节点的RLP哈希值。Block的成员变量transactions中所有的tx对象，被逐个插入一个MPT结构，形成“tx Trie”。 ReceiptHash common.Hash “Receipt Trie”的根节点的RLP哈希值。Block的所有Transaction执行完后会生成一个Receipt数组，这个数组中的所有Receipt被逐个插入一个MPT结构中，最后形成”Receipt Trie” Bloom Bloom Bloom过滤器(Filter)，用来快速判断一个参数Log对象是否存在于一组已知的Log集合中。 Difficulty *big.Int 区块的难度。Block的Difficulty由共识算法基于parentBlock的Time和Difficulty计算得出，它会应用在区块的‘挖掘’阶段。 Number *big.Int 区块的序号。Block的Number等于其父区块Number +1。 GasLimit *big.Int 区块内所有Gas消耗的上限。该数值在区块创建时赋值，与父区块的数据相关。具体来说，根据父区块的GasUsed同创世块的GasLimit * 2/3的大小关系来计算得出。 GasUsed *big.Int 区块内所有Transaction执行时所实际消耗的Gas总和。 Time *big.Int 区块“应该”被创建的时间。由共识算法确定，一般来说，要么等于parentBlock.Time + 10s，要么等于当前系统时间。区块开始打包时间戳（调用Engine.Prepare函数的时候设置） Extra []byte 扩展信息 MixDigest common.Hash 区块头除去Nonce, mixDigest数据的hash+nonce的RLP的hash值 Nonce BlockNonce 一个64bit的哈希数，它被用于POW等挖块算法，暴力碰撞得出,该哈希值与MixDigest哈希值一起证明该区块上已经进行了足够的计算，用于证明挖矿成功 HardwareRandom []byte BOE硬件随机数 1234type Body struct &#123; Transactions []*Transaction Uncles []*Header&#125; 字段 类型 含义 备注 Transactions []*Transaction 交易集合 Uncles []*Header 叔区块头集合 12345678type Transaction struct &#123; data txdata // caches hash atomic.Value size atomic.Value from atomic.Value fromP2P bool&#125; 字段 类型 含义 备注 data txdata 交易数据 hash atomic.Value size atomic.Value from atomic.Value tx的转帐转出方地址，就是对该tx对象作ECDSA签名计算时所用的公钥publicKey fromP2P bool 1234567891011121314type txdata struct &#123; AccountNonce uint64 `json:"nonce" gencodec:"required"` Price *big.Int `json:"gasPrice" gencodec:"required"` GasLimit *big.Int `json:"gas" gencodec:"required"` Recipient *common.Address `json:"to" rlp:"nil"` // nil means contract creation Amount *big.Int `json:"value" gencodec:"required"` Payload []byte `json:"input" gencodec:"required"` // Signature values V *big.Int `json:"v" gencodec:"required"` R *big.Int `json:"r" gencodec:"required"` S *big.Int `json:"s" gencodec:"required"` // This is only used when marshaling to JSON. Hash *common.Hash `json:"hash" rlp:"-"`&#125; 字段 类型 含义 备注 AccountNonce uint64 发送者发起的交易总数 Price *big.Int 交易的Gas价格 GasLimit *big.Int 交易允许消耗的最大Gas Recipient *common.Address 交易接收者地址， Amount *big.Int 交易额 Payload []byte 它既可以作为所创建合约的指令数组，其中每一个byte作为一个单独的虚拟机指令；也可以作为数据数组，由合约指令进行操作。合约由以太坊虚拟机(Ethereum Virtual Machine, EVM)创建并执行。 V *big.Int tx的数字签名（ECDSA）,是一个长度为65bytes的字节数组，它被截成三段放进tx中，前32bytes赋值给成员变量R, 再32bytes赋值给S，末1byte赋给V R *big.Int 同上 S *big.Int 同上 Hash *common.Hash 交易HAsh，只在JSON转换时使用 以上便是区块链中最主要的“区块链”数据结构，有些字段描述不是很清楚，后续再逐步完善。]]></content>
      <categories>
        <category>HPB源码解读</category>
      </categories>
      <tags>
        <tag>HPB</tag>
        <tag>区块链</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GO-HPB源码解读--节点初始化]]></title>
    <url>%2F2019%2F07%2F21%2FGO-HPB%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB-%E8%8A%82%E7%82%B9%E5%88%9D%E5%A7%8B%E5%8C%96%2F</url>
    <content type="text"><![CDATA[#GO-HPB源码解读–节点初始化HPB在创建帐号时使用的命令是 ./ghpb --datadir node/data init gensis.json通过代码看下节点初始化做了什么事情 init命令定义在chaincmd.go文件中，关于urfave和utils.MigrateFlags在创建帐号中做过说明，这里直接看下initGenesis做了什么事情。 initGenesis方法流程： MakeConfigNode方法配置节点的默认参数信息，这个时候如果很多参数没有通过命令很输入进来，程序会把所有的参数信息设置为默认值 加载文件gensis.json文件，文件名通过init的flag参数输入进行。后边我们对gensis.json文件解读一下。 创建bc.Genesis对象，然后通过gensis.json文件的信息进行赋值 db.OpenDatabase创建数据库 bc.SetupGenesisBlockf进行初始块的生成和写入文件 github.com\hpb-project\go-hpb\cmd\chaincmd.go 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051 initCommand = cli.Command&#123; Action: utils.MigrateFlags(initGenesis), Name: "init", Usage: "Bootstrap and initialize a new genesis block", ArgsUsage: "&lt;genesisPath&gt;", Flags: []cli.Flag&#123; utils.DataDirFlag, utils.LightModeFlag, &#125;, Category: "BLOCKCHAIN COMMANDS", Description: ``, &#125; // initGenesis will initialise the given JSON format genesis file and writes it as// the zero'd block (i.e. genesis) or will fail hard if it can't succeed.func initGenesis(ctx *cli.Context) error &#123; // Open an initialise both full and light databases //stack, _ := MakeConfigNode(ctx) MakeConfigNode(ctx) // Make sure we have a valid genesis JSON genesisPath := ctx.Args().First() if len(genesisPath) == 0 &#123; utils.Fatalf("Must supply path to genesis JSON file") &#125; file, err := os.Open(genesisPath) if err != nil &#123; log.Warn("genesis path is %s", genesisPath) utils.Fatalf("Failed to read genesis file: %v", err) &#125; defer file.Close() genesis := new(bc.Genesis) if err := json.NewDecoder(file).Decode(genesis); err != nil &#123; utils.Fatalf("invalid genesis file: %v", err) &#125; for _, name := range []string&#123;"chaindata"&#125; &#123; chaindb, err := db.OpenDatabase(name, 0, 0) if err != nil &#123; utils.Fatalf("Failed to open database: %v", err) &#125; _, hash, err := bc.SetupGenesisBlock(chaindb, genesis) if err != nil &#123; utils.Fatalf("Failed to write genesis block: %v", err) &#125; log.Info("Successfully wrote genesis state", "database", name, "hash", hash) &#125; return nil&#125; 看下创建数据库的代码，数据库实例通过atomic.Value{}来实现线程安全操作。当没有传入–datadir参数时，会直接返回内存数据库,否则会创建chaindata数据库文件。ResolvePath方法会在chaindata路径前加个ghpb路径。数据库使用的是Google的levelDB, 123456789101112131415161718192021// OpenDatabase opens an existing database with the given name (or creates one// if no previous can be found) from within the node's data directory. If the// node is an ephemeral one, a memory database is returned.func OpenDatabase(name string, cache int, handles int) (hpbdb.Database, error) &#123; if DBINSTANCE.Load() != nil &#123; return DBINSTANCE.Load().(*hpbdb.LDBDatabase),nil &#125; var cfg = config.GetHpbConfigInstance() if cfg.Node.DataDir == ""&#123; return hpbdb.NewMemDatabase() &#125; db, err := hpbdb.NewLDBDatabase(cfg.Node.ResolvePath(name), cache, handles) if err != nil &#123; return nil, err &#125; DBINSTANCE.Store(db) return db, nil&#125; SetupGenesisBlock方法主要是对初始区块的文件写入。 GetCanonicalHash(db, 0)首先从数据库获取第0个hash，如果没有则返回一个初始hash，即[32]byte{0} 把初始的genesis信息生成初始区块提交到数据库 … … …后续再读 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758func SetupGenesisBlock(db hpbdb.Database, genesis *Genesis) (*config.ChainConfig, common.Hash, error) &#123; if genesis != nil &amp;&amp; genesis.Config == nil &#123; return config.MainnetChainConfig, common.Hash&#123;&#125;, errGenesisNoConfig &#125; // Just commit the new block if there is no stored genesis block. stored := GetCanonicalHash(db, 0) if (stored == common.Hash&#123;&#125;) &#123; if genesis == nil &#123; genesis = DefaultGenesisBlock() &#125; else &#123; log.Info("Writing custom genesis block") &#125; block, err := genesis.Commit(db) return genesis.Config, block.Hash(), err &#125; // Check whether the genesis block is already written. if genesis != nil &#123; block, _ := genesis.ToBlock() hash := block.Hash() if hash != stored &#123; return genesis.Config, block.Hash(), &amp;GenesisMismatchError&#123;stored, hash&#125; &#125; &#125; // Get the existing chain configuration. newcfg := genesis.configOrDefault(stored) storedcfg, err := GetChainConfig(db, stored) if err != nil &#123; if err == ErrChainConfigNotFound &#123; // This case happens if a genesis write was interrupted. log.Warn("Found genesis block without chain config") err = WriteChainConfig(db, stored, newcfg) &#125; return newcfg, stored, err &#125; // Special case: don't change the existing config of a non-mainnet chain if no new // config is supplied. These chains would get AllProtocolChanges (and a compat error) // if we just continued here. if genesis == nil &amp;&amp; stored != config.MainnetGenesisHash &#123; return storedcfg, stored, nil &#125; // Check config compatibility and write the config. Compatibility errors // are returned to the caller unless we're already at block zero. height := GetBlockNumber(db, GetHeadHeaderHash(db)) if height == missingNumber &#123; return newcfg, stored, fmt.Errorf("missing block number for head header hash") &#125; compatErr := storedcfg.CheckCompatible(newcfg, height) if compatErr != nil &amp;&amp; height != 0 &amp;&amp; compatErr.RewindTo != 0 &#123; return newcfg, stored, compatErr &#125; return newcfg, stored, WriteChainConfig(db, stored, newcfg)&#125; genesis.Commit(db)方法中，首先将genesis转化成一个区块，然后再将区块信息写入数据库，同时包含其他一些数据内容，比如blockReceipts、GetCanonicalHash,WriteHeadBlockHash等等。此时已接触到初始block，后续文章我们对相关数据结构进行详细说明 1234567891011121314151617181920212223242526272829303132333435// Commit writes the block and state of a genesis specification to the database.// The block is committed as the canonical head block.func (g *Genesis) Commit(db hpbdb.Database) (*types.Block, error) &#123; block, statedb := g.ToBlock() if block.Number().Sign() != 0 &#123; return nil, fmt.Errorf("can't commit genesis block with number &gt; 0") &#125; if _, err := statedb.CommitTo(db, false); err != nil &#123; return nil, fmt.Errorf("cannot write state: %v", err) &#125; if err := WriteTd(db, block.Hash(), block.NumberU64(), g.Difficulty); err != nil &#123; return nil, err &#125; if err := WriteBlock(db, block); err != nil &#123; return nil, err &#125; if err := WriteBlockReceipts(db, block.Hash(), block.NumberU64(), nil); err != nil &#123; return nil, err &#125; if err := WriteCanonicalHash(db, block.Hash(), block.NumberU64()); err != nil &#123; return nil, err &#125; if err := WriteHeadBlockHash(db, block.Hash()); err != nil &#123; return nil, err &#125; if err := WriteHeadHeaderHash(db, block.Hash()); err != nil &#123; return nil, err &#125; configtemp := g.Config if configtemp == nil &#123; configtemp = config.MainnetChainConfig &#125; return block, WriteChainConfig(db, block.Hash(), configtemp)&#125;]]></content>
      <categories>
        <category>HPB源码解读</category>
      </categories>
      <tags>
        <tag>HPB</tag>
        <tag>区块链</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GO-HPB源码解读--创建帐号]]></title>
    <url>%2F2019%2F07%2F21%2FGO-HPB%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB-%E5%88%9B%E5%BB%BA%E5%B8%90%E5%8F%B7%2F</url>
    <content type="text"><![CDATA[#GO-HPB源码解读–创建帐号HPB在创建帐号时使用的命令是 ./ghpb --datadir node/data account init通过代码看下创建流程 go-hpb源码命令架构使用的是urfave/cli，不知道是不是这样读这个名称：you are 废物，这里有个不错的帖子介绍，可以学习下。主要对命令进行了封装，我们主要关心命令所对应的业务实现逻辑即可，使用起来非常方便。阅读也从这个地方开始。 account命令定义在accountcmd.go文件中，通过源码可以看到account命令有list、new、update、import四个子命令。每一个命令都有flags参数。 github.com\hpb-project\go-hpb\cmd\accountcmd.go 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556accountCommand = cli.Command&#123; Name: "account", Usage: "Manage accounts", Category: "ACCOUNT COMMANDS", Description: ``, Subcommands: []cli.Command&#123; &#123; Name: "list", Usage: "Print summary of existing accounts", Action: utils.MigrateFlags(accountList), Flags: []cli.Flag&#123; utils.DataDirFlag, utils.KeyStoreDirFlag, &#125;, Description: `Print a short summary of all accounts`, &#125;, &#123; Name: "new", Usage: "Create a new account", Action: utils.MigrateFlags(accountCreate), Flags: []cli.Flag&#123; utils.DataDirFlag, utils.KeyStoreDirFlag, utils.PasswordFileFlag, utils.LightKDFFlag, &#125;, Description: ``, &#125;, &#123; Name: "update", Usage: "Update an existing account", Action: utils.MigrateFlags(accountUpdate), ArgsUsage: "&lt;address&gt;", Flags: []cli.Flag&#123; utils.DataDirFlag, utils.KeyStoreDirFlag, utils.LightKDFFlag, &#125;, Description: ``, &#125;, &#123; Name: "import", Usage: "Import a private key into a new account", Action: utils.MigrateFlags(accountImport), Flags: []cli.Flag&#123; utils.DataDirFlag, utils.KeyStoreDirFlag, utils.PasswordFileFlag, utils.LightKDFFlag, &#125;, ArgsUsage: "&lt;keyFile&gt;", Description: `, &#125;, &#125;, &#125;) 现在主要看一下new这个子命令，Action属性主要用来指定new命令的所需要执行的动作。这里可以看到是utils.MigrateFlags(accountCreate)， MigrateFlags方法是把account命令的flag参数设置到全局参数里。比如命令hpb account new –keystore /tmp/mykeystore –lightkdf是等价于hpb –keystore /tmp/mykeystore –lightkdf account new。主要的业务实现需要查看accountCreate 123456789101112&#123; Name: "new", Usage: "Create a new account", Action: utils.MigrateFlags(accountCreate), Flags: []cli.Flag&#123; utils.DataDirFlag, utils.KeyStoreDirFlag, utils.PasswordFileFlag, utils.LightKDFFlag, &#125;, Description: ``,&#125;, accountCreate方法首先初始化节点配置对象，并实例化一下节点对象,getPassPhrase接收一个用户输入的口令。接下来通过口令参数生成用户帐户信息. 12345678910111213141516171819202122// accountCreate creates a new account into the keystore defined by the CLI flags.func accountCreate(ctx *cli.Context) error &#123; //进行节点参数配置 cfg := MakeConfigNode(ctx) //创建节点实例 stack, err := createNode(cfg) if err != nil &#123; utils.Fatalf("Failed to create node") return err &#125; //接收用户输入的口令 password := getPassPhrase("Your new account is locked with a password. Please give a password. Do not forget this password.", true, 0, utils.MakePasswordList(ctx)) //创建一个keyStore ks := stack.AccountManager().KeyStore().(*keystore.KeyStore) //使用口令对keyStore信息进行加密，并返回一个帐户地址 account, err := ks.NewAccount(password) if err != nil &#123; utils.Fatalf("Failed to create account: %v", err) &#125; fmt.Printf("Address: &#123;%x&#125;\n", account.Address) return nil&#125; NewAccount方法用来生成一个密钥，并把他保存在文件中，也就是命令执行后生成的文件，比如node/data/keystore/UTC–2018-11-25T14-05-44.446434210Z–a0603b3443c89a6e2eff7614acec5a59f9f70ebb。生成之后返回的account需要加载到当前cache里，并刷新wallet信息 1234567891011121314// NewAccount generates a new key and stores it into the key directory,// encrypting it with the passphrase.func (ks *KeyStore) NewAccount(passphrase string) (accounts.Account, error) &#123; _, account, err := storeNewKey(ks.storage, crand.Reader, passphrase) if err != nil &#123; return accounts.Account&#123;&#125;, err &#125; // Add the account to the cache immediately rather // than waiting for file system notifications to pick it up. ks.cache.add(account) ks.refreshWallets() return account, nil&#125; 关键方法storeNewKey，第一步newKey会随机生成非对称密钥，使用的是大名顶顶的ECDSA算法。然后创建 一个account对象，并进行保存。保存完成需要把当前内存信息进行清除，以防安全隐患。 123456789101112func storeNewKey(ks keyStore, rand io.Reader, auth string) (*Key, accounts.Account, error) &#123; key, err := newKey(rand) if err != nil &#123; return nil, accounts.Account&#123;&#125;, err &#125; a := accounts.Account&#123;Address: key.Address, URL: accounts.URL&#123;Scheme: KeyStoreScheme, Path: ks.JoinPath(keyFileName(key.Address))&#125;&#125; if err := ks.StoreKey(a.URL.Path, key, auth); err != nil &#123; zeroKey(key.PrivateKey) return nil, a, err &#125; return key, a, err&#125; newKey方法生成非对称密钥，并转成一个用户帐户信息，主要是需要通过公钥生成一个用户帐户地址，在newKeyFromECDSA方法里，可以看到的是ECDSA.PublicKey生成Address 1234567891011121314151617func newKey(rand io.Reader) (*Key, error) &#123; privateKeyECDSA, err := ecdsa.GenerateKey(crypto.S256(), rand) if err != nil &#123; return nil, err &#125; return newKeyFromECDSA(privateKeyECDSA), nil&#125;func newKeyFromECDSA(privateKeyECDSA *ecdsa.PrivateKey) *Key &#123; id := uuid.NewRandom() key := &amp;Key&#123; Id: id, Address: crypto.PubkeyToAddress(privateKeyECDSA.PublicKey), PrivateKey: privateKeyECDSA, &#125; return key&#125; StoreKey主要完成非对称密钥通过用户输入口令进行加密保存到文件 1234567func (ks keyStorePassphrase) StoreKey(filename string, key *Key, auth string) error &#123; keyjson, err := EncryptKey(key, auth, ks.scryptN, ks.scryptP) if err != nil &#123; return err &#125; return writeKeyFile(filename, keyjson)&#125; 文件保存后，业务就基本完成，程序退出执行。]]></content>
      <categories>
        <category>HPB源码解读</category>
      </categories>
      <tags>
        <tag>HPB</tag>
        <tag>区块链</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2019%2F07%2F20%2Fhello-world%2F</url>
    <content type="text"><![CDATA[摘要显示 Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
</search>
