<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[RabbitMQ]]></title>
    <url>%2F2019%2F11%2F13%2FRabbitMQ%2F</url>
    <content type="text"><![CDATA[消息模式以下每种模式的测试代码请参考工程（https://github.com/buff0000/CodeDiary/tree/master/CD-RabbitMQ-JavaClient） 简单模式 工作队列模式 订阅发布模式 路由模式 通配符模式 RPC模式 消息可靠机制图片原文件rabbit-mq.png 队列参数（一共10个）Message TTL : 消息生存期 一个队列中的消息,在被丢弃之前能够存活多少毫秒.( key 为 “x-message-ttl”).通俗讲就是,队列中的消息的生存周期,单位毫秒. Auto expire : 队列生存期 队列多长时间(毫秒)没有被使用(访问)就会被删除.换个说法就是,当队列在指定的时间内没有被使用(访问)就会被删除. Max length : 队列可以容纳的消息的最大条数 队列可以容纳的消息的最大条数,超过这个条数,队列头部的消息将会被丢弃. Max length bytes : 队列可以容纳的消息的最大字节数 队列可以容纳的消息的最大字节数,超过这个字节数,队列头部的消息将会被丢弃. Overflow behaviour : 队列中的消息溢出后如何处理 队列中的消息溢出时,如何处理这些消息.要么丢弃队列头部的消息,要么拒绝接收后面生产者发送过来的所有消息.( 从上面两个参数的测试中可以看出,”drop-head” 应该是默认行为) ,官方只给了 value,没给 key . key 为 “x-overflow”. Dead letter exchange : 溢出的消息需要发送到绑定该死信交换机的队列 该参数值为一个(死信)交换机的名称,当队列中的消息的生存期到了,或者因长度限制被丢弃时,消息会被推送到(绑定到)这台交换机(的队列中),而不是直接丢掉. Dead letter routing key : 溢出的消息需要发送到绑定该死信交换机,并且路由键匹配的队列 和Dead letter exchange结合使用 Maximum priority : 最大优先级 设置该队列中的消息的优先级最大值.发布消息的时候,可以指定消息的优先级,优先级高的先被消费.如果没有设置该参数,那么该队列不支持消息优先级功能.也就是说,就算发布消息的时候传入了优先级的值,也不会起什么作用. Lazy mode : 懒人模式 设置队列为懒人模式.该模式下的队列会先将交换机推送过来的消息(尽可能多的)保存在磁盘上,以减少内存的占用.当消费者开始消费的时候才加载到内存中;如果没有设置懒人模式,队列则会直接利用内存缓存,以最快的速度传递消息. *Master locator : * 集群相关参数 MQ集群关于集群的描述转载自RabbitMQ集群原理介绍。以下是粘贴转载内容。 一、RabbitMQ默认集群原理RabbitMQ本身是基于Erlang编写，Erlang语言天生具备分布式特性（通过同步Erlang集群各节点的erlang.cookie来实现）。因此，RabbitMQ天然支持集群。集群是保证可靠性的一种方式，同时可以通过水平扩展以达到增加消息吞吐量能力的目的。 下图为集群的示例：上面图中采用三个节点组成了一个RabbitMQ的集群，Exchange A（交换器）的元数据信息在所有节点上是一致的，而Queue（存放消息的队列）的完整数据则只会存在于它所创建的那个节点上。，其他节点只知道这个queue的metadata信息和一个指向queue的owner node的指针。 RabbitMQ集群元数据的同步RabbitMQ集群会始终同步四种类型的内部元数据： 队列元数据：队列名称和它的属性 交换器元数据：交换器名称、类型和属性 绑定元数据：一张简单的表格展示了如何将消息路由到队列 vhost元数据：为vhost内的队列、交换器和绑定提供命名空间和安全属性 因此，当用户访问其中任何一个RabbitMQ节点时，通过rabbitmqctl查询到的queue／user／exchange/vhost等信息都是相同的。 为何RabbitMQ集群仅采用元数据同步的方式第一，存储空间。如果每个集群节点都拥有所有Queue的完全数据拷贝，那么每个节点的存储空间会非常大，集群的消息积压能力会非常弱（无法通过集群节点的扩容提高消息积压能力）； 第二，性能。消息的发布者需要将消息复制到每一个集群节点，对于持久化消息，网络和磁盘同步复制的开销都会明显增加。 RabbitMQ集群发送/订阅消息的基本原理RabbitMQ集群的工作原理图如下： 客户端直接连接队列所在节点如果有一个消息生产者或者消息消费者通过amqp-client的客户端连接至节点1进行消息的发布或者订阅，那么此时的集群中的消息收发只与节点1相关。 客户端连接的是非队列数据所在节点如果消息生产者所连接的是节点2或者节点3，此时队列1的完整数据不在该两个节点上，那么在发送消息过程中这两个节点主要起了一个路由转发作用，根据这两个节点上的元数据转发至节点1上，最终发送的消息还是会存储至节点1的队列1上。同样，如果消息消费者所连接的节点2或者节点3，那这两个节点也会作为路由节点起到转发作用，将会从节点1的队列1中拉取消息进行消费。 集群节点类型磁盘节点将配置信息和元信息存储在磁盘上（单节点系统必须是磁盘节点，否则每次重启RabbitMQ之后所有的系统配置信息都会丢失）。 内存节点将配置信息和元信息存储在内存中。性能是优于磁盘节点的。 RabbitMQ要求集群中至少有一个磁盘节点，当节点加入和离开集群时，必须通知磁盘节点（如果集群中唯一的磁盘节点崩溃了，则不能进行创建队列、创建交换器、创建绑定、添加用户、更改权限、添加和删除集群节点）。总之如果唯一磁盘的磁盘节点崩溃，集群是可以保持运行的，但不能更改任何东西。因此建议在集群中设置两个磁盘节点，只要一个可以，就能正常操作。 总结普通集群模式，并不保证队列的高可用性。尽管交换机、绑定这些可以复制到集群里的任何一个节点，但是队列内容不会复制。虽然该模式解决一项目组节点压力，但队列节点宕机直接导致该队列无法应用，只能等待重启。所以要想在队列节点宕机或故障也能正常应用，就要复制队列内容到集群里的每个节点，必须要创建镜像队列。 二、RabbitMQ镜像队列原理镜像队列是基于普通的集群模式的，然后再添加一些策略，所以还是得先配置普通集群，然后才能设置镜像队列。镜像队列存在于多个节点。要实现镜像模式，需要先搭建一个普通集群模式，在这个模式的基础上再配置镜像模式以实现高可用。 镜像队列的结构 镜像队列基本上就是一个特殊的BackingQueue，它内部包裹了一个普通的BackingQueue做本地消息持久化处理，在此基础上增加了将消息和ack复制到所有镜像的功能。所有对mirror_queue_master的操作，会通过可靠组播GM的方式同步到各slave节点。GM负责消息的广播，mirror_queue_slave负责回调处理，而master上的回调处理是由coordinator负责完成。mirror_queue_slave中包含了普通的BackingQueue进行消息的存储，master节点中BackingQueue包含在mirror_queue_master中由AMQQueue进行调用。 消息的发布（除了Basic.Publish之外）与消费都是通过master节点完成。master节点对消息进行处理的同时将消息的处理动作通过GM广播给所有的slave节点，slave节点的GM收到消息后，通过回调交由mirror_queue_slave进行实际的处理。 对于Basic.Publish，消息同时发送到master和所有slave上，如果此时master宕掉了，消息还发送slave上，这样当slave提升为master的时候消息也不会丢失。 GM（Guarenteed Multicast）GM模块实现的一种可靠的组播通讯协议，该协议能够保证组播消息的原子性，即保证组中活着的节点要么都收到消息要么都收不到。 它的实现大致如下： 将所有的节点形成一个循环链表，每个节点都会监控位于自己左右两边的节点，当有节点新增时，相邻的节点保证当前广播的消息会复制到新的节点上；当有节点失效时，相邻的节点会接管保证本次广播的消息会复制到所有的节点。在master节点和slave节点上的这些gm形成一个group，group（gm_group）的信息会记录在mnesia中。不同的镜像队列形成不同的group。消息从master节点对于的gm发出后，顺着链表依次传送到所有的节点，由于所有节点组成一个循环链表，master节点对应的gm最终会收到自己发送的消息，这个时候master节点就知道消息已经复制到所有的slave节点了。 新增节点新节点的加入过程如下图所示：每当一个节点加入或者重新加入（例如从网络分区中恢复过来）镜像队列，之前保存的队列内容会被清空。 节点的失效如果某个slave失效了，系统处理做些记录外几乎啥都不做。master依旧是master，客户端不需要采取任何行动，或者被通知slave失效。 如果master失效了，那么slave中的一个必须被选中为master。被选中作为新的master的slave通常是最老的那个，因为最老的slave与前任master之间的同步状态应该是最好的。然而，需要注意的是，如果存在没有任何一个slave与master完全同步的情况，那么前任master中未被同步的消息将会丢失。 消息的同步将新节点加入已存在的镜像队列是，默认情况下ha-sync-mode=manual，镜像队列中的消息不会主动同步到新节点，除非显式调用同步命令。当调用同步命令后，队列开始阻塞，无法对其进行操作，直到同步完毕。 当ha-sync-mode=automatic时，新加入节点时会默认同步已知的镜像队列。由于同步过程的限制，所以不建议在生产的消费队列中操作。 总结镜像节点在集群中的其他节点拥有从队列拷贝，一旦主节点不可用，最老的从队列将被选举为新的主队列。但镜像队列不能作为负载均衡使用，因为每个操作在所有节点都要做一遍。该模式带来的副作用也很明显，除了降低系统性能外，如果镜像队列数量过多，加之大量的消息进入，集群内部的网络带宽将会被这种同步通讯大大消耗掉。所以在对可靠性要求较高的场合中适用。]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>MQ</tag>
        <tag>中间件</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[手写AQS]]></title>
    <url>%2F2019%2F11%2F10%2F%E6%89%8B%E5%86%99AQS%2F</url>
    <content type="text"><![CDATA[网上看了视频，讲解的比较好，特此记录，加深记忆。 1234567891011ReentrantLock syn = new ReentrantLock();public void func()&#123; syn.lock(); ... syn.unLock();&#125; 首先定义一个自己的lock。public class CustomLock{ } 当有10个线程分别是T1，T2，T3… … T10，假为T1获得锁，那个其他线程在执行到syn.lock()的地方，肯定是停在这个地方等T1释放锁了。那这个停的行为怎么实现呢？ this.wait()，这种方式先不考虑，因为他是基于object.monitor()实现的。也就是synchronized原理。 sleep，无法知道睡多久？ park，相当于wait–一同样无法知道什么时候唤醒其实我们的目标是把线程的停在lock方法里，不让他出来，这样就达到阻塞的效果了。这时就可以使用自旋，即for(;;){}123456789101112public class CustomLock&#123; public void lock()&#123; //this.wait() //sleep //park //所有线程进行循环，只有拿到锁的线程才可以跳出for循环 for(;;)&#123; &#125; &#125;&#125; – 自旋不是一直占用CPU吗？怎么让渡CPU呢？ 怎么设计互斥锁，任意时刻只有一个人能执行成功，要求原子性。这时就需要用到CAS操作，由操作系统提供的方法。 首先需要定义一个状态status，获取锁的过程，也就是把status修改为1的过程。 通过CAS操作进行status的竞争 另外需要把当前线程，也就是当前获取锁的线程保存一下123456789101112131415161718192021public boolean acquire()&#123; Thread t = Thread.currentThread(); if(compareAndSwapState(0,1))&#123; setLockHolder(t); return true; &#125; return false;&#125;public void lock()&#123; if(acquire())&#123; return ; &#125; for(;;)&#123; if(acquire())&#123;//在循环里竞争锁 break; &#125; &#125;&#125; 由于for(;;)中，一直占用CPU，这很浪费资源。有什么办法呢？ 这个时候其实可以修改线程状态，通过LockSupport.park()，永久park。通过unpark解锁,也就需要定义个unlock方法。如果使用wait，唤醒是随即的，不通达到公平锁的要求 123456789101112131415161718 public void lock()&#123; if(acquire())&#123; return ; &#125; for(;;)&#123; if(acquire())&#123;//在循环里竞争锁 break; &#125; LockSupport.park() &#125; public void unlock()&#123; LockSupport.unpark() &#125;&#125; 由于unpark的线程时，需要确定的是哪个线程，所以当多个线程在竞争锁时，如果没拿到锁，那个就都需要保存到一个队列里，等待上一个线程释放锁时唤醒。但是这个队列不能使用阻塞队列，因为阻塞队列也是基于AQS实现的。这里使用ConcurrentLinkedQueue，线程安全，但不是阻塞的。 123456789101112131415161718192021222324252627282930313233343536373839404142434445ConcurrentLinkedQueue&lt;Thread&gt; aiters = new ConcurrentLinkedQueue(); public void lock()&#123; if(acquire())&#123; return ; &#125; Thread current = Thread.currentThread(); waiters.add(current); for(;;)&#123; if(acquire())&#123;//在循环里竞争锁 break; &#125; LockSupport.park() &#125; public void unlock()&#123; LockSupport.unpark() &#125; &#125;6. 再看下解锁 * 首先判断下释放锁的线程是不是保存的获取锁的线程 * 通过CAS把锁的状态修改为0，即解锁，同时要把线程holder置空，并且从等待队列中取一个线程进行解锁 ```JAVA public void unlock()&#123; if(Thread.currentThread != lockHolder)&#123; throw new RuntimeExcption("不是当前线程持有的锁"); &#125; int state = getState(); if(compareAndSwapState(state,0))&#123; setLockHolder(null); Thread t = waiters.peek(); if (t != null)&#123; LockSupport.unpark(t); &#125; &#125; &#125; 这里再看lock的过程，在unlock方法中已经把队列中等待的第一个线程unpark了。所以在lock方法中，在acquire成功时，要移除这个线程，并return。 123456789101112131415161718192021222324public void lock()&#123;if(acquire())&#123; return ;&#125;Thread current = Thread.currentThread();waiters.add(current);for(;;)&#123; /* if(acquire())&#123;//在循环里竞争锁 break; &#125; */ if(current == waiters.peek() &amp;&amp; acquire())&#123; waiters.poll(); return; &#125; LockSupport.park()&#125; 还有个问题，如果队列不是空的，那么进来的线程应该去排队，而不是直接获取锁。由于acquire方法初始了在lock一开始执行，还在for(;;)中执行，这个时候假如T2在获取锁时，由于他是在队列里的，这个时候判断waiters==0永远不会成功 12345678public boolean acquire()&#123; Thread t = Thread.currentThread(); if((waiters.size == 0 || current == waiters.peek()) &amp;&amp; compareAndSwapState(0,1))&#123; setLockHolder(t); return true; &#125; return false;&#125; 另外我们补充一下park方法获取的代码 123456789101112131415public final boolean compareAndSwapState(int except, int update)&#123; return unsafe.compareAndSwapInt(this,stateOffset, except, update);&#125;private static final Unsafe unsafe = UnsafeInstance.reflectGetUnsafe();private static final long stateOffset;static&#123; try&#123; stateOffset = unsafe.objectFieldOffset(CustomLock.class.getDeclareField("state")) &#125;catch(Exception e)&#123; throw new Error(); &#125;&#125; 如果LockSupport.park执行时，线程被中断了怎么办？t.interrupt()—-这块比较复杂，可再研究 总结AQS = 自旋 + CAS + LockSupportAQL具备：阻塞等待队列、共享/独占、公平/非公司、可重入、允许中断]]></content>
      <categories>
        <category>JAVA并发编程</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
        <tag>并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发--volatile]]></title>
    <url>%2F2019%2F11%2F09%2FJava%E5%B9%B6%E5%8F%91-volatile%2F</url>
    <content type="text"><![CDATA[volatile特性 保证了不同线程对这个变量进行操作时的可见性，即一个线程修改了某个变量的值，这新值对其他线程来说是立即可见的。（实现可见性） 禁止进行指令重排序。（实现有序性） volatile 只能保证对单次读/写的原子性（有限的原子性）。i++ 这种操作不能保证原子性。同步64位int/long的写操作也不具有原子性。 可见性实现volatile变量在编译后，会插入一条lock指令，其作用是将当前处理器缓存行的数据写回到系统内存。同时写回内存的操作会使在其他 CPU 里缓存了该内存地址的额数据无效。这样当其他处理器在读取该变量时就会从系统内存中直接读取，得到最新值。早期处理器是通过对总线进行锁定，这样其他CPU对内存的都会被阻塞，直到锁释放。 后来通过高速缓存锁代替总线锁来处理，缓存一致性（MESI）有多种，常用的就是“嗅探（snooping）” 协议。就是不停在嗅探总线上发生的数据交换，跟踪其他缓存在做什么。当一个缓存代表它所属的处理器去读写内存时，其它处理器都会得到通知，它们以此来使自己的缓存保持同步。 有序性实现happens-beforehappens-before 规则中有一条是 volatile 变量规则：对一个 volatile 域的写，happens-before 于任意后续对这个 volatile 域的读。 内存屏障 为了性能优化，JMM 在不改变正确语义的前提下，会允许编译器和处理器对指令序列进行重排序 Java 编译器会在生成指令系列时在适当的位置会插入内存屏障指令来禁止特定类型的处理器重排序。 是否能重排序 第二个操作 第一个操作 - 普通读写 volatile读 volatile写 普通读写 NO volatile读 NO NO NO volatile写 NO NO 其中JMM针对volatile采取的策略是在前面和后面分别插入内存屏障，而 volatile 读操作是在后面插入两个内存屏障。 在每个 volatile 写操作的前面插入一个 StoreStore 屏障（禁止上面的普通写和下面的 volatile 写重排序）。 在每个 volatile 写操作的后面插入一个 StoreLoad 屏障（防止上面的 volatile 写与下面可能有的 volatile 读/写重排序）。 在每个 volatile 读操作的后面插入一个 LoadLoad 屏障（禁止下面所有的普通读操作和上面的 volatile 读重排序）。 在每个 volatile 读操作的后面插入一个 LoadStore 屏障（禁止下面所有的普通写操作和上面的 volatile 读重排序）。 其中StoreLaod屏障，它是确保可见性的关键，因为它会将屏障之前的写缓冲区中的数据全部刷新到主内存中。另外volatile写后面有StoreLoad屏障，此屏障的作用是避免volatile写与后面可能有的读或写操作进行重排序。因为编译器常常无法准确判断在一个volatile写的后面是否需要插入一个StoreLoad屏障（比如，一个volatile写之后方法立即return）为了保证能正确实现volatile的内存语义，JMM采取了保守策略：在每个volatile写的后面插入一个StoreLoad屏障。下边是volatile读的顺序 原子性如果对volatile变量的操作只有只有简单的读和写，那么可确保原子性。比如volatile变量i进行这些操作i++、 i=b;。这是由于i++本质是i = i+ 1;其操作过程需要读取i，然后加1，然后写给i，包含多个操作步骤，同样对于i=b，先要读取b的值，然后写给i。还有一点就是64位的long/int的写操作同样不是原子性，他是分为两次32位的操作完成，也不具备原子性。还有if(i == true)，也是两步操作，先是读取i，然后再做比较 使用根据以上特性，由于是原子性的描述，正确使用volatile时，需要确保以下两点（其实就针对原子性的操作）： 对变量的写操作不依赖于当前值。 该变量没有包含在具有其他变量的不变式中。 标态标志1234567891011volatile boolean shutdownRequested;...public void shutdown() &#123; shutdownRequested = true; &#125;public void doWork() &#123; while (!shutdownRequested) &#123; // do stuff &#125;&#125; 一次性安全发布（one-time safe publication）12345678910111213141516171819public class BackgroundFloobleLoader &#123; public volatile Flooble theFlooble; public void initInBackground() &#123; // do lots of stuff theFlooble = new Flooble(); // this is the only write to theFlooble &#125;&#125;public class SomeOtherClass &#123; public void doWork() &#123; while (true) &#123; // do some stuff... // use the Flooble, but only if it is ready if (floobleLoader.theFlooble != null) doSomething(floobleLoader.theFlooble); &#125; &#125;&#125; 这种模式有些疑问，先看下关于单例中双重检查的分析。 单例User user=new User(“男”，26)；该语句做了几件事： 因为new用到了User.class，所以找到User.class文件并加载到内存中 执行该类的static代码块，如果有的话，给User.class类进行初始化 在堆内存中开辟空间，分配内存地址。 在堆内存中建立对象的特有属性，并进行默认初始化。 对属性进行显式初始化 对对象进行构造代码块初始化 对对象进行对应的构造函数初始化 将内存地址赋给栈内存中的p变量特别注意，步骤7和步骤8，先后发生顺序是随机的，或者说不确定性。 饿汉式单例12345678910public class Singleton&#123; private static Singleton instance = new Singleton(); private Singleton()&#123; … &#125; public static Singleton getInstance()&#123; return instance; &#125;&#125; 在类加载时就创建好实例了，但是不一定使用,所以可能造成资源浪费。如果创建这个类需要很多的系统资源，则浪费更严重。 懒汉式单例1234567891011public class Singleton&#123; private static Singleton instance = null; private Singleton()&#123; … &#125; public static Singleton getInstance()&#123; if (instance == null) instance = new Singleton(); return instance; &#125;&#125; 这种方式存在线程安全问题， A进入if判断，此时instance为null，因此进入if内 B进入if判断，此时A还没有创建instance，因此instance也为null，因此B也进入if内 A创建了一个instance并返回 B也创建了一个instance并返回如果在方法上加上synchronized，则每次获取对象时都有锁同步，影响效率12345public static synchronized Singleton getInstance()&#123; if (instance == null) instance = new Singleton(); return instance;&#125; 于是有人提出了双重检查的方式，这种方式如果在new对象时的执行顺序7和8发生变量，则会得到一个不完事的对象，所以也存在问题， 123456789101112131415161718192021public static Singleton getInstance()&#123; if (instance == null) synchronized(instance)&#123; if(instance == null) instance = new Singleton(); &#125; return instance;&#125;//使用内部类方式public class Singleton&#123; private Singleton()&#123; … &#125; private static class SingletonContainer&#123; private static Singleton instance = new Singleton(); &#125; public static Singleton getInstance()&#123; return SingletonContainer.instance; &#125;&#125; Doug Lea发表意见Doug Lea 在他的文章中写道：“根据最新的 JSR133 的 Java 内存模型，如果将引用类型声明为 volatile，双重检查模式就可以工作了” 12// 在引用类型声明加上volatile关键字private volatile static Singleton instance = null; 所以文章中关于一次性安全发布（one-time safe publication）的示例是没问题的，虚惊一场。 独立观察（independent observation）这种模式主要是利用了可见性，关键点在于last这个字眼，目标是获取最后的状态，只要修改了volatile变量，那他就是最新的，也就是最last的，就达到目的了。 12345678910111213public class UserManager &#123; public volatile String lastUser; public boolean authenticate(String user, String password) &#123; boolean valid = passwordIsValid(user, password); if (valid) &#123; User u = new User(); activeUsers.add(u); lastUser = user; &#125; return valid; &#125;&#125; “volatile bean” 模式JavaBean 的所有数据成员都是 volatile 类型的，并且 getter 和 setter 方法必须非常普通 —— 除了获取或设置相应的属性外，不能包含任何逻辑。此外，对于对象引用的数据成员，引用的对象必须是有效不可变的。（这将禁止具有数组值的属性，因为当数组引用被声明为 volatile 时，只有引用而不是数组本身具有 volatile 语义）。对于任何 volatile 变量，不变式或约束都不能包含 JavaBean 属性 12345678910111213141516171819202122@ThreadSafepublic class Person &#123; private volatile String firstName; private volatile String lastName; private volatile int age; public String getFirstName() &#123; return firstName; &#125; public String getLastName() &#123; return lastName; &#125; public int getAge() &#123; return age; &#125; public void setFirstName(String firstName) &#123; this.firstName = firstName; &#125; public void setLastName(String lastName) &#123; this.lastName = lastName; &#125; public void setAge(int age) &#123; this.age = age; &#125;&#125; 关于volatile修饰对象，String，数组，一直没找到靠的资料，有些网友写道volatile传递性，待验证，看了好几一直得不出什么结论，再研究研究 volatile 和 synchronized 实现 “开销较低的读－写锁”如果更新不频繁的话，该方法可实现更好的性能，因为读路径的开销仅仅涉及 volatile 读操作，这通常要优于一个无竞争的锁获取的开销。 123456789101112@ThreadSafepublic class CheesyCounter &#123; // Employs the cheap read-write lock trick // All mutative operations MUST be done with the 'this' lock held @GuardedBy("this") private volatile int value; public int getValue() &#123; return value; &#125; public synchronized int increment() &#123; return value++; &#125;&#125;]]></content>
      <categories>
        <category>JAVA并发编程</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
        <tag>并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM内存模型（二）]]></title>
    <url>%2F2019%2F11%2F09%2FJVM%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%EF%BC%88%E4%BA%8C%EF%BC%89%2F</url>
    <content type="text"><![CDATA[这个文章关于JMM写的比较详细，写了一些记录。 内部原文章图片原文件]]></content>
      <categories>
        <category>JAVA并发编程</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
        <tag>并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM内存模型（一）]]></title>
    <url>%2F2019%2F11%2F03%2FJVM%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[线程之间的通信和同步 线程的通信是指线程之间以何种机制来交换信息。在命令式编程中，线程之间的通信机制有两种共享内存和消息传递。 在共享内存的并发模型里，线程之间共享程序的公共状态，线程之间通过写-读内存中的公共状态来隐式进行通信，典型的共享内存通信方式就是通过共享对象进行通信。 在消息传递的并发模型里，线程之间没有公共状态，线程之间必须通过明确的发送消息来显式进行通信，在java中典型的消息传递方式就是wait()和notify()。 同步是指程序用于控制不同线程之间操作发生相对顺序的机制。 在共享内存并发模型里，同步是显式进行的。程序员必须显式指定某个方法或某段代码需要在线程之间互斥执行。 在消息传递的并发模型里，由于消息的发送必须在消息的接收之前，因此同步是隐式进行的。 JAVA内存模型JMM决定一个线程对共享变量的写入何时对另一个线程可见。从抽象的角度来看，JMM定义了线程和主内存之间的抽象关系：线程之间的共享变量存储在主内存（main memory）中，每个线程都有一个私有的本地内存（local memory），本地内存中存储了该线程以读/写共享变量的副本。本地内存是JMM的一个抽象概念，并不真实存在。它涵盖了缓存，写缓冲区，寄存器以及其他的硬件和编译器优化。 从上图来看，线程A与线程B之间如要通信的话，必须要经历下面2个步骤： 首先，线程A把本地内存A中更新过的共享变量刷新到主内存中去。 然后，线程B到主内存中去读取线程A之前已更新过的共享变量。 下面通过示意图来说明这两个步骤： 如上图所示，本地内存A和B有主内存中共享变量x的副本。假设初始时，这三个内存中的x值都为0。线程A在执行时，把更新后的x值（假设值为1）临时存放在自己的本地内存A中。当线程A和线程B需要通信时，线程A首先会把自己本地内存中修改后的x值刷新到主内存中，此时主内存中的x值变为了1。随后，线程B到主内存中去读取线程A更新后的x值，此时线程B的本地内存的x值也变为了1。 从整体来看，这两个步骤实质上是线程A在向线程B发送消息，而且这个通信过程必须要经过主内存。JMM通过控制主内存与每个线程的本地内存之间的交互，来为java程序员提供内存可见性保证。 上面也说到了，Java内存模型只是一个抽象概念，那么它在Java中具体是怎么工作的呢？为了更好的理解上Java内存模型工作方式，下面就JVM对Java内存模型的实现、硬件内存模型及它们之间的桥接做详细介绍。 JVM对Java内存模型的实现JMM的定义是一种规范要求，具体的实现要看虚拟机的实现方式。 JVM中运行的每个线程都拥有自己的线程栈，线程栈还包含了当前方法的所有本地变量信息。一个线程只能读取自己的线程栈,线程中的本地变量对其它线程是不可见的。即使两个线程执行的是同一段代码，它们也会各自在自己的线程栈中创建本地变量，因此，每个线程中的本地变量都会有自己的版本。所有原始类型(boolean,byte,short,char,int,long,float,double)的本地变量都直接保存在线程栈当中，对于它们的值各个线程之间都是独立的。对于原始类型的本地变量，一个线程可以传递一个副本给另一个线程，当它们之间是无法共享的。 堆区包含了Java应用创建的所有对象信息，不管对象是哪个线程创建的，其中的对象包括原始类型的封装类（如Byte、Integer、Long等等）。不管对象是属于一个成员变量还是方法中的本地变量，它都会被存储在堆区。 下图展示了调用栈和本地变量都存储在栈区，对象都存储在堆区： 一个本地变量如果是原始类型，那么它会被完全存储到栈区。 一个本地变量也有可能是一个对象的引用，这种情况下，这个本地引用会被存储到栈中，但是对象本身仍然存储在堆区。 对于一个对象的成员方法，这些方法中包含本地变量，仍需要存储在栈区，即使它们所属的对象在堆区。 对于一个对象的成员变量，不管它是原始类型还是包装类型，都会被存储到堆区。 Static类型的变量以及类本身相关信息都会随着类本身存储在堆区。 堆中的对象可以被多线程共享。如果一个线程获得一个对象的应用，它便可访问这个对象的成员变量。如果两个线程同时调用了同一个对象的同一个方法，那么这两个线程便可同时访问这个对象的成员变量，但是对于本地变量，每个线程都会拷贝一份到自己的线程栈中。 下图展示了上面描述的过程: 硬件内存架构不管是什么内存模型，最终还是运行在计算机硬件上的，所以我们有必要了解计算机硬件内存架构，下图就简单描述了当代计算机硬件内存架构： 在CPU内部有一组CPU寄存器，也就是CPU的储存器。CPU操作寄存器的速度要比操作计算机主存快的多。在主存和CPU寄存器之间还存在一个CPU缓存，CPU操作CPU缓存的速度快于主存但慢于CPU寄存器。某些CPU可能有多个缓存层（一级缓存和二级缓存）。计算机的主存也称作RAM，所有的CPU都能够访问主存，而且主存比上面提到的缓存和寄存器大很多。 当一个CPU需要访问主存时，会先读取一部分主存数据到CPU缓存，进而在读取CPU缓存到寄存器。当CPU需要写数据到主存时，同样会先flush寄存器到CPU缓存，然后再在某些节点把缓存数据flush到主存。 Java内存模型和硬件架构之间的桥接正如上面讲到的，Java内存模型和硬件内存架构并不一致。硬件内存架构中并没有区分栈和堆，从硬件上看，不管是栈还是堆，大部分数据都会存到主存中，当然一部分栈和堆的数据也有可能会存到CPU寄存器中，如下图所示，Java内存模型和计算机硬件内存架构是一个交叉关系： 文章]]></content>
      <categories>
        <category>JAVA并发编程</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
        <tag>并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库事务]]></title>
    <url>%2F2019%2F10%2F27%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[数据库事务数据库事务(Database Transaction) ,具有原子性（Atomicity）、一致性（Consistency）、隔离性（Isolation）、持久性（Durability） 原子性：原子性是指事务是一个不可分割的工作单位，事务中的操作要么全部成功，要么全部失败 一致性：事务必须使数据库从一个一致性状态变换到另外一个一致性状态 隔离性：并发执行的事务不会相互影响,其对数据库的影响和它们串行执行时一样 持久性：持久性是指一个事务一旦被提交，它对数据库中数据的改变就是永久性的 持久性(Durability):事务一旦提交,其对数据库的更新就是持久的。任何事务或系统故障都不会导致数据丢失。 在事务的ACID特性中,C即一致性是事务的根本追求,而对数据一致性的破坏主要来自两个方面 1.事务的并发执行2.事务故障或系统故障数据库系统是通过并发控制技术和日志恢复技术来避免这种情况发生的。ACID并发控制技术保证了事务的隔离性,使数据库的一致性状态不会因为并发执行的操作被破坏。日志恢复技术保证了事务的原子性,使一致性状态不会因事务或系统故障被破坏。同时使已提交的对数据库的修改不会因系统崩溃而丢失,保证了事务的持久性。 理想状态下，事务的隔离性保存了数据库向串行一样的执行，但是在一定程度的并发情况下，严重影响数据库的性能，所以将隔离性化分为不同的等级，在不同的要求或场景下使用不同的等级。就好比安检，在国庆期间安检等级是最高的，必须一个人一个人的接受检查，然后再通过安全通道。平时的话保安看人比较多就管的不那么严格了，有人可能着急就和别人一并过去了。所以在不同的场景下进行不同的隔离要求。MYSQL数据库设置了四种隔离级别，从低到高分别是读未提交(READ UNCOMMITTED)、读已提交(READ COMMITTED)、可重复读(REPEATABLE READ)、串行化(SERIALIZABLE)。其中串行化是最高级别的，保证事务能够串行执行，真正可以实现数据库隔离性要求的。那么其他三种低级别的隔离必然会导致一些问题存在。下面依次看下这些问题。 脏写 一个事务回滚导致别的事务提交的数据也被回滚了 TX-A TX-B ————– ————- read X＝100 read X＝100 write X=X+200 commit X=300 write X=X+200 roolback X=100 丢失更新 如果两个事务都更新同一个字段时： TX-A TX-B read X＝100 read X＝100 write X=X+200 write X=X+300 commit X=300 commit X=400 TX-A将X加200，应该是300，然后TX-B将X加300，应该是600，结果最后X是400，相当于把TX-A加的200给丢了 脏读 一个事务读取到了另一个事务未提交的数据： TX-A TX-B ———– ————- read X＝100 read X＝100 write X=X+300 read X=400 在事务TX-A中读取了TX-B还没有提交的数据，如果TX-B回滚，则TX-A计算就出错了 不可重复读一个事务读取到了另一个事务已提交的数据： TX-A TX-B ———– ————- read X＝100 read X＝100 write X=X+300 commit X=400 read X=400 在事务TX-A中读取了TX-B已提交的数据，这样会导致TX-A在一个事务内每次读取的数据不一样，其结果依赖于别人并行提交的数据。与脏读的区别就是读取的数据是另一个事务提交前的还是提交后的数据。 幻读一个事务读取到了另一个事务插入的数据： TX-A TX-B read count(*) = 5 write insert 1 commit X=400 read count(*) = 6 虚读(幻读)是指在一个事务内读取到了别的事务插入的数据，导致前后读取的数据数量不同。 不同的事务隔离级别可能会出现不同的等级错误|隔离级别|脏写|脏读|不可重复读|幻读|丢失更新|| ————————– | — | —- | —- | —- | —- || 读未提交(READ UNCOMMITTED) | | 可能 | 可能 | 可能 | 可能 || 读已提交(READ COMMITTED) | | | 可能 | 可能 | 可能 || 可重复读(REPEATABLE READ) | | | | 可能 | || 串行化(SERIALIZABLE) | | | | | | 隔离实现并发控制主要是通过锁的机制实现，从“心里预期”来说可以分为两种，分别是乐观锁、悲观锁。这里说的锁是一个抽象概念，是一种实现机制，并不一定是有锁这个类或者API等实体的东西。 乐观锁：在并发执行时，假定不会发生资源竞争，允许执行，只有在真正发生冲突时才会解决冲突，比如事务回滚，再次尝试等。 悲观锁：在并发执行时，已经认为会发生资源竞争，所以只能按照串行执行，一刀切，爱谁谁。 基于封锁的并发控制核心思想:对于并发可能冲突的操作,比如读-写,写-读,写-写,通过锁使它们互斥执行 锁通常分为共享锁和排他锁两种类型 共享锁(S):事务T对数据A加共享锁,其他事务只能对A加共享锁但不能加排他锁。 排他锁(X):事务T对数据A加排他锁,其他事务对A既不能加共享锁也不能加排他锁基于锁的并发控制流程: 事务根据自己对数据项进行的操作类型申请相应的锁(读申请共享锁,写申请排他锁) 申请锁的请求被发送给锁管理器。锁管理器根据当前数据项是否已经有锁以及申请的和持有的锁是否冲突决定是否为该请求授予锁。 若锁被授予,则申请锁的事务可以继续执行;若被拒绝,则申请锁的事务将进行等待,直到锁被其他事务释放。 可能出现的问题: 死锁:多个事务持有锁并互相循环等待其他事务的锁导致所有事务都无法继续执行。 饥饿:数据项A一直被加共享锁,导致事务一直无法获取A的排他锁。 对于可能发生冲突的并发操作,锁使它们由并行变为串行执行,是一种悲观的并发控制。 基于时间戳的并发控制核心思想:对于并发可能冲突的操作,基于时间戳排序规则选定某事务继续执行,其他事务回滚 系统会在每个事务开始时赋予其一个时间戳,这个时间戳可以是系统时钟也可以是一个不断累加的计数器值,当事务回滚时会为其赋予一个新的时间戳,先开始的事务时间戳小于后开始事务的时间戳。 每一个数据项Q有两个时间戳相关的字段:W-timestamp(Q):成功执行write(Q)的所有事务的最大时间戳R-timestamp(Q):成功执行read(Q)的所有事务的最大时间戳 时间戳排序规则如下: 假设事务T发出read(Q),T的时间戳为TS 若TS(T)&lt;W-timestamp(Q),则T需要读入的Q已被覆盖。此read操作将被拒绝,T回滚。 若TS(T)&gt;=W-timestamp(Q),则执行read操作,同时把R-timestamp(Q)设置为TS(T)与R-timestamp(Q)中的最大值 假设事务T发出write(Q) 若TS(T)&lt;R-timestamp(Q),write操作被拒绝,T回滚。 若TS(T)&lt;W-timestamp(Q),则write操作被拒绝,T回滚。 其他情况:系统执行write操作,将W-timestamp(Q)设置为TS(T)。 基于时间戳排序和基于锁实现的本质一样:对于可能冲突的并发操作,以串行的方式取代并发执行,因而它也是一种悲观并发控制。它们的区别主要有两点: 基于锁是让冲突的事务进行等待,而基于时间戳排序是让冲突的事务回滚。基于锁冲突事务的执行次序是根据它们申请锁的顺序,先申请的先执行;而基于时间戳排序是根据特定的时间戳排序规则。 基于有效性检查的并发控制核心思想:事务对数据的更新首先在自己的工作空间进行,等到要写回数据库时才进行有效性检查,对不符合要求的事务进行回滚 基于有效性检查的事务执行过程会被分为三个阶段: 读阶段:数据项被读入并保存在事务的局部变量中。所有write操作都是对局部变量进行,并不对数据库进行真正的更新。 有效性检查阶段:对事务进行有效性检查,判断是否可以执行write操作而不违反可串行性。如果失败,则回滚该事务。 写阶段:事务已通过有效性检查,则将临时变量中的结果更新到数据库中。 有效性检查通常也是通过对事务的时间戳进行比较完成的,不过和基于时间戳排序的规则不一样。 该方法允许可能冲突的操作并发执行,因为每个事务操作的都是自己工作空间的局部变量,直到有效性检查阶段发现了冲突才回滚。因而这是一种乐观的并发策略。 基于快照隔离的并发控制其核心思想是:数据库为每个数据项维护多个版本(快照),每个事务只对属于自己的私有快照进行更新,在事务真正提交前进行有效性检查,使得事务正常提交更新或者失败回滚。快照隔离是多版本并发控制(mvcc)的一种实现方式 由于快照隔离导致事务看不到其他事务对数据项的更新,为了避免出现丢失更新问题,可以采用以下两种方案避免： 先提交者获胜:对于执行该检查的事务T,判断是否有其他事务已经将更新写入数据库,是则T回滚否则T正常提交。 先更新者获胜:通过锁机制保证第一个获得锁的事务提交其更新,之后试图更新的事务中止。 事务间可能冲突的操作通过数据项的不同版本的快照相互隔离,到真正要写入数据库时才进行冲突检测。因而这也是一种乐观并发控制。 MYSQL- InnoDB锁InnoDB引擎使用了七种类型的锁，他们分别是： 共享排他锁（Shared and Exclusive Locks） 意向锁（Intention Locks） 记录锁（Record Locks） 间隙锁（Gap Locks） Next-Key Locks 插入意图锁（Insert Intention Locks） 自增锁（AUTO-INC Locks） 共享排他锁（Shared and Exclusive Locks） 如果一个事务对某一行数据加了S锁，另一个事务还可以对相应的行加S锁，但是不能对相应的行加X锁。 如果一个事务对某一行数据加了X锁，另一个事务既不能对相应的行加S锁也不能加X锁。 意向锁（Intention Locks）如果事务A申请了行锁(写锁)，事务B申请了表锁（写锁），那么这两个事务就会发冲突。为了解决这类问题引入了意向锁。 意向锁分为意向读锁(IS)和意向写锁(IX) 意向锁是“表锁”，他并不会锁定表，只是显示某人正在锁定行，或者要锁定表中的行。当事务B申请表写锁时，发现该表已经有意向写锁，则会被阻塞。 这样也就解决了上边的问题了，意向锁是由InnoDB自行实现的，用户无法操作 Record Locks、Gap Locks、Next-Key Locks 记录锁（Record Locks）:记录锁锁定索引中一条记录。 间隙锁（Gap Locks）:间隙锁要么锁住索引记录中间的值，要么锁住第一个索引记录前面的值或者最后一个索引记录后面的值。 Next-Key Locks:Next-Key锁是索引记录上的记录锁和在索引记录之前的间隙锁的组合。 三种类型锁的锁定范围不同，且逐渐扩大。我们来举一个例子来简要说明各种锁的锁定范围，假设表t中索引列有3、5、8、9四个数字值，根据官方文档的确定三种锁的锁定范围如下： 记录锁的锁定范围是单独的索引记录，就是3、5、8、9这四行数据。 间隙锁的锁定为行中间隙，用集合表示为(-∞,3)、(3,5)、(5,8)、(8,9)、(9,+∞)。 Next-Key锁是有索引记录锁加上索引记录锁之前的间隙锁组合而成，用集合的方式表示为(-∞,3]、(3,5]、(5,8]、(8,9]、(9,+∞)。 最后补充几点： 间隙锁阻止其他事务对间隙数据的并发插入，这样可有有效的解决幻读问题(Phantom Problem)。正因为如此，并不是所有事务隔离级别都使用间隙锁，MySQL InnoDB引擎只有在Repeatable Read（默认）隔离级别才使用间隙锁。 间隙锁的作用只是用来阻止其他事务在间隙中插入数据，他不会阻止其他事务拥有同样的的间隙锁。这就意味着，除了insert语句，允许其他SQL语句可以对同样的行加间隙锁而不会被阻塞。 对于唯一索引的加锁行为，间隙锁就会失效，此时只有记录锁起作用。 行锁实现依赖于索引，一旦某个加锁操作没有使用到索引，那么该锁就会退化为表锁。 记录锁存在于包括主键索引在内的唯一索引中，锁定单条索引记录。]]></content>
      <categories>
        <category>MYSQL</category>
      </categories>
      <tags>
        <tag>事务</tag>
        <tag>MYSQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[闭包原理]]></title>
    <url>%2F2019%2F10%2F26%2F%E9%97%AD%E5%8C%85%2F</url>
    <content type="text"><![CDATA[在了解JAVA闭包的过程中偶然读到JS的闭包文章，讲解的很明了，所以就先从JS的闭包入手学习。文章出自廖雪峰的网站 #高价函数JS中函数可以通过变更引用，当把函数的变量引用作为参数传递给其他参数时就构成了高价函数。比如以下add方法，将其中f指定为一个函数如Math.abs，则方法体中的f(x) + f(y)则可以转换成Math.abs(y) + Math.abs(y)。当x=-1,y=2时，add方法体计算过程为Math.abs(-1) + Math.abs(2)=1+2=3。 123function add(x, y, f) &#123; return f(x) + f(y);&#125; ##map/reducemap/reduce方法是Array类中的方法，其中map方法需要传入一个函数，他作用于数组中的每一个元素。比如定义pow函数，计算一个数的平方，传入map后，map方法会针对每个元素调用该pow函数，并将结果返回 1234567function pow(x) &#123; return x * x;&#125;var arr = [1, 2, 3, 4, 5, 6, 7, 8, 9];var results = arr.map(pow); // [1, 4, 9, 16, 25, 36, 49, 64, 81]console.log(results); reduce方法同样需要传入一个函数，比如我们要对数组元素作累加操作，定义一个函数f = function(x,y){return x+y}，函数的返回值与下一个元素合作为两个参数再将调用函数f。下边的例子可以分解成[1, 2, 3, 4].reduce(f) = f(f(f(1, 2), 3), 4)= 10。有点儿递归的意思 123456var arr = [1,2,3,4];var f = function (x, y) &#123; return x + y;&#125;var results = arr.reduce(f); // 10console.log(results); reduce方法的完整定义如下（参考文档）： 1arr.reduce(callback(accumulator, currentValue[, index[, array]])[, initialValue]) previousValue上一次调用回调返回的值，或者是提供的初始值（initialValue） currentValue数组中当前被处理的元素 index当前元素在数组中的索引 array调用 reduce 的数组 initialValue作为第一次调用 callback 的第一个参数。 回调函数第一次执行时，previousValue 和 currentValue 可以是一个值，如果 initialValue 在调用 reduce 时被提供，那么第一个 previousValue 等于 initialValue ，并且currentValue 等于数组中的第一个值；如果initialValue 未被提供，那么previousValue 等于数组中的第一个值，currentValue等于数组中的第二个值。 如果数组为空并且没有提供initialValue， 会抛出TypeError 。如果数组仅有一个元素（无论位置如何）并且没有提供initialValue， 或者有提供initialValue但是数组为空，那么此唯一值将被返回并且callback不会被执行。 更多的使用就不作展开了，这里帖下polyfill，可以更好的理解其中的处理机制 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768if(!Array.prototype.reduce)&#123; Object.defineProperty(Array.prototype, 'reduce', &#123; value: function(callback/*, initialValue*/)&#123; if(this === null) &#123; //判断是否是是null调用的reduce函数 throw new TypeError('Array.prototype.reduce called on null or undefined')//使用===能判断出undefined? &#125; if(typeof callback !== 'function') &#123;//判断出入的参数是否是函数 throw new TypeError(callback + 'is not a function' ) &#125; // 1. let o be ?? ToObject(this value) var o = Object(this) // 生成了一个数组o //得到数组的副本 // 2. let len be ? toLength( ? get(0, "lenght")) var len = o.length &gt;&gt;&gt; 0 //获取数组的长度 var k = 0 //当前索引 var value //最终返回的值 if(arguments.length &gt;= 2) &#123; //如果有第二参数 （初始值）， 从数组的第一个元素开始遍历 value = arguments[1] //将其赋值给value, 在做累加 &#125;else &#123; //没有初始值 while (k &lt; len &amp;&amp; !(k in o))&#123; //当数组是稀疏数组时， 判断数组当前是否有元素， 如果没有就索引加一 k++ &#125; //3. if len is 0 and initialValue is not present //如果数组为空， 且初始值不存在。抛出一个错误 if( k &gt;= len) &#123; throw new TypeError('Reduce of empty array with no initial value') &#125; //把第一个非空元素的值给value， 并索引加一 value = o[k++] &#125; //以上都是为了获得value的初始值。 以便一下累加 // 8. Repeat, while k &lt; len while (k &lt; len)&#123; // a. let Pk be ! ToString(k) // b. let Kpresent be ? HasProperty(0, Pk) // c. if kPresent is true, then // i. let kValue be ? Get(0, Pk) // ii. let accumulator be ? call( // callbackfn, undefined, // &lt;&lt; accumulator, kValue, k, o &gt;&gt;). if( k in o) &#123;//如果当前索引处有值， 调用函数，累加 value = callback(value, o[k], k, o)// 传入4个参数， 第一个是value, 第二个当前值， 当前索引， 当前数组 &#125; k++ &#125; return value &#125; &#125;)&#125;/** * 整体说一下该polyfill函数的思路 * 1. 如果javascript引擎不支持reduce函数， 那么久在Array的原型上定义了一个reduce的函数， 不过为啥要通过Object.defineProperty()来定义呢？ 可以直接添加一个这样的函数就是了嘛 * 2. 在添加的函数中，判断是否是null调用。 * 3. 判断第一个参数是是否为函数， 如果不是抛出错误 * 4. 复制这个数组 * 5. 得到数组的长度 * 6. 设置当前索引 * 7. 定义value变量 * 8. 给value设置初始值， 如果传入了第二参数， 就将其设置为value, 否则找到第一个非空元素设置其为value的值 * 9. 循环调用callback累加， 其中会通过in 判断是否为空， 如果为空跳过调用callback、 * 10. 返回value */ 同时，Array还有其他很多的高阶函数，比如filter(),sort(),every(),find()等等。 #闭包 上边介绍了高阶函数，即把函数当作参数传递给方法。而闭包则是方法返回函数。先看下reduce求和的例子 1234567function sum(arr) &#123; return arr.reduce(function (x, y) &#123; return x + y; &#125;);&#125;sum([1, 2, 3, 4, 5]); // 15 当执行sum([1, 2, 3, 4, 5]); 时，则立即计算出结果，如果把sum定义成一个函数，当执行sum()时才进行计算结果，这时需要怎么做呢？操作如下： 12345678910function lazy_sum(arr) &#123; var sum = function () &#123; return arr.reduce(function (x, y) &#123; return x + y; &#125;); &#125; return sum;&#125;var f = lazy_sum([1, 2, 3, 4, 5]);f(); 当我们调用lazy_sum时返回的是一个函数，并没有真正的进行计算,只有当调用f()函数才开始执行，计算求和。在函数lazy_sum中又定义了函数sum，并且，内部函数sum可以引用外部函数lazy_sum的参数和局部变量，当lazy_sum返回函数sum时，相关参数和变量都保存在返回的函数中这就构成强大的闭包。这里特别注意的sum函数的定义使用到了其作用域外的变量，即arr,当我们调用lazy_sum方法时返回的f函数，其内部保存了传递的参数[1, 2, 3, 4, 5]。换个角度说当一个函数返回了一个函数后，其内部的局部变量还被新函数引用。看个例子： 123456789101112131415161718function count() &#123; var arr = []; for (var i=1; i&lt;=3; i++) &#123; arr.push(function () &#123; return i * i; &#125;); &#125; return arr;&#125;var results = count();var f1 = results[0];var f2 = results[1];var f3 = results[2];f1(); // 16f2(); // 16f3(); // 16 count方法返回一个数组，每个数组元素是一个函数，这个函数引用了外部变量i，当count方法执行完毕后，i变成了4，这个时候再调用f1时，这个比引用的变量i已经变成了4，所以执行结果为16，其他元素也一样。并不是期许的1、4、9。如果说要达到1、4、9的效果需要怎么做呢？再看个例子: 12345678910111213141516171819202122function count() &#123; var arr = []; var ft = function(n)&#123; return function () &#123; return n * n; &#125; &#125; for (var i=1; i&lt;=3; i++) &#123; arr.push(ft(i)); &#125; return arr;&#125;var results = count();var f1 = results[0];var f2 = results[1];var f3 = results[2];console.log(f1());console.log(f2());console.log(f3()); ft函数返回一个函数类型的返回值，这个函数引用的变量是ft的参数n。当执行for循环时，每次push进去的分别是ft(1)、ft(2)、ft(3)，所以当调用f1()、f2()、f3()分别返回的是1、4、9。这里为啥i的变化没有影响到（传递给）求积函数呢？是因为i作为变量传递给了方法ft，ft重新分配内存，生成临时变量，这个临时变量被求积函数引用。而上一个例子中每次push进去的求积函数引用的变量i都是同一个，当for循环完了他们共同引用的变量已经变成了4，所以每个执行结果都是16。这里有两个点需要注意： 闭包最大的特点就是返回函数引用了外层变量，所以当外层函数执行完，变量并没有销毁，还在被返回函数持有，或者说被返回函数hang住了，这就是闭包最厉害的地方。 返回函数直接引用的外层变量，外层变量发生变化，对于返回函数来说做不了任何事情，他既不能记录外层变量的变化状态，也不能持有某一时刻该变量的值，他只能眼吧吧的看着。只有，当，返回函数被调用执行时他才获取并使用此刻的外层变量，这时的外层变量是啥就是啥。 当返回函数改变外层变量时，当前的返回函数变量是可以感知的，例子如下(为啥c2的执行不是4、5、6？因为c2是重新执行函数create_counter()返回的对象，与c1无任何关系)：1234567891011121314151617181920function create_counter(initial) &#123; var x = initial || 0; return &#123; inc: function () &#123; x += 1; return x; &#125; &#125;&#125;var c1 = create_counter();console.log(c1.inc());//1console.log(c1.inc());//2console.log(c1.inc());//3var c2 = create_counter();console.log(c2.inc());//1console.log(c2.inc());//2console.log(c2.inc());//3 #脑洞大开很久很久以前，有个叫阿隆佐·邱奇的帅哥，发现只需要用函数，就可以用计算机实现运算，而不需要0、1、2、3这些数字和+、-、*、/这些符号。 JavaScript支持函数，所以可以用JavaScript用函数来写这些计算。来试试： // 定义数字0: var zero = function (f) { return function (x) { return x; } }; // 定义数字1: var one = function (f) { return function (x) { return f(x); } }; // 定义加法: function add(n, m) { return function (f) { return function (x) { return m(f)(n(f)(x)); } } } // 计算数字2 = 1 + 1: var two = add(one, one); // 计算数字3 = 1 + 2: var three = add(one, two); // 计算数字5 = 2 + 3: var five = add(two, three); // 你说它是3就是3，你说它是5就是5，你怎么证明？ // 呵呵，看这里: // 给3传一个函数,会打印3次: (three(function () { console.log('print 3 times'); }))(); // 给5传一个函数,会打印5次: (five(function () { console.log('print 5 times'); }))(); `` *上边说了半天闭包，但是正式的概念不好给出，是一种设计模式？还是语法特性？还是什么？所以也就不知道整体叫闭包函数，还是返回函数叫闭包函数，因此本文描述中使用了外层变量、返回函数这样的字眼*]]></content>
      <categories>
        <category>闭包原理</category>
      </categories>
      <tags>
        <tag>闭包</tag>
        <tag>JS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[存储过程调试过程]]></title>
    <url>%2F2019%2F10%2F23%2F%E5%AD%98%E5%82%A8%E8%BF%87%E7%A8%8B%E8%B0%83%E8%AF%95%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[记一次MYSQL存储过程调试过程 ···以下存储过程在最近总是偶尔出现返回失败的情况，由于看不到异常信息，所以查找原因颇费周折。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213DELIMITER $$USE `IotProductDB`$$DROP PROCEDURE IF EXISTS `PROC_PRODUCT_PERSRESULT_CARD`$$CREATE DEFINER=`links`@`%` PROCEDURE `PROC_PRODUCT_PERSRESULT_CARD`(IN `IN_PERS_ICCID` VARCHAR(20),IN `IN_ICCID` VARCHAR(20),IN `IN_ASSET_ID` VARCHAR(20), IN `IN_RSTCODE` VARCHAR(4), IN `IN_RSTINFO` VARCHAR(100), IN `IN_TASKNO` VARCHAR(20), IN `IN_PDN` VARCHAR(20),OUT `OUT_RESULT` VARCHAR(2))BEGIN #定义变量 DECLARE V_MANUFACTURERCODE VARCHAR(10) DEFAULT NULL; DECLARE V_MANUFACTURERNAME VARCHAR(50) DEFAULT NULL; DECLARE V_PARTNERCODE VARCHAR(32) DEFAULT NULL; DECLARE V_PARTNERNAME VARCHAR(30) DEFAULT NULL; DECLARE V_ROAMSIM_CODE VARCHAR(50) DEFAULT NULL; DECLARE V_ROAMSIM_VERSION VARCHAR(20) DEFAULT NULL; DECLARE V_RODUCT_CODE VARCHAR(200) DEFAULT NULL; DECLARE V_CARD_MATERIAL_CODE VARCHAR(25) DEFAULT NULL; DECLARE V_PRODUCTTYPE VARCHAR(2) DEFAULT NULL; DECLARE V_M2MCARD_SCLIENT_DATE VARCHAR(5) DEFAULT NULL; DECLARE V_M2MCARD_STOP_DATE VARCHAR(5) DEFAULT NULL; DECLARE V_OTA_FLAG VARCHAR(2) DEFAULT NULL; DECLARE V_MORE_IMSI_FLAG VARCHAR(2) DEFAULT NULL; DECLARE V_INUSE_INDUSTRY VARCHAR(50) DEFAULT NULL; DECLARE V_OTA_PROTOCOL_VERSION VARCHAR(50) DEFAULT NULL; DECLARE V_LIFECYCLE VARCHAR(2) DEFAULT NULL; DECLARE V_ASSIGN_TIME VARCHAR(30) DEFAULT NULL; DECLARE V_LIFECYCLE_STARTTIME VARCHAR(30) DEFAULT NULL; DECLARE V_PRODUCT_TYPE VARCHAR(2) DEFAULT NULL; DECLARE V_BIP_PARAM_NAME VARCHAR(50) DEFAULT NULL; DECLARE V_DEVICE_STATUS VARCHAR(2) DEFAULT NULL; DECLARE V_TWICE_TYPE VARCHAR(2) DEFAULT NULL; DECLARE V_ASSET_SIGN VARCHAR(30) DEFAULT NULL; DECLARE V_CVT INT(2); # 定义游标遍历时，作为判断是否遍历完全部记录的标记 DECLARE num INT DEFAULT 0; # 集合变量 DECLARE V_ICCID VARCHAR(20) DEFAULT NULL; DECLARE V_IMSI VARCHAR(20) DEFAULT NULL; DECLARE V_NUMBERTYPE VARCHAR(2) DEFAULT NULL; DECLARE V_SUPPLIERCODE VARCHAR(12) DEFAULT NULL; DECLARE V_SUPPLIERNAME VARCHAR(100) DEFAULT NULL; DECLARE V_OPERATORCODE VARCHAR(4) DEFAULT NULL; DECLARE V_OPERATORNAME VARCHAR(50) DEFAULT NULL; DECLARE V_COVER_COUNTRY VARCHAR(2000) DEFAULT NULL; # 定义游标，并将sql结果集赋值到游标中 DECLARE softsim_list CURSOR FOR SELECT `iccid`,`imsi`,`number_type`,`supplier_code`,`supplier_name`,`operator_code`, `operator_name`,`cover_country` FROM `production_log_t` WHERE asset_sign=( SELECT asset_sign FROM `production_log_t` WHERE pers_data_iccid=IN_PERS_ICCID AND task_no=IN_TASKNO AND (asset_id=IN_ASSET_ID OR dispersion_factor=IN_ASSET_ID) LIMIT 1); # 声明当游标遍历完全部记录后将标志变量置成某个值 DECLARE CONTINUE HANDLER FOR NOT FOUND SET num=1; DECLARE CONTINUE HANDLER FOR SQLEXCEPTION SET OUT_RESULT=&apos;0&apos;; SET OUT_RESULT = &apos;1&apos;; START TRANSACTION;#事务; SELECT `manufacturer_code`,`manufacturer_name`,`partner_code`,`partner_name`,`roamingsim_code`,`roamingsim_version`,`product_code`, `card_material_code`,`product_type`,`m2mcard_slient_date`,`m2mcard_stop_date`,`ota_flag`,`more_imsi_flag`,`inuse_industry`, `ota_protocol_version`,`product_type`,`twice_type` INTO V_MANUFACTURERCODE,V_MANUFACTURERNAME,V_PARTNERCODE, V_PARTNERNAME,V_ROAMSIM_CODE,V_ROAMSIM_VERSION,V_RODUCT_CODE,V_CARD_MATERIAL_CODE,V_PRODUCTTYPE,V_M2MCARD_SCLIENT_DATE,V_M2MCARD_STOP_DATE, V_OTA_FLAG,V_MORE_IMSI_FLAG,V_INUSE_INDUSTRY,V_OTA_PROTOCOL_VERSION,V_PRODUCT_TYPE,V_TWICE_TYPE FROM `simcard_production_task_t` WHERE task_no=IN_TASKNO LIMIT 1; IF &apos;0000&apos; = IN_RSTCODE THEN #生产成功 # 如果异常数据表中有该记录的数据则删除 DELETE FROM `simcard_product_abnormal_t` WHERE task_no=IN_TASKNO AND eficcid=IN_PERS_ICCID AND pdn=IN_PDN; SELECT asset_sign INTO V_ASSET_SIGN FROM `production_log_t` WHERE pers_data_iccid=IN_PERS_ICCID AND task_no=IN_TASKNO AND (asset_id=IN_ASSET_ID OR dispersion_factor=IN_ASSET_ID) LIMIT 1; UPDATE production_log_t SET `status`=&apos;2&apos;, finish_time=NOW(), rst_code=IN_RSTCODE, rst_info=IN_RSTINFO WHERE task_no=IN_TASKNO AND asset_sign=V_ASSET_SIGN; # 打开游标 OPEN softsim_list; # 将游标中的值赋值给变量，要注意sql结果列的顺序 FETCH softsim_list INTO V_ICCID,V_IMSI,V_NUMBERTYPE,V_SUPPLIERCODE,V_SUPPLIERNAME,V_OPERATORCODE,V_OPERATORNAME,V_COVER_COUNTRY; # while循环 WHILE num &lt;&gt; 1 DO IF &apos;2&apos;=V_NUMBERTYPE THEN UPDATE softsim_resource_info_t SET `status`=&apos;02&apos; WHERE iccid=V_ICCID; IF &apos;2&apos;=V_OTA_FLAG || &apos;1&apos;=V_TWICE_TYPE THEN INSERT INTO `asset_softsim_usage_t` ( `asset_id`,`iccid`,`imsi`,`status`,`create_date`,`cover_mcc`,`operator_code`,`operator_name`,`supplier_code`,`supplier_name`, `multi_imsi_flag`,`soft_sim_type` ) VALUES( IN_ASSET_ID,V_ICCID,V_IMSI,&apos;1&apos;,NOW(),V_COVER_COUNTRY,V_OPERATORCODE,V_OPERATORNAME,V_SUPPLIERCODE,V_SUPPLIERNAME, V_MORE_IMSI_FLAG,&apos;2&apos; ); END IF; ELSE IF &apos;1&apos;=V_OTA_FLAG THEN INSERT INTO `asset_softsim_usage_t` ( `asset_id`,`iccid`,`imsi`,`status`,`create_date`,`cover_mcc`,`operator_code`,`operator_name`,`supplier_code`,`supplier_name`, `multi_imsi_flag`,`soft_sim_type` ) VALUES( IN_ASSET_ID,V_ICCID,V_IMSI,&apos;1&apos;,NOW(),V_COVER_COUNTRY,V_OPERATORCODE,V_OPERATORNAME,V_SUPPLIERCODE,V_SUPPLIERNAME, V_MORE_IMSI_FLAG,&apos;2&apos; ); END IF; END IF; FETCH softsim_list INTO V_ICCID,V_IMSI,V_NUMBERTYPE,V_SUPPLIERCODE,V_SUPPLIERNAME,V_OPERATORCODE,V_OPERATORNAME,V_COVER_COUNTRY; END WHILE; # 关闭游标 CLOSE softsim_list; IF V_PARTNERCODE=&apos;0&apos; THEN SET V_LIFECYCLE=&apos;5&apos;; ELSE SET V_LIFECYCLE=&apos;0&apos;; SET V_ASSIGN_TIME=NOW(); END IF; SET V_LIFECYCLE_STARTTIME=DATE_FORMAT(NOW(),&apos;%Y%m%d&apos;); IF &apos;4&apos;=V_PRODUCT_TYPE &amp;&amp; &apos;2&apos;=V_TWICE_TYPE THEN SET V_DEVICE_STATUS=&apos;1&apos;; UPDATE `asset_info_t` SET `roamingsim_code`=V_ROAMSIM_CODE,`version`=V_ROAMSIM_VERSION,lifecycle=V_LIFECYCLE, lifecycle_start_time=V_LIFECYCLE_STARTTIME,task_no=IN_TASKNO,manufacturer_code=V_MANUFACTURERCODE, manufacturer_name=V_MANUFACTURERNAME,in_time=NOW(),activate_flag=&apos;0&apos;,partner_name=V_PARTNERNAME,partner_code=V_PARTNERCODE, data_encrypt_factor=IN_ASSET_ID,assign_time=V_ASSIGN_TIME,is_online=&apos;0&apos;,silent_cycle=V_M2MCARD_SCLIENT_DATE, stop_service_period=V_M2MCARD_STOP_DATE,init_flag=&apos;0&apos;,ota_flag=V_OTA_FLAG,bip_flag=&apos;0&apos;,inuse_industry=V_INUSE_INDUSTRY, more_imsi_flag=V_MORE_IMSI_FLAG,device_form=&apos;1&apos;,manu_type=V_PRODUCT_TYPE,ota_protocol_version=V_OTA_PROTOCOL_VERSION, bip_param_name=V_BIP_PARAM_NAME,device_status=V_DEVICE_STATUS,card_material_code=V_CARD_MATERIAL_CODE WHERE asset_id=IN_ASSET_ID; UPDATE asset_lifecycle_t SET cyclelife=V_LIFECYCLE,cyclelife_start_time=V_LIFECYCLE_STARTTIME,STATUS=&apos;1&apos;,createtime=NOW() WHERE asset_id=IN_ASSET_ID; ELSE SET V_DEVICE_STATUS=&apos;3&apos;; UPDATE `asset_info_t` SET `roamingsim_code`=V_ROAMSIM_CODE,`version`=V_ROAMSIM_VERSION,lifecycle=V_LIFECYCLE, lifecycle_start_time=V_LIFECYCLE_STARTTIME,task_no=IN_TASKNO,manufacturer_code=V_MANUFACTURERCODE, manufacturer_name=V_MANUFACTURERNAME,in_time=NOW(),activate_flag=&apos;0&apos;,partner_name=V_PARTNERNAME,partner_code=V_PARTNERCODE, data_encrypt_factor=IN_ASSET_ID,assign_time=V_ASSIGN_TIME,is_online=&apos;0&apos;,silent_cycle=V_M2MCARD_SCLIENT_DATE, stop_service_period=V_M2MCARD_STOP_DATE,init_flag=&apos;0&apos;,ota_flag=V_OTA_FLAG,bip_flag=&apos;0&apos;,inuse_industry=V_INUSE_INDUSTRY, more_imsi_flag=V_MORE_IMSI_FLAG,device_form=&apos;1&apos;,manu_type=V_PRODUCT_TYPE,ota_protocol_version=V_OTA_PROTOCOL_VERSION, bip_param_name=V_BIP_PARAM_NAME,device_status=V_DEVICE_STATUS,card_material_code=V_CARD_MATERIAL_CODE WHERE asset_id=IN_ASSET_ID; UPDATE asset_lifecycle_t SET cyclelife=V_LIFECYCLE,cyclelife_start_time=V_LIFECYCLE_STARTTIME,STATUS=&apos;1&apos;,createtime=NOW() WHERE asset_id=IN_ASSET_ID; END IF; # 修改任务成功数量 UPDATE simcard_production_task_t SET actual_quantity=actual_quantity+1 WHERE task_no=IN_TASKNO; ELSE # 生产失败 SELECT COUNT(*) INTO V_CVT FROM simcard_product_abnormal_t WHERE task_no=IN_TASKNO AND eficcid=IN_PERS_ICCID AND pdn=IN_PDN; IF V_CVT=0 THEN #如果不存在则添加异常数据记录 INSERT INTO `simcard_product_abnormal_t` (`task_no`, `pdn`, `eficcid`, `abnormal_code`, `abnormal_desc`, `create_time`) VALUES (IN_TASKNO, IN_PDN, IN_PERS_ICCID, IN_RSTCODE, IN_RSTINFO, NOW()); END IF; #修改生产日志信息 UPDATE `production_log_t` SET `status`=&apos;3&apos; WHERE eficcid=IN_PERS_ICCID AND task_no=IN_TASKNO; END IF; SELECT COUNT(*) INTO V_CVT FROM production_log_t WHERE task_no=IN_TASKNO AND (`status`=&apos;0&apos; OR `status`=&apos;1&apos;) FOR UPDATE; SELECT OUT_RESULT; IF 0=V_CVT THEN # 全部生产完毕 SELECT COUNT(*) INTO V_CVT FROM simcard_production_task_t WHERE task_no=IN_TASKNO AND quantity=actual_quantity FOR UPDATE; IF 0 &lt;&gt; V_CVT THEN # 已经全部成功 UPDATE simcard_production_task_t SET `status`=&apos;3&apos;, end_date=NOW() WHERE task_no=IN_TASKNO; INSERT INTO hist_simcard_production_task_t SELECT * FROM simcard_production_task_t WHERE task_no=IN_TASKNO; DELETE FROM simcard_production_task_t WHERE task_no=IN_TASKNO; INSERT INTO `simcard_product_tracker_t`(`task_no`,`oper_type`,`oper_content`,`oper_name`,`oper_date`) VALUES (IN_TASKNO,&apos;4&apos;,&apos;系统结束生产任务&apos;,&apos;pms_gateway&apos;,SYSDATE()); INSERT INTO `hist_production_log_t` SELECT * FROM `production_log_t` WHERE task_no=IN_TASKNO; DELETE FROM production_log_t WHERE task_no=IN_TASKNO; UPDATE device_info_t SET `status`=&apos;1&apos;,task_type=&apos;&apos; WHERE manufacturer_name=V_MANUFACTURERNAME AND pdn = IN_PDN; ELSE UPDATE simcard_production_task_t SET end_date=NOW() WHERE task_no=IN_TASKNO; END IF; END IF; IF &apos;0&apos;=OUT_RESULT THEN ROLLBACK;#回滚 ELSE COMMIT;#提交 END IF; END$$DELIMITER ; 存储过程写的非常复杂，最主要的一点是发生异常时直接回滚，返回OUT_RESULT=0，无法得知异常信息，所以首要的是先给存储过程加上异常处理。下边是一段存储过程异常处理的方式，直接插入数据库表中，当然实际生产时，除了要插入异常信息，还要和相关的业务信息进行关联。其于以下的方式对存储过程进行改造，改造后的就不帖了。 12345678910111213141516171819202122DROP PROCEDURE IF EXISTS proc_exception;CREATE PROCEDURE proc_exception()BEGINDECLARE v_commit INT DEFAULT 1; -- 定义事务用，1为正常，0为失败DECLARE mysql_error_code TEXT;-- 记录错误信息DECLARE mysql_error_msg TEXT;-- 记录错误信息 mysql_error_code = RETURNED_SQLSTATE, mysql_error_msg = MESSAGE_TEXT;-- 异常的时候msg捕获报错信息DECLARE CONTINUE HANDLER FOR SQLEXCEPTIONBEGIN get diagnostics CONDITION 1 mysql_error_code = RETURNED_SQLSTATE, mysql_error_msg = MESSAGE_TEXT; SET v_commit = 0; END ;START TRANSACTION;-- 设置事务-- 业务相关语法INSERT INTO ......;IF v_commit = 0 THENROLLBACK;INSERT INTO proc_error_log VALUES (mysql_error_code,mysql_error_msg);END IF ;END; 因为失败是偶尔出现的，后来手动执行没啥问题，初步怀疑是并发问题。然后使用JMETER进行压力测试，第一次使用，还真是挺好用的。当进行20个用户发并调用存储过程时，只有第一个成功，其他都失败了。。。。。。，好惨啊！查看proc_error_log表中的记录数据，显示|code|message||—|—||1|2||40001|Deadlock found when trying to get lock; try restarting transaction||40001|Deadlock found when trying to get lock; try restarting transaction||40001|Deadlock found when trying to get lock; try restarting transaction||40001|Deadlock found when trying to get lock; try restarting transaction||40001|Deadlock found when trying to get lock; try restarting transaction||…|…| 好吧，死锁问题，使用命令 SHOW ENGINE INNODB STATUS 查看日志，查找死锁原因。（其他参考命令SHOW STATUS LIKE ‘innodb_row_lock%’;SHOW GLOBAL VARIABLES LIKE ‘innodb_lock_wait_timeout%’;）日志如下： 第一次压测后获取的日志： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283------------------------LATEST DETECTED DEADLOCK------------------------2019-10-24 11:48:01 7f01e69cd700*** (1) TRANSACTION:TRANSACTION 60863969, ACTIVE 2 sec starting index readmysql tables in use 1, locked 1LOCK WAIT 12 lock struct(s), heap size 2936, 7 row lock(s), undo log entries 3MySQL thread id 370111, OS thread handle 0x7f01e6253700, query id 10273081 123.58.107.133 iottest updatingUPDATE asset_lifecycle_t SET cyclelife=V_LIFECYCLE,cyclelife_start_time=V_LIFECYCLE_STARTTIME,STATUS=&apos;1&apos;,createtime=NOW() WHERE asset_id=IN_ASSET_ID*** (1) WAITING FOR THIS LOCK TO BE GRANTED:RECORD LOCKS space id 6455 page no 4 n bits 232 index `PRIMARY` of table `IotProductDB`.`asset_lifecycle_t` trx id 60863969 lock_mode X waitingRecord lock, heap no 2 PHYSICAL RECORD: n_fields 10; compact format; info bits 0 0: len 8; hex 8000000000000001; asc ;; 1: len 6; hex 000001d9b9bd; asc ;; 2: len 7; hex d4000013250110; asc % ;; 3: len 15; hex 383630353939303033303139313731; asc 860599003019171;; 4: len 1; hex 32; asc 2;; 5: len 8; hex 3230313930313239; asc 20190129;; 6: SQL NULL; 7: len 19; hex 323031392d30312d32392032303a35353a3336; asc 2019-01-29 20:55:36;; 8: len 1; hex 31; asc 1;; 9: len 8; hex 3230313930323238; asc 20190228;;*** (2) TRANSACTION:TRANSACTION 60863913, ACTIVE 6 sec fetching rowsmysql tables in use 1, locked 113203 lock struct(s), heap size 1291816, 1282571 row lock(s), undo log entries 5MySQL thread id 370090, OS thread handle 0x7f01e69cd700, query id 10273182 123.58.107.133 iottest Sending dataSELECT COUNT(*) INTO V_CVT FROM production_log_t WHERE task_no=IN_TASKNO AND (`status`=&apos;0&apos; OR `status`=&apos;1&apos;) FOR UPDATE*** (2) HOLDS THE LOCK(S):RECORD LOCKS space id 6455 page no 4 n bits 232 index `PRIMARY` of table `IotProductDB`.`asset_lifecycle_t` trx id 60863913 lock_mode XRecord lock, heap no 1 PHYSICAL RECORD: n_fields 1; compact format; info bits 0 0: len 8; hex 73757072656d756d; asc supremum;;Record lock, heap no 2 PHYSICAL RECORD: n_fields 10; compact format; info bits 0 0: len 8; hex 8000000000000001; asc ;; 1: len 6; hex 000001d9b9bd; asc ;; 2: len 7; hex d4000013250110; asc % ;; 3: len 15; hex 383630353939303033303139313731; asc 860599003019171;; 4: len 1; hex 32; asc 2;; 5: len 8; hex 3230313930313239; asc 20190129;; 6: SQL NULL; 7: len 19; hex 323031392d30312d32392032303a35353a3336; asc 2019-01-29 20:55:36;; 8: len 1; hex 31; asc 1;; 9: len 8; hex 3230313930323238; asc 20190228;;*** (2) WAITING FOR THIS LOCK TO BE GRANTED:RECORD LOCKS space id 7448 page no 6241 n bits 88 index `PRIMARY` of table `IotProductDB`.`production_log_t` trx id 60863913 lock_mode X waitingRecord lock, heap no 15 PHYSICAL RECORD: n_fields 29; compact format; info bits 0 0: len 8; hex 800000000003db53; asc S;; 1: len 6; hex 000003a0b5e1; asc ;; 2: len 7; hex 640000c01821ed; asc d ! ;; 3: len 16; hex 53494d50323031393130323132353838; asc SIMP201910212588;; 4: SQL NULL; 5: len 20; hex 3839383630323230313930353238303136313931; asc 89860220190528016191;; 6: len 25; hex 53494d50323031393130323132353838343338393031323237; asc SIMP201910212588438901227;; 7: len 20; hex 3839383532303030333633313036303539393836; asc 89852000363106059986;; 8: len 15; hex 343534303036333130363035393938; asc 454006310605998;; 9: len 1; hex 30; asc 0;; 10: len 1; hex 31; asc 1;; 11: len 4; hex 31303032; asc 1002;; 12: len 3; hex 4e5454; asc NTT;; 13: len 4; hex 38303035; asc 8005;; 14: len 7; hex e5928ce8aeb033; asc 3;; 15: len 12; hex 363446303030363446303130; asc 64F00064F010;; 16: len 30; hex 3230323b3230343b3230363b3230383b3231323b3231333b3231343b3231; asc 202;204;206;208;212;213;214;21; (total 499 bytes); 17: len 20; hex 3839383630323230313930353238303136313931; asc 89860220190528016191;; 18: len 30; hex 393836383230303239313530383231303136313930383439343530303336; asc 986820029150821016190849450036; (total 134 bytes); 19: len 20; hex 3938363832303032393135303832313031363139; asc 98682002915082101619;; 20: len 8; hex 3442314534304343; asc 4B1E40CC;; 21: SQL NULL; 22: len 1; hex 32; asc 2;; 23: len 19; hex 323031392d31302d32312031363a33333a3137; asc 2019-10-21 16:33:17;; 24: len 19; hex 323031392d31302d32312031393a30313a3033; asc 2019-10-21 19:01:03;; 25: len 19; hex 323031392d31302d32342031313a34373a3539; asc 2019-10-24 11:47:59;; 26: len 4; hex 30303030; asc 0000;; 27: len 7; hex 73756363657373; asc success;; 28: SQL NULL;*** WE ROLL BACK TRANSACTION (1) 第二次压测后获取的日志： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061LATEST DETECTED DEADLOCK------------------------2019-10-24 17:19:49 7f00f773b700*** (1) TRANSACTION:TRANSACTION 60872312, ACTIVE 5 sec starting index readmysql tables in use 1, locked 1LOCK WAIT 6822 lock struct(s), heap size 718376, 1154441 row lock(s), undo log entries 4MySQL thread id 382928, OS thread handle 0x7f01e4c69700, query id 10489419 123.58.107.133 iottest updatingUPDATE simcard_production_task_t SET actual_quantity=actual_quantity+1 WHERE task_no=IN_TASKNO*** (1) WAITING FOR THIS LOCK TO BE GRANTED:RECORD LOCKS space id 6713 page no 4 n bits 184 index `task_no` of table `IotProductDB`.`simcard_production_task_t` trx id 60872312 lock_mode X locks rec but not gap waitingRecord lock, heap no 111 PHYSICAL RECORD: n_fields 2; compact format; info bits 0 0: len 16; hex 53494d50323031393130323132353838; asc SIMP201910212588;; 1: len 8; hex 8000000000000346; asc F;;*** (2) TRANSACTION:TRANSACTION 60872310, ACTIVE 5 sec fetching rowsmysql tables in use 1, locked 16355 lock struct(s), heap size 570920, 128099 row lock(s), undo log entries 1MySQL thread id 382968, OS thread handle 0x7f00f773b700, query id 10489628 123.58.107.133 iottest Sending dataSELECT COUNT(*) INTO V_CVT FROM production_log_t WHERE task_no=IN_TASKNO AND (`status`=&apos;0&apos; OR `status`=&apos;1&apos;) FOR UPDATE*** (2) HOLDS THE LOCK(S):RECORD LOCKS space id 6713 page no 4 n bits 184 index `task_no` of table `IotProductDB`.`simcard_production_task_t` trx id 60872310 lock_mode X locks rec but not gapRecord lock, heap no 111 PHYSICAL RECORD: n_fields 2; compact format; info bits 0 0: len 16; hex 53494d50323031393130323132353838; asc SIMP201910212588;; 1: len 8; hex 8000000000000346; asc F;;*** (2) WAITING FOR THIS LOCK TO BE GRANTED:RECORD LOCKS space id 7448 page no 6253 n bits 80 index `PRIMARY` of table `IotProductDB`.`production_log_t` trx id 60872310 lock_mode X waitingRecord lock, heap no 7 PHYSICAL RECORD: n_fields 29; compact format; info bits 0 0: len 8; hex 800000000003db35; asc 5;; 1: len 6; hex 000003a0d678; asc x;; 2: len 7; hex 3f000001770f1b; asc ? w ;; 3: len 16; hex 53494d50323031393130323132353838; asc SIMP201910212588;; 4: SQL NULL; 5: len 20; hex 3839383630323230313930353238303135313938; asc 89860220190528015198;; 6: len 25; hex 53494d50323031393130323132353838343338383938333632; asc SIMP201910212588438898362;; 7: len 20; hex 3839383532303030333633313036303431323038; asc 89852000363106041208;; 8: len 15; hex 343534303036333130363034313230; asc 454006310604120;; 9: len 1; hex 30; asc 0;; 10: len 1; hex 31; asc 1;; 11: len 4; hex 31303032; asc 1002;; 12: len 3; hex 4e5454; asc NTT;; 13: len 4; hex 38303035; asc 8005;; 14: len 7; hex e5928ce8aeb033; asc 3;; 15: len 12; hex 363446303030363446303130; asc 64F00064F010;; 16: len 30; hex 3230323b3230343b3230363b3230383b3231323b3231333b3231343b3231; asc 202;204;206;208;212;213;214;21; (total 499 bytes); 17: len 20; hex 3839383630323230313930353238303135313938; asc 89860220190528015198;; 18: len 30; hex 393836383230303239313530383231303135383930383439343530303336; asc 986820029150821015890849450036; (total 134 bytes); 19: len 20; hex 3938363832303032393135303832313031353839; asc 98682002915082101589;; 20: len 8; hex 4441424139303231; asc DABA9021;; 21: SQL NULL; 22: len 1; hex 32; asc 2;; 23: len 19; hex 323031392d31302d32312031363a33333a3137; asc 2019-10-21 16:33:17;; 24: len 19; hex 323031392d31302d32312031393a30303a3531; asc 2019-10-21 19:00:51;; 25: len 19; hex 323031392d31302d32342031373a31393a3434; asc 2019-10-24 17:19:44;; 26: len 4; hex 30303030; asc 0000;; 27: len 7; hex 73756363657373; asc success;; 28: SQL NULL;*** WE ROLL BACK TRANSACTION (2) 其可以确定是这条语句出现死锁，但是出现顺序暂时没分析明白，明天再更新。 1SELECT COUNT(*) INTO V_CVT FROM production_log_t WHERE task_no=IN_TASKNO AND (`status`=&apos;0&apos; OR `status`=&apos;1&apos;) FOR UPDATE]]></content>
      <categories>
        <category>MYSQL</category>
      </categories>
      <tags>
        <tag>MYSQL</tag>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Solidity编程语言（13）--地址（Address）]]></title>
    <url>%2F2019%2F07%2F22%2FSolidity%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80%EF%BC%8813%EF%BC%89-%E5%9C%B0%E5%9D%80%EF%BC%88Address%EF%BC%89%2F</url>
    <content type="text"><![CDATA[这里要说的地址并不是通常的编程语言中的内存地址，而是交易地址。我们知道区块链进行价值传递的时候必须是通过一个地址传递到另一个地址，无论交易或者合约都离不开地址。因此把地址作Address为Solidity语言的内嵌数据类型会十分方便开发的，更重要的一点就是在Solidity中，所有合约都继承地址Address类型。这不仅仅是单纯的为了在语法上的实现，而在实际情况是合约本身就离不开地址，包括合约的部署和执行都需要地址的参与。地址是两种类型，一种是address，一种是address payable。其中address payable相比address类型多了两个成员方法send和transfer，表示可以向address payable类型的变量进行转帐操作。 ###地址类型格式要求以太坊中的地址是20个字节，比如0x52908400098527886E0F7030069857D2E4169EE7，由于一个字节等于8位，所以地址也可以使用uint160来声明。地址通常可以进行比较运算。 123456789101112131415pragma solidity &gt;=0.4.0 &lt;0.6.0;contract EgAddress&#123; function testType() public &#123; address _addr = 0x52908400098527886E0F7030069857D2E4169EE7; uint160 _addi = 471360049350540642640628028220064440840608208820; string memory h = hex&quot;52908400098527886E0F7030069857D2E4169EE7&quot;; address addr = address(_addi); //addr = address(h); uint160 addi = uint160(_addr); &#125;&#125; 注意的是hex类型是不能直接和address进行转换的 address虽然是十六进制串，address是有格式要求的，检验方法是可参考EIP55###合约地址我们知道每个合约都是径过一个帐户部署到区块连上的，同时这个合约也会生成一个地址，并可以向这个合约地址进行转帐操作。那么这个部署的帐户地址和合约地址是怎么得到呢。 123456789101112131415161718192021pragma solidity &gt;=0.4.0 &lt;0.6.0;contract EgAddress&#123; address public owner; constructor() public &#123; owner = msg.sender; &#125; function getOwner() public returns(address)&#123; return owner; &#125; function getContractAddr() public view returns(address)&#123; return address(this); &#125; function getSenderAddr() public returns (address)&#123; return msg.sender; &#125;&#125; msg.sender是内置方法，他返回当前方法的调用者地址，也就是说我通过A帐户调用合约方法getSenderAddr，则返回的是A的地址，通过B帐户调用合约方法getSenderAddr，则返回的是B的地址。（另外还有msg.value和msg.data都通过调用者传进来的数据） 构造函数constructor是在合约进行部署时执行，且只执行一次。 在获取合约的创建者则是通过“曲线”的方式获取，首先声明状态变量owner，接着在构造函数中将方法的调用者的地址赋值给owner，因为构造函数只有在合约创建时才会被调用，所以owner保存的就是合约创建者的地址，最后通过公有方法getOwner将状态变量的值返回出去。 在获取合约本身的地址是通过this来获取，旧的版本可能this本身就是address类型的，可以直接返回this，但本示例中的版本需要将this是EgAddress类型的，需要做个类型转换才能返回address类型。###成员变量balance每个地址都代表着一个价值的持有者，所以可以直接查看其余额，即通过balance属性###成员方法除了成员变量balance外，还有以下几个成员方法 成员方法 &lt;address&gt;.balance (uint256) &lt;address payable&gt;.transfer(uint256 amount) &lt;address payable&gt;.send(uint256 amount) returns (bool) &lt;address&gt;.call(bytes memory) returns (bool, bytes memory) &lt;address&gt;.delegatecall(bytes memory) returns (bool, bytes memory) &lt;address&gt;.staticcall(bytes memory) returns (bool, bytes memory) 123456789101112131415161718192021222324252627282930313233pragma solidity &gt;=0.4.0 &lt;0.6.0;contract EgAddress&#123; function testSend()payable public &#123; address payable to = 0x52908400098527886E0F7030069857D2E4169EE7; to.send(msg.value); &#125; function testTranser()payable public &#123; address payable to = 0x52908400098527886E0F7030069857D2E4169EE7; to.transfer(msg.value); &#125; function testStack1024(uint depth) payable public&#123; address payable to = 0x52908400098527886E0F7030069857D2E4169EE7; bool r = to.send(1 wei); if (depth &gt;1 &amp;&amp; r)&#123; testStack1024(depth -1); &#125; &#125; /*function testCSend() payable public &#123; address payable to = address(this); this.send(msg.value); address(this).send(msg.value); &#125;*/ /*function testCTranser()payable public &#123; // address payable to = 0x52908400098527886E0F7030069857D2E4169EE7; address(this).transfer(msg.value); &#125;*/&#125; send send方法相比较transfer方法来说更“底层”一些，如果send方法执行失败，并不会抛出异常，而是返回false。 send调用栈深度不能超过1024，否则会执行失败。这个问题在testStack1024方法中进行了验证，不过传入的数字太大的话，会执行失败，即使没到1024，原因还没找到。。。。。 send方法会返回bool类型的结果来表示执行结果 如果gas不够会执行失败 建议使用transfer方法，相对更安全些 transfer transfer和send使用方法上一样，也是用来进行转帐操作，如果当前帐户余额不足或者对方帐户拒绝转帐，则会执行失败。 如果transfer的调用地址是一个合约地址，则合约的回调函数将被执行 关call及delegatecall、staticcall单独使用一篇幅来讲]]></content>
      <categories>
        <category>solidity</category>
      </categories>
      <tags>
        <tag>区块链</tag>
        <tag>solidity</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Solidity编程语言（12）--结构体struct]]></title>
    <url>%2F2019%2F07%2F22%2FSolidity%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80%EF%BC%8812%EF%BC%89-%E7%BB%93%E6%9E%84%E4%BD%93struct%2F</url>
    <content type="text"><![CDATA[使用结构体struct可以自定义数据类型，结构体内可以包含除自身以外的所有数据类型，如果包含自身则会形成递归。 ###定义与初始化 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051pragma solidity &gt;=0.4.0 &lt;0.6.0;contract EgStruct &#123; mapping (string =&gt; Book) bookList; struct Book&#123; string name; uint pages; string[] contents; &#125; struct Reader&#123; mapping (string =&gt; Book) books; string name; &#125; Reader r; function init() public&#123; string[] memory b1c = new string[](3); b1c[0] = &quot;1.0.1&quot;; b1c[1] = &quot;1.0.2&quot;; b1c[2] = &quot;2.0.1&quot;; Book memory b1 = Book(&quot;book1&quot;,10,b1c); Book memory b2 = Book(&#123; name:&quot;book2&quot;, pages:20, contents:b1c &#125;); Reader memory r1 = Reader(&quot;jack&quot;); Reader memory r2 = Reader(&#123; name:&quot;rosh&quot; &#125;); // Reader memory r2 = Reader(bookList,&quot;jack&quot;); // Reader memory r3 = Reader(&#123; // books:bookList, // name:&quot;rosh&quot; // &#125;); r = r2; r.books[&quot;book1&quot;] = b1; //r2.bookList[&quot;book2&quot;] = b2; //r2.books = bookList; //r.books = bookList; &#125;&#125; 结构体struct的初始化有两种方式，一种是Book(“book1”,10,b1c)，需要按结构体的非mapping定义顺序传入，一种种Book({name:”book2”,pages:20,contents:b1c }) 当结构体中包含mapping成员时，初始化的时候不能对mapping成员进行传参赋值 结构体的mapping成员变量是不能直接去引用其他mapping的（storage），不管该结构体对象是storage还是memory 只有结构体对象是状态变量（storage）的，才能使用其mapping成员进行赋值操作###可见性 12345678910111213141516171819202122232425262728293031323334pragma solidity &gt;=0.4.0 &lt;0.6.0;contract EgStruct &#123; struct Book&#123; string name; uint pages; &#125; function read(Book memory b) internal&#123;&#125; function callTmp(EgStructTmp tmp) public&#123; Book memory b = Book(&quot;jingpinmei&quot;,10); tmp.seal(b.name,b.pages); &#125;&#125;contract EgStructSub is EgStruct&#123; function write(Book memory b) internal&#123;&#125;&#125;contract EgStructOut &#123; /*function seal(Book memory b) &#123;&#125;*/&#125;contract EgStructTmp&#123; struct Book&#123; string name; uint pages; &#125; function seal(string memory name, uint pages) public &#123; Book memory b = Book(name, pages); &#125;&#125; Solidity中的结构只在当前合约或者子类合约中可用，外部是不可见的，而且使用结构体的函数需要修饰为internal。 非要这么做的话，则可以通过函数调用进行传递基本类型的数据，然后再次组装成同样的结构体###数组参数这里有碰到个问题就是在函数参数不能是不固定的复杂类型参数，下边代码中seal1就无法编译通过 12345678910111213141516pragma solidity &gt;=0.4.0 &lt;0.6.0;contract EgStructTmp&#123; struct Book&#123; string name; uint pages; &#125; function seal1(string memory name, uint pages,string[] memory s) public &#123; Book memory b = Book(name, pages); &#125; function seal2(string memory name, uint pages, string[] memory s) internal &#123; Book memory b = Book(name, pages); &#125;&#125;]]></content>
      <categories>
        <category>solidity</category>
      </categories>
      <tags>
        <tag>区块链</tag>
        <tag>solidity</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Solidity编程语言（11）--枚举enum]]></title>
    <url>%2F2019%2F07%2F22%2FSolidity%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80%EF%BC%8811%EF%BC%89-%E6%9E%9A%E4%B8%BEenum%2F</url>
    <content type="text"><![CDATA[Solidity中枚举类型与其他编程语言基本一样。我们来看一个例子，比如定义个季节的枚举。 123456789101112131415161718192021222324pragma solidity &gt;=0.4.0 &lt;0.6.0;contract EgEnum&#123; enum Season&#123;Spring, Summer, Autumn, Winter&#125; function printSeason(Season s) public returns(Season) &#123; return s; &#125; function test1() public returns(Season)&#123; return printSeason(Season.Spring); &#125; function test2() public returns(uint)&#123; uint s = uint(Season.Spring); return s; &#125; function test3() public returns(Season)&#123; //Season s = Season(5);//越界 Season s = Season(3); return s; &#125;&#125; enum的实际类型是无符号整数，当枚举数量是0-127范围内，则enum是uint8类型的，如果是0-32,767范围内，则enum是uint16类型的，以次类推。 既然enum是uint类型，则可以进行类型转换，比如uint s = uint(Season.Spring)是将枚举Season类型转换在uint，当然也可以转成uint8，只要不越界就可以。同样Season s = Season(3)是将uint转成Season类型的。同样需要注意的是整数不要超过枚举的范围，比如Season的范围是0-3，如果将5转换成Season则会在运行进出现异常，而编译可以通过。]]></content>
      <categories>
        <category>solidity</category>
      </categories>
      <tags>
        <tag>区块链</tag>
        <tag>solidity</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Solidity编程语言（10）--十六进制串]]></title>
    <url>%2F2019%2F07%2F22%2FSolidity%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80%EF%BC%8810%EF%BC%89-%E5%8D%81%E5%85%AD%E8%BF%9B%E5%88%B6%E4%B8%B2%2F</url>
    <content type="text"><![CDATA[个人觉得十六进制串hex并不是一种Solidity的数据类型，因为你无法将hex作为一个类型去使用。当把hex加到字面量前的时候，其作用就是限定了字面量的数据格式，必须是偶数位的[0-9a-fA-F]的字符串。这样当使用特定的数据类型去引用hex串的时候，隐式的会进行转换。比如string memory h = hex”010A31”，转换后的字符串h实际内容是\u0001\n1。另外在使用bytes4类型的固定长度字节数组进行引用时，hex长度不能超过引用类型的实际长度，比如bytes4 b = hex”AABBccddee”是无法编译的。 1234567891011121314151617181920212223242526pragma solidity &gt;=0.4.0 &lt;0.6.0;contract EgHex&#123; function test() public returns(string memory)&#123; string memory h = hex&quot;010A31&quot;; //string memory h = hex&quot;010G&quot; return h; &#125; function test1() public returns(string memory)&#123; string memory h = hex&quot;010A&quot;; return h; &#125; function test2() public returns(bytes4)&#123; //bytes4 b = hex&quot;AABBccddee&quot;; bytes4 c = hex&quot;AABB&quot;; bytes4 b = hex&quot;AABBccdd&quot;; return b; &#125; function test3() public returns(bytes memory)&#123; bytes memory b = hex&quot;AABBccdd&quot;; return b; &#125;&#125;]]></content>
      <categories>
        <category>solidity</category>
      </categories>
      <tags>
        <tag>区块链</tag>
        <tag>solidity</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Solidity编程语言（9）--mapping]]></title>
    <url>%2F2019%2F07%2F22%2FSolidity%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80%EF%BC%889%EF%BC%89-mapping%2F</url>
    <content type="text"><![CDATA[###mapping的使用特性mapping是用来保存键值对的，其书写方式与一般的编程语言有些不同，mapping(keyType =&gt; valueType)。mapping只能使用在合约的状态变量中，或者在函数内进行storage的引用，如var storage mappVal的用于存储状态变量的引用的对象，不能使用非状态变量来初始化这个引用，也就是mapping最终会保存在区块链上的，不可能是内存型变量。 123456789101112pragma solidity &gt;=0.4.0 &lt;0.6.0;contract EgMapping&#123; mapping(uint =&gt; string) public kvs; function put () public&#123; kvs[1] = &quot;a&quot;; kvs[2] = &quot;b&quot;; mapping(uint =&gt; string) storage kvs1 = kvs; string memory a = kvs[1]; &#125;&#125; mapping的key可以使用除了mapping类型以外的所有类型，value没有任何限制。 mapping实际上并不存储key的值，而是把key转换成keccak256的哈希值进行存储，所以通过mapping是无法获取保存的key的。 mapping只能用来定义状态变量，如果要在函数内部使用的话，则也需要将其声名为一个storage类型的引用，引用指向的是还是状态变量。###CURD操作 增加元素，比如kvs[1] = “a”。 更新元素，和增加一样，只不过key已经存在了。 查找元素，比如string memory a = kvs[1]。 删除元素，使用关键delete，比如delete kvs[1]。注意delete操作修改的是状态变量，所以会有gas的消耗，一般不会轻易的delete元素的。###遍历上边已经知道mapping是不保存key的值的，所以无法进行mapping的直接遍历。但是如果把key保存下来不就可以进行遍历了吗。其具体实现可以看这个工具包，是将key保存到一个不固定长度的数组中，所以你在插入元素的时候也需要使用这个工具包的插入方法。]]></content>
      <categories>
        <category>solidity</category>
      </categories>
      <tags>
        <tag>区块链</tag>
        <tag>solidity</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Solidity编程语言（8）--字节数组]]></title>
    <url>%2F2019%2F07%2F22%2FSolidity%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80%EF%BC%888%EF%BC%89-%E5%AD%97%E8%8A%82%E6%95%B0%E7%BB%84%2F</url>
    <content type="text"><![CDATA[字节数组可以看作一种特殊的数组，其元素类型是字节。在类型声名时有其专有的声名方式。作为数组他有不固定长度字节数组和固定长度字节数组。 ###不固定长度字节数组 ###固定长度字节数组 123456789101112131415161718pragma solidity &gt;=0.4.0 &lt;0.6.0;contract EgFixedByteArray &#123; byte[5] ba5; bytes5 bs5; function modify() public&#123; ba5 = [byte(&apos;1&apos;),&apos;2&apos;,&apos;3&apos;,&apos;4&apos;,&apos;5&apos;]; //ba5.push(6); //ba5.length = 6; //bs5 = [byte(&apos;1&apos;),&apos;2&apos;,&apos;3&apos;,&apos;4&apos;,&apos;5&apos;]; ba5[1] = &apos;0&apos;; bs5 = &apos;12345&apos;; //bs5.length = 6; //bs5.push(6); //bs5[1] = &apos;0&apos;; &#125;&#125; 固定长度字节数组可以使用以下两种方式声名，一种是使用数组声名，一种是使用关键字声名，其中bytes后边的数字范围是从1至32，即不能使用bytes33。在实际编码中，如果确定长度最好使用这种方式。 byte[5] bs5; bytes5 bs5_; 不管哪种方式声名的，都不可以修改length以及使用push方法 bytes5这种方式的声名不能使用数组来进行赋值的 bytes5这种方式声名的字节数组其内容是不可修改的###不固定长度字节数组（动态数组）不固定长度字节数组同理也有两种方式声名，数组和关键字。数组方式其特性就是数组的特性，这里我们看下使用关键字bytes的方式12345678910111213pragma solidity &gt;=0.4.0 &lt;0.6.0;contract EgUnFixedByteArray &#123; bytes name = new bytes(5); function modifyName() public returns( bytes memory) &#123; name.length = 6; name.push(&apos;9&apos;); name[1] = &apos;1&apos;; return name; &#125;&#125; ###转换这里主要说下固定长度字节数组、不固定长度字节数组以及string之间的转换 固定长度字节数组之间的转换12345678contract EgSwitchBytes&#123; function switchBytes1() public returns(bytes2) &#123; bytes2 bs2 = &apos;12&apos;; bytes5 bs5 = &apos;00000&apos;; //return bytes2(bs5); return bytes2(bs5); &#125;&#125; 长度较长的固定长度字节数组可以转成转短的，反过来则不行，而长的转成短的会将后边的部分长度截取掉，比如上边的bs5转成bytes2的时候会把‘234’截取掉的。 固定长度字节数组和不固定长度字节数组或者string的转换function switchBytes2() public { /*bytes5 bs5 = &apos;00000&apos;; bytes bs = bytes(bs5);//固定长度字节数组与不固定长度字节数组不能直接转换 bytes memory bs = new bytes(10); bytes5 bs5 = bytes5(bs);//固定长度字节数组与不固定长度字节数组不能直接转换 */ bytes memory bs = new bytes(10); string memory str = string(bs); string memory str1 = &quot;abcd&quot;; bytes memory bs1 = bytes(str1); /*bytes5 memory bs5 = &apos;00000&apos;; string memory str2 = string(bs5);//固定长度字节数组与string不能直接转换 string memory str3 = &quot;abcd&quot;; bytes5 memory bs5_ = bytes5(str3);//固定长度字节数组与string不能直接转换 */ }固定长度字节数组与不固定长度字节数组或者string（本质也是不固定长度字节数组）不能互相直接转换，但是string和bytes可以。 怎么转换固定长度字节数组这里说下思路，就是遍历固定长度字节数组，然后逐个把元素赋值到不固定长度字节数组中，这样就得到了不固定长度字节数组，也可以再次通过不固定长度字节数组转换成string。其中有个问题是比如bytes5 bs5 = ‘1’，本来bs5的类型是bytes5，也就是应该包含5个字节，但实际只赋值了‘1’，那么其余4个字节是啥呢？是空的，也就是\u0000，即空字符（不是空格，也不是null），所以在遍历的时候会把四个\u0000也进行了遍历。导致不固定长度字节数组中包含了4个\u0000，转成的string也有问题。所在在转换的时候要考虑\u0000的问题。 bytes和string是一种特殊的数组。bytes类似byte[]，但在外部函数作为参数调用中，会进行压缩打包，更省空间，所以应该尽量使用bytes4。string类似bytes，但不提供长度和按序号的访问方式。]]></content>
      <categories>
        <category>solidity</category>
      </categories>
      <tags>
        <tag>区块链</tag>
        <tag>solidity</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Solidity编程语言（7）--数组]]></title>
    <url>%2F2019%2F07%2F22%2FSolidity%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80%EF%BC%887%EF%BC%89-%E6%95%B0%E7%BB%84%2F</url>
    <content type="text"><![CDATA[在solidity中，数组分为固定长度数组和不固定长度数组，顾名思义就是在声名后的数组长度是否可以发生变化。 ###固定长度数组 123456789101112131415161718pragma solidity &gt;=0.4.0 &lt;0.6.0;contract EgFixedArray &#123; uint[5] arr1 = [1,2,3,4,5]; //uint[5] arr1 = []; //uint[5] arr2 = new uint[](5); function modifyLen()public&#123; // arr1.length = 2;编译失败 &#125; function modifyElement()public &#123; arr1[1] = 3; &#125; function pushToArray() public&#123; // arr1.push(1);编译失败 &#125;&#125; 固定长度数组必须初始化元素，并且无法通过new来创建。 固定长度数组的长度length属性是不可以修改的，否则会报编译错误。 固定长度数组元素是可以修改的，但是需要通过索引操作。 固定长度数组不可以使用push方法，编译无法通过。###不固定长度数组 1234567891011121314151617pragma solidity &gt;=0.4.0 &lt;0.6.0;contract EgUnFixedArray &#123; //uint[] arr1 = [1,2,3,4,5]; uint[] arr1 = new uint[](5); function modifyLen()public&#123; arr1.length = 2; &#125; function modifyElement()public &#123; arr1[1] = 3; &#125; function pushToArray() public &#123; arr1.push(1); &#125;&#125; 不固定长度数组，可以通过new来声名，元素默认取值为数组类型的默认值。 length可以修改，如果修改的length小于原先，则数组元素从后往前被去掉。 元素可以修改 可以使用push方法，push之后数据长度加一，push方法返回的是数组的长度###memory修饰数组 123456function modifyMemoryArr() public returns(uint)&#123; uint8[5] memory arr2 = [1,2,3,4,5]; // arr2.push(6); // arr2.length = 6; return arr2.length;&#125; memory修饰的数组必须指定数组长度 memory修饰的数组不能使用push方法 memory修饰的数组不能修改length属性 1234function inputArr(uint[5] arr) public&#123; // arr.length = 6; // arr.push(6);&#125; 对于方法参数是数组类型的参数，其默认也是memory修饰的，所以也无法使用length属性和push方法 123456function assignment() public&#123; // uint[] memory x = [uint(1), 3, 4]; // uint[] x = [uint(1), 3, 4]; uint[3] memory x = [uint(1), 3, 4]; uint[] memory x1 = new uint[](3);&#125; 固定长度数组不能赋值于memory修饰的不固定长度数组 不固定长度数组不能使用数组字面量进行赋值123456789function testReturn1() public returns(uint[3] memory)&#123; uint[3] memory u1 = [uint(1),2,3]; return u1;&#125;function testReturn2() public returns(uint[] memory)&#123; uint[] memory u2 = new uint[](5); return u2;&#125; 网上有看到说是返回值不能使用不固定长度数组，我使用0.5.2的solidity版本验了一下是可以的。有可能是旧版本不行吧。]]></content>
      <categories>
        <category>solidity</category>
      </categories>
      <tags>
        <tag>区块链</tag>
        <tag>solidity</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Solidity编程语言（6）--字符串]]></title>
    <url>%2F2019%2F07%2F22%2FSolidity%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80%EF%BC%886%EF%BC%89-%E5%AD%97%E7%AC%A6%E4%B8%B2%2F</url>
    <content type="text"><![CDATA[字符串的定义使用单引号或双引号都可以。这里主要说一下有关string的常见操作，在solidity中不是很方便。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667pragma solidity &gt;=0.4.0 &lt;0.6.0;//import &quot;github.com/Arachnid/solidity-stringutils/strings.sol&quot;;contract EgString &#123; string name = &apos;buff&apos;; string addr = &quot;beijing&quot;; function getAddrLength()public returns(uint)&#123; return bytes(addr).length;//获取字符串 &#125; function concatenateWithAbi ()public returns(string memory)&#123; return string(abi.encodePacked(name, addr)); &#125; /*function concatenateWithGit() public returns(string memory)&#123; return name.toSlice().concat(addr.toSlice()); &#125;*/ function compare1() public returns(bool)&#123; return keccak256(bytes(name)) == keccak256(bytes(addr)); &#125; function compare2() public returns (bool)&#123; for (uint i = 0; i &lt; bytes(name).length; i ++) &#123; if(bytes(name)[i] != bytes(addr)[i]) &#123; return false; &#125; &#125; &#125;/* // parseInt(parseFloat*10^_b) function parseInt(string memory _a, uint _b) internal returns (uint) &#123; bytes memory bresult = bytes(_a); uint mint = 0; bool decimals = false; for (uint i=0; i&lt;bresult.length; i++)&#123; if ((bresult[i] &gt;= 48)&amp;&amp;(bresult[i] &lt;= 57))&#123; if (decimals)&#123; if (_b == 0) break; else _b--; &#125; mint *= 10; mint += uint(bresult[i]) - 48; &#125; else if (bresult[i] == 46) decimals = true; &#125; if (_b &gt; 0) mint *= 10**_b; return mint; &#125; function uint2str(uint i) internal returns (string memory) &#123; if (i == 0) return &quot;0&quot;; uint j = i; uint len; while (j != 0)&#123; len++; j /= 10; &#125; bytes memory bstr = new bytes(len); uint k = len - 1; while (i != 0)&#123; bstr[k--] = byte(48 + i % 10); i /= 10; &#125; return string(bstr); &#125;*/&#125; ###长度字符串长度的获取需要将string转换成bytes，然后使用bytes的length属性获取长度。 ###拼接 字符串拼接，官网上给出的方法是使用abi.encodePacked方法 也可以自己写一个方法，思路就是把string转换成bytes，然后将bytes合并成一个大的bytes，最后再将结果bytes转换成string。其中bytes与string转换方法为bytes(string),string(bytes)，这里就不写代码了。 网上有人使用git上的一个工具包，不过我自己编译一直通不过，后续再查下原因。浏览了下代码，可以学习下。###比较Solidity同样不支持字符串的比较，需要自己实现，这里提供两种方式（这里不包含其他的工具包方式），当然出于性能要求以及gas消耗情况，可以首先对字符串的长度进行比较，然后再比较内容。这个文章写的不错，而且有gas消耗测试统计。 比较两字字符串的hash是否相等 逐个比较每个字符###int转换Solidity同样不支持string与int的互相转换。这里可以直接查看工具类oraclize。其转换思路就是把string首先转换成bytes类型，然后逐个遍历，进行数值累加。]]></content>
      <categories>
        <category>solidity</category>
      </categories>
      <tags>
        <tag>区块链</tag>
        <tag>solidity</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Solidity编程语言（5）--布尔型和整型]]></title>
    <url>%2F2019%2F07%2F22%2FSolidity%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80%EF%BC%885%EF%BC%89-%E5%B8%83%E5%B0%94%E5%9E%8B%E5%92%8C%E6%95%B4%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[布尔型bool类型同其他语言一样，取值为true或false， 其运算操作有!、||、&amp;&amp;、!=、==，注意这里并没有|、&amp; 12345678910111213141516171819202122232425262728293031pragma solidity &gt;=0.4.22 &lt;0.6.0;contract EgBool &#123; bool isOne; bool isTwo; function operation() public &#123; isOne = true; if (isOne)&#123; // dosomething &#125; if (!isOne)&#123; // dosomething &#125; if (isOne || isTwo )&#123; // dosomething &#125; if (isOne &amp;&amp; isTwo )&#123; // dosomething &#125; if (isOne != isTwo )&#123; // dosomething &#125; if (isOne == isTwo )&#123; // dosomething &#125; &#125;&#125; 整型整型包含无符号uint和有符号int两种类型，每种类型有多种长度，比如uint8、uint64、int128等等，长度范围是8至256，相差8个长度，8，16，24，32……256。其中uint和uint256一样，int和int256一样。运算操作有比较、位操作和算术操作三种。 比较操作：&lt;= , &lt; , == , != , &gt;= , &gt; 位操作： &amp;(与） , |(或) , ^ (异或)， ~ (非） 算术操作：+ , - , * , /, % , (乘方，求幂) ，&lt;&lt;(左移) , &gt;&gt;(右移)其中左移和右移操作，a&lt;&lt;b，可以理解为a乘以2的b次方，表示为a*2b，同理右移a&gt;&gt;b表示为a/2**b。123456789101112131415161718192021222324252627282930313233343536373839pragma solidity &gt;=0.4.22 &lt;0.6.0;contract EgInt &#123; int i = 0; int8 i8 = -1; int256 i256 = 256; uint ui = 0; uint ui8 = 1; uint256 ui256 = 256; function operation() public &#123; if ( i &lt; i8 || i &lt;= i8 || i == i8 || i != i8 || i &gt; i8 || i &gt;= i8 )&#123; //dosomeing &#125; int a; int b; int c; c = a &amp; b; c = a | b; c = a ^ b; c = ~ b; c = a + b; c = a - b; c = a * b; c = a / b; c = a % b; c = a &lt;&lt; b; c = a &gt;&gt; b; //c = a**b; uint d; uint e; uint f; f = d**e; //c = d**e; &#125;&#125; 注意 有符号整数是不能够使用”**”操作， 有符号和无符号不能进行类型转换，不能同时参数运算，比如c = d + e;]]></content>
      <categories>
        <category>solidity</category>
      </categories>
      <tags>
        <tag>区块链</tag>
        <tag>solidity</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Solidity编程语言（4）--HelloWorld]]></title>
    <url>%2F2019%2F07%2F22%2FSolidity%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80%EF%BC%884%EF%BC%89-HelloWorld%2F</url>
    <content type="text"><![CDATA[智能合约就像是一份合同一样，你书写的每个代码都是合同的内容。所以合约一经部署，合约内容就无法修改，好比你和别人签苹写了合同之后，是没法再修改的。这也是正是基于区块链不可篡改的特性。在通常的编程语言中，一般会使用标准输出来打印“Hello World”，Solidity作为一门智能合约编程语言，是有别与一般的编程语言，他是基于以太坊，并且是用来编写“合约”的。所以这里不再使用“HelloWorld”作为示例，而是使用Solidity官网中的一个入门示例。 12345678910pragma solidity &gt;=0.4.0 &lt;0.6.0;contract SimpleStorage &#123; uint storedData; function set(uint x) public &#123; storedData = x; &#125; function get() public view returns (uint) &#123; return storedData; &#125;&#125; 以上代码就是一个使用Solidity编写的名为SimpleStorage的合约。 第一行代码是用来指定Solidity的语言版本，pragma solidity是固定格式，后边加上版本号，版本号通过范围来确定的，即大等于0.4.0，小于0.6.0。在网上会经常看到^0.4.21这样的书写方式，这种格式是支持在0.5.2及之前的版本。比如在remix-ide环境中编写pragma solidity ^0.5.3，则会提示编译错误：browser/Untitled.sol:3:1: ParserError: Source file requires different compiler version (current compiler is 0.5.2+commit.1df8f40c.Emscripten.clang - note that nightly builds are considered to be strictly less than the released version。 第二代码创建名为SimpleStorage的合约。contract 是关键字，SimpleStorage为合约名称。这个类似于java的类定义一样，class Person{}，比较容易理解。 第三行代码定了一个无符号整数storedData，这个状态变量将会保存在区块链上，好比写入数据库进行了持久化，什么时候都可以进行读取。 定义set方法，对状态变量storedData进行赋值，其中public是关键定，修饰set方法可以被合约外部调用。 定义get方法，返回状态变量storedData的值，对于返回值的书写稍有不同，关键字是returns，而不是return，另外返回值可以是多个，使用圆括号包起来。这就是一个简单的Solidity编写的合约了，有编程经验的人很容易理解。]]></content>
      <categories>
        <category>solidity</category>
      </categories>
      <tags>
        <tag>区块链</tag>
        <tag>solidity</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Solidity开发环境（3）--Mist]]></title>
    <url>%2F2019%2F07%2F22%2FSolidity%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%EF%BC%883%EF%BC%89-Mist%2F</url>
    <content type="text"><![CDATA[Remix是一个solidity的开发环境，他本身包含了EVM以及一些预置的帐户信息，所以可以进行测试开发。如果我们要把自己的合约部署到本地搭建的以太坊私链上要怎么做呢？一种是通过节点控制台命令将Remix生成的ABI和bytecode部署到私链上，一种是使用Mist钱包工具进行合约的部署（调用RPC接口进行部署）。 ###Mist安装 下载安装包http://upyun-assets.ethfans.org/mist/0-9-3/Mist-linux64-0-9-3.zip 解压后进入linux-unpacked目录 启动命令./mist –rpc http://127.0.0.1:9541 –swarmurl=http://swarm-gateways.net，其中–rpc参数用来指定我们私链节点的rpc地址。Mist不仅可以进行合约部署，最主要的是他可以查看合约部署状态，比如在哪个区块上，gas消耗待待。]]></content>
      <categories>
        <category>solidity</category>
      </categories>
      <tags>
        <tag>区块链</tag>
        <tag>solidity</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Solidity开发环境（2）--Remix-IDE]]></title>
    <url>%2F2019%2F07%2F22%2FSolidity%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%EF%BC%882%EF%BC%89-Remix-IDE%2F</url>
    <content type="text"><![CDATA[使用Remix来开发Solidity合约十分的方便，而且环境搭建也十分方便，他是通过web页面过行开发的。 ###在线Remix直接访问地址http://remix.ethereum.org/#optimize=false就可以进行开发，不过这种在线的方式是无法保存源码到本地，可以直接推到githup上。 ###本地npm安装本地安装直接使用npm命令就行（当然有些其他环境要求，这个安装过程中依情况解决），npm install remix-ide -g，安装后直接用行remix-ide命令，然后通过浏览器访问http://127.0.0.1:8080就可以看到开发界面了。 ###本地源码安装上边的安装结果是我们只能通过8080端口启动web服务，如果要修改成别的端口的话，本人尝试了一些命令参数都没有成功设置。不过可以通过源码进行修改，这样的话就需要下载源码了。下载地址是https://github.com/ethereum/remix-ide/。下载后修改文件/bin/remix-ide中的端口8080为其他端口即可。 1234567891011121314151617181920#!/usr/bin/env nodevar httpServer = require(&apos;http-server&apos;)var remixd = require(&apos;remixd&apos;)var server = httpServer.createServer(&#123; root: __dirname + &apos;/../&apos;&#125;)var folder = process.argv.length &gt; 2 ? process.argv[2] : process.cwd()server.listen(8080, &apos;127.0.0.1&apos;, function () &#123;&#125;)var router = new remixd.Router(65520, remixd.services.sharedFolder, &#123; remixIdeUrl: &apos;http://localhost:8080&apos; &#125;, (webSocket) =&gt; &#123; remixd.services.sharedFolder.setWebSocket(webSocket) remixd.services.sharedFolder.setupNotifications(folder) remixd.services.sharedFolder.sharedFolder(folder, false) &#125;)router.start()console.log(&apos;\x1b[33m%s\x1b[0m&apos;, &apos;Starting Remix IDE at http://localhost:8080 and sharing &apos; + folder)]]></content>
      <categories>
        <category>solidity</category>
      </categories>
      <tags>
        <tag>区块链</tag>
        <tag>solidity</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>%2F2019%2F07%2F22%2FSolidity%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%EF%BC%881%EF%BC%89-%E5%BF%AB%E9%80%9F%E6%90%AD%E5%BB%BA%E4%BB%A5%E5%A4%AA%E5%9D%8A%E7%A7%81%E9%93%BE%2F</url>
    <content type="text"><![CDATA[title: Solidity开发环境（1）–快速搭建以太坊私链date: 2019-07-22 21:59:37tags: - solidity - 区块链categories: solidity 对于以太坊私链环境的搭建网上文章比较多，有的也比较详细，可以多参考一下。这里主要说一下关键步骤，对于虚拟机安装（ubuntu）、golang安装、git安装这些操作这里就不进行说明了。 1、下载geth在gopath路径下，使用git命令clone源码https://github.com/ethereum/go-ethereum.git。 2、编译geth在编译前需要修改一下挖矿难度，这样节点在挖矿时会出块快一些，方便测试，不然会很慢的。进入go-ethereum中找到consensus.go文件，找到方法func CalcDifficulty(config *params.ChainConfig, time uint64, parent *types.Header) *big.Int，将这个方法的返回值修改为return big.NewInt(10);，这样挖矿难度就不会逐渐增加了。然后再在go-ethereum目录下执行make all命令进行编译。 3、创建部署路径上一步已经有了可执行文件，然后把go-ethereum/build/bin下的geth文件拷贝到单独的工作路径，比如建立一个~/work/geth-bin的文件夹，将geth拷贝至其下。 4、创建帐户创建帐户其实是可以在节点启动后，通过geth命令来创建，但是我们需要在节点启动的时候预置一些币到帐户中，就必须先有帐户。这样节点一启动帐户就钱了，可以直接进行交易测试了，不需要等待挖矿来获取币了。一出生嘴里就含着金钥匙的感觉还是很爽的。使用./geth –datadir node1/data account new命令来创建帐户，本人一般喜欢创建3个节点，所以执行三次，每次路径改变一下就可以，比如node2/data、node3/data，这样就生成了三个帐户文件。每次创建帐户的时候把帐户地址复制下来，后续使用，当然也可以去node1/data/keystore查看，比如UTC–2018-12-12T08-03-06.473554277Z–7882005b83ee97c00817d9eaaadc340a7763b2f0，这是一个帐户文件，最后的一串数字就是帐户地址。 5、生成genesis.json文件 在alloc标签下指定三个帐户地址，以及他们的余额，余额可以弄多些，花的时候可以放开了花。 difficulty不用修改了，因为已经通过源码修改过了，这里修改也没意义了。123456789101112131415161718192021222324252627&#123; &quot;config&quot;: &#123; &quot;chainId&quot;: 14, &quot;homesteadBlock&quot;: 0, &quot;eip155Block&quot;: 0, &quot;eip158Block&quot;: 0 &#125;, &quot;alloc&quot; : &#123; &quot;7882005b83ee97c00817d9eaaadc340a7763b2f0&quot;:&#123; &quot;balance&quot;: &quot;33333300000000000000000000000&quot; &#125;, &quot;1db644fbeb757f6e73b4b1917ced1c06f1b0cc97&quot;:&#123; &quot;balance&quot;: &quot;110000000000000000000000&quot; &#125;, &quot;414ca00f449873c510476cf3e85dd044f114a3b5&quot;:&#123; &quot;balance&quot;: &quot;90000000000000000&quot; &#125; &#125;, &quot;coinbase&quot; : &quot;0x0000000000000000000000000000000000000000&quot;, &quot;difficulty&quot; : &quot;0x00002&quot;, &quot;extraData&quot; : &quot;&quot;, &quot;gasLimit&quot; : &quot;0x2fefd8&quot;, &quot;nonce&quot; : &quot;0x0000000000000042&quot;, &quot;mixhash&quot; : &quot;0x0000000000000000000000000000000000000000000000000000000000000000&quot;, &quot;parentHash&quot; : &quot;0x0000000000000000000000000000000000000000000000000000000000000000&quot;, &quot;timestamp&quot; : &quot;0x00&quot;&#125; 6、初始化节点有了初始化配置文件，我们就可以初始化节点了，使用./geth –datadir node1/data init genesis.json命令来创建，和帐户对应，分别创建三次，即三个节点。 7、启动节点启动命令./geth –networkid 14 –nodiscover –datadir node1/data –port 4001 –rpc –rpcapi net,eth,web3,personal –rpcaddr 0.0.0.0 –rpcport 9541 console，每次启动都要修改一下datadir、port、rpcport的值，这些是不可重复的。 12./geth --networkid 14 --nodiscover --datadir node2/data --port 4002 --rpc --rpcapi net,eth,web3,personal --rpcaddr 0.0.0.0 --rpcport 9542 console./geth --networkid 14 --nodiscover --datadir node3/data --port 4003 --rpc --rpcapi net,eth,web3,personal --rpcaddr 0.0.0.0 --rpcport 9543 console 7、节点发现上边虽然启动了三个节点，可他们之前是互相独立的，没有建立连接，可以手动的将他们连接在一起。在node1节点启动后的console中执行admin.nodeInfo.enode命令，会看到当前节点的url，比如enode://aa5bd995bf3ccdd693c46d54fd09598f3d58c99a4ac091ae2c31f725796c6e7ddffd2672fea5e4ff2d5085967a4c071915d7448fbb1757cf8f7411af94b25ed8@127.0.0.1:4001，然后在node2的console中执行admin.addPeer(“enode://aa5bd995bf3ccdd693c46d54fd09598f3d58c99a4ac091ae2c31f725796c6e7ddffd2672fea5e4ff2d5085967a4c071915d7448fbb1757cf8f7411af94b25ed8@127.0.0.1:4001”)，这样node1和node2就建立了连接了，然后同样的可以把node1和node3，node2和node3建立连接。 8、测试以上操作就搭建好了自己的以太坊私链了，然后你可以进行各种命令的测试了，看看你的帐户余额地址是多少，发发交易等等]]></content>
  </entry>
  <entry>
    <title><![CDATA[GO-HPB源码解读--work.go]]></title>
    <url>%2F2019%2F07%2F21%2FGO-HPB%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB-work-go%2F</url>
    <content type="text"><![CDATA[在了解HPB持久化区块的时候，在levelDB的put方法中打印了一下调用栈，发现一共调用了5次，日志如下： 12345678910INFO [01-27|22:54:54] HPB : Successfully sealed new block number -&gt; =2 hash -&gt; =8060c5…80af4c difficulty -&gt; =1ERROR[01-27|22:54:54] HPB : mdatabase %s=&quot;goroutine 56 [running]:\nruntime/debug.Stack(0xc001ad3940, 0x41167f, 0x10)/usr/local/go/src/runtime/debug/stack.go:24 +0xa7\ngithub.com/hpb-project/go-hpb/blockchain/storage.(*LMDBDatabase).Put(0xc0001452b0, 0xc0018ab7a0, 0x2a, 0x30, 0xc0017f9c20, 0x1, 0x1, 0x0, 0x0)/home/buff/workspace/goland/src/github.com/hpb-project/go-hpb/build/workspace/src/github.com/hpb-project/go-hpb/blockchain/storage/mdatabase.go:65 +0x42\ngithub.com/hpb-project/go-hpb/blockchain.WriteTd(0x7fd9a9b5cbf0, 0xc0001452b0, 0x7eef19c735c56080, 0x558872de29feac8, 0x69fb026f2a700595, 0x4caf80c4389aafac, 0x2, 0xc001ac7de0, 0x0, 0x0)/home/buff/workspace/goland/src/github.com/hpb-project/go-hpb/build/workspace/src/github.com/hpb-project/go-hpb/blockchain/database_util.go:481 +0x212\ngithub.com/hpb-project/go-hpb/blockchain.(*HeaderChain).WriteTd(0xc00012a400, 0x7eef19c735c56080, 0x558872de29feac8, 0x69fb026f2a700595, 0x4caf80c4389aafac, 0x2, 0xc001ac7de0, 0x0, 0x0)/home/buff/workspace/goland/src/github.com/hpb-project/go-hpb/build/workspace/src/github.com/hpb-project/go-hpb/blockchain/headerchain.go:333 +0xa5\ngithub.com/hpb-project/go-hpb/blockchain.(*BlockChain).WriteBlockAndState(0xc000056e00, 0xc001a83680, 0x0, 0x0, 0x0, 0xc001cc4690, 0x0, 0x0, 0x0)/home/buff/workspace/goland/src/github.com/hpb-project/go-hpb/build/workspace/src/github.com/hpb-project/go-hpb/blockchain/blockchain.go:846 +0x381\ngithub.com/hpb-project/go-hpb/worker.(*worker).handlerSelfMinedBlock(0xc0000ec360)/home/buff/workspace/goland/src/github.com/hpb-project/go-hpb/build/workspace/src/github.com/hpb-project/go-hpb/worker/worker.go:345 +0x22e\ncreated by github.com/hpb-project/go-hpb/worker.newWorker/home/buff/workspace/goland/src/github.com/hpb-project/go-hpb/build/workspace/src/github.com/hpb-project/go-hpb/worker/worker.go:165 +0x385\n&quot;ERROR[01-27|22:54:54] HPB : mdatabase put=1 123456789ERROR[01-27|22:54:54] HPB : mdatabase %s=&quot;goroutine 56 [running]:\nruntime/debug.Stack(0x479eae, 0x41167f, 0x431301)/usr/local/go/src/runtime/debug/stack.go:24 +0xa7\ngithub.com/hpb-project/go-hpb/blockchain/storage.(*LMDBDatabase).Put(0xc0001452b0, 0xc0017f9dd0, 0xa, 0x10, 0xc001a6df60, 0x20, 0x20, 0x0, 0x0)/home/buff/workspace/goland/src/github.com/hpb-project/go-hpb/build/workspace/src/github.com/hpb-project/go-hpb/blockchain/storage/mdatabase.go:65 +0x42\ngithub.com/hpb-project/go-hpb/blockchain.WriteCanonicalHash(0x7fd9a9b5cbf0, 0xc0001452b0, 0x7eef19c735c56080, 0x558872de29feac8, 0x69fb026f2a700595, 0x4caf80c4389aafac, 0x2, 0x30, 0xc0017f9d98)/home/buff/workspace/goland/src/github.com/hpb-project/go-hpb/build/workspace/src/github.com/hpb-project/go-hpb/blockchain/database_util.go:406 +0x156\ngithub.com/hpb-project/go-hpb/blockchain.(*BlockChain).insert(0xc000056e00, 0xc001a83680)/home/buff/workspace/goland/src/github.com/hpb-project/go-hpb/build/workspace/src/github.com/hpb-project/go-hpb/blockchain/blockchain.go:501 +0x1db\ngithub.com/hpb-project/go-hpb/blockchain.(*BlockChain).WriteBlockAndState(0xc000056e00, 0xc001a83680, 0x0, 0x0, 0x0, 0xc001cc4690, 0x1, 0x0, 0x0)/home/buff/workspace/goland/src/github.com/hpb-project/go-hpb/build/workspace/src/github.com/hpb-project/go-hpb/blockchain/blockchain.go:890 +0x80e\ngithub.com/hpb-project/go-hpb/worker.(*worker).handlerSelfMinedBlock(0xc0000ec360)/home/buff/workspace/goland/src/github.com/hpb-project/go-hpb/build/workspace/src/github.com/hpb-project/go-hpb/worker/worker.go:345 +0x22e\ncreated by github.com/hpb-project/go-hpb/worker.newWorker/home/buff/workspace/goland/src/github.com/hpb-project/go-hpb/build/workspace/src/github.com/hpb-project/go-hpb/worker/worker.go:165 +0x385\n&quot;ERROR[01-27|22:54:54] HPB : mdatabase put=32 123456789ERROR[01-27|22:54:54] HPB : mdatabase %s=&quot;goroutine 56 [running]:\nruntime/debug.Stack(0x20, 0x0, 0x0)/usr/local/go/src/runtime/debug/stack.go:24 +0xa7\ngithub.com/hpb-project/go-hpb/blockchain/storage.(*LMDBDatabase).Put(0xc0001452b0, 0x1983068, 0x9, 0x9, 0xc001a6dfc0, 0x20, 0x20, 0x0, 0x0)/home/buff/workspace/goland/src/github.com/hpb-project/go-hpb/build/workspace/src/github.com/hpb-project/go-hpb/blockchain/storage/mdatabase.go:65 +0x42\ngithub.com/hpb-project/go-hpb/blockchain.WriteHeadBlockHash(0x7fd9a9b5cbf0, 0xc0001452b0, 0x7eef19c735c56080, 0x558872de29feac8, 0x69fb026f2a700595, 0x4caf80c4389aafac, 0x2, 0x0)/home/buff/workspace/goland/src/github.com/hpb-project/go-hpb/build/workspace/src/github.com/hpb-project/go-hpb/blockchain/database_util.go:422 +0x9f\ngithub.com/hpb-project/go-hpb/blockchain.(*BlockChain).insert(0xc000056e00, 0xc001a83680)/home/buff/workspace/goland/src/github.com/hpb-project/go-hpb/build/workspace/src/github.com/hpb-project/go-hpb/blockchain/blockchain.go:504 +0x2f0\ngithub.com/hpb-project/go-hpb/blockchain.(*BlockChain).WriteBlockAndState(0xc000056e00, 0xc001a83680, 0x0, 0x0, 0x0, 0xc001cc4690, 0x1, 0x0, 0x0)/home/buff/workspace/goland/src/github.com/hpb-project/go-hpb/build/workspace/src/github.com/hpb-project/go-hpb/blockchain/blockchain.go:890 +0x80e\ngithub.com/hpb-project/go-hpb/worker.(*worker).handlerSelfMinedBlock(0xc0000ec360)/home/buff/workspace/goland/src/github.com/hpb-project/go-hpb/build/workspace/src/github.com/hpb-project/go-hpb/worker/worker.go:345 +0x22e\ncreated by github.com/hpb-project/go-hpb/worker.newWorker/home/buff/workspace/goland/src/github.com/hpb-project/go-hpb/build/workspace/src/github.com/hpb-project/go-hpb/worker/worker.go:165 +0x385\n&quot;ERROR[01-27|22:54:54] HPB : mdatabase put=32 12345678910ERROR[01-27|22:54:54] HPB : mdatabase %s=&quot;goroutine 56 [running]:\nruntime/debug.Stack(0xc001ad3868, 0x563c36, 0xc001d4e060)/usr/local/go/src/runtime/debug/stack.go:24 +0xa7\ngithub.com/hpb-project/go-hpb/blockchain/storage.(*LMDBDatabase).Put(0xc0001452b0, 0x1983098, 0xa, 0xa, 0xc001d4e080, 0x20, 0x20, 0x0, 0x0)/home/buff/workspace/goland/src/github.com/hpb-project/go-hpb/build/workspace/src/github.com/hpb-project/go-hpb/blockchain/storage/mdatabase.go:65 +0x42\ngithub.com/hpb-project/go-hpb/blockchain.WriteHeadHeaderHash(0x7fd9a9b5cbf0, 0xc0001452b0, 0x7eef19c735c56080, 0x558872de29feac8, 0x69fb026f2a700595, 0x4caf80c4389aafac, 0x9ca0cf, 0xc001cd65d0)/home/buff/workspace/goland/src/github.com/hpb-project/go-hpb/build/workspace/src/github.com/hpb-project/go-hpb/blockchain/database_util.go:414 +0x9f\ngithub.com/hpb-project/go-hpb/blockchain.(*HeaderChain).SetCurrentHeader(0xc00012a400, 0xc001245400)/home/buff/workspace/goland/src/github.com/hpb-project/go-hpb/build/workspace/src/github.com/hpb-project/go-hpb/blockchain/headerchain.go:396 +0xaa\ngithub.com/hpb-project/go-hpb/blockchain.(*BlockChain).insert(0xc000056e00, 0xc001a83680)/home/buff/workspace/goland/src/github.com/hpb-project/go-hpb/build/workspace/src/github.com/hpb-project/go-hpb/blockchain/blockchain.go:511 +0x3da\ngithub.com/hpb-project/go-hpb/blockchain.(*BlockChain).WriteBlockAndState(0xc000056e00, 0xc001a83680, 0x0, 0x0, 0x0, 0xc001cc4690, 0x1, 0x0, 0x0)/home/buff/workspace/goland/src/github.com/hpb-project/go-hpb/build/workspace/src/github.com/hpb-project/go-hpb/blockchain/blockchain.go:890 +0x80e\ngithub.com/hpb-project/go-hpb/worker.(*worker).handlerSelfMinedBlock(0xc0000ec360)/home/buff/workspace/goland/src/github.com/hpb-project/go-hpb/build/workspace/src/github.com/hpb-project/go-hpb/worker/worker.go:345 +0x22e\ncreated by github.com/hpb-project/go-hpb/worker.newWorker/home/buff/workspace/goland/src/github.com/hpb-project/go-hpb/build/workspace/src/github.com/hpb-project/go-hpb/worker/worker.go:165 +0x385\n&quot;ERROR[01-27|22:54:54] HPB : mdatabase put=32 123456789ERROR[01-27|22:54:54] HPB : mdatabase %s=&quot;goroutine 56 [running]:\nruntime/debug.Stack(0xc001d4e100, 0xc001d35500, 0xc001d4e0e0)/usr/local/go/src/runtime/debug/stack.go:24 +0xa7\ngithub.com/hpb-project/go-hpb/blockchain/storage.(*LMDBDatabase).Put(0xc0001452b0, 0x1982cb0, 0x8, 0x8, 0xc001d4e120, 0x20, 0x20, 0x0, 0x0)/home/buff/workspace/goland/src/github.com/hpb-project/go-hpb/build/workspace/src/github.com/hpb-project/go-hpb/blockchain/storage/mdatabase.go:65 +0x42\ngithub.com/hpb-project/go-hpb/blockchain.WriteHeadFastBlockHash(0x7fd9a9b5cbf0, 0xc0001452b0, 0x7eef19c735c56080, 0x558872de29feac8, 0x69fb026f2a700595, 0x4caf80c4389aafac, 0x0, 0x0)/home/buff/workspace/goland/src/github.com/hpb-project/go-hpb/build/workspace/src/github.com/hpb-project/go-hpb/blockchain/database_util.go:430 +0x9f\ngithub.com/hpb-project/go-hpb/blockchain.(*BlockChain).insert(0xc000056e00, 0xc001a83680)/home/buff/workspace/goland/src/github.com/hpb-project/go-hpb/build/workspace/src/github.com/hpb-project/go-hpb/blockchain/blockchain.go:513 +0x455\ngithub.com/hpb-project/go-hpb/blockchain.(*BlockChain).WriteBlockAndState(0xc000056e00, 0xc001a83680, 0x0, 0x0, 0x0, 0xc001cc4690, 0x1, 0x0, 0x0)/home/buff/workspace/goland/src/github.com/hpb-project/go-hpb/build/workspace/src/github.com/hpb-project/go-hpb/blockchain/blockchain.go:890 +0x80e\ngithub.com/hpb-project/go-hpb/worker.(*worker).handlerSelfMinedBlock(0xc0000ec360)/home/buff/workspace/goland/src/github.com/hpb-project/go-hpb/build/workspace/src/github.com/hpb-project/go-hpb/worker/worker.go:345 +0x22e\ncreated by github.com/hpb-project/go-hpb/worker.newWorker/home/buff/workspace/goland/src/github.com/hpb-project/go-hpb/build/workspace/src/github.com/hpb-project/go-hpb/worker/worker.go:165 +0x385\n&quot;ERROR[01-27|22:54:54] HPB : mdatabase put=32 11’atom-workspace’: ‘ctrl-v’: ‘markdown-img-paste:paste’ !ls../images/SubscribeTxPreEvent.png 通过日志发现入口都是worker.go这个文件中的]]></content>
      <categories>
        <category>HPB源码解读</category>
      </categories>
      <tags>
        <tag>HPB</tag>
        <tag>区块链</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GO-HPB源码解读--PRC服务启动]]></title>
    <url>%2F2019%2F07%2F21%2FGO-HPB%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB-PRC%E6%9C%8D%E5%8A%A1%E5%90%AF%E5%8A%A8%2F</url>
    <content type="text"><![CDATA[RPC服务是在节点启动的时候通过参数–rpcaddr 0.0.0.0 –rpcport 8541来指定的，启动代码是： 12hpbnode.SetNodeAPI()hpbnode.Hpbrpcmanager.Start(hpbnode.RpcAPIs) 其中SetNodeAPI是把所有的API定义以[]rpc.API的数据类型保存hpbnode.RpcAPIs，然后再传给Start方法。API的结构如下，其中public为false的话是不会发布出去了。 123456type API struct &#123; Namespace string // namespace under which the rpc methods of Service are exposed Version string // api version for DApp's Service interface&#123;&#125; // receiver instance which holds the methods Public bool // indication if the methods must be considered safe for public use&#125; 然后启动RPC服务，可以看到一共指定了三种形式的服务参数，分别是ipc、http、ws，ipc是进程间通信，在同一机器上进行的内存共享方式通信，由于不经过网卡转输数据，所以可以节省网络资源；http就是我们通过web3接口调用的通信服务，ws是WebService是一种严格定义报文格式的协议，底层也是基于http的，这里我们主要看下http服务。如果后启动的服务出现异常，则需要把所有已启动的服务停止掉，并返回。 1234567891011121314151617181920212223242526func (prm *RpcManager)Start(apis []API ) error &#123; config :=config.GetHpbConfigInstance() // for-test log.Debug("Para from config.","IpcEndpoint",config.Network.IpcEndpoint,"HttpEndpoint",config.Network.HttpEndpoint,"WsEndpoint",config.Network.WsEndpoint) prm.rpcmgr = &amp;RpcMgr&#123; ipcEndpoint: config.Network.IpcEndpoint, httpEndpoint: config.Network.HttpEndpoint, wsEndpoint: config.Network.WsEndpoint, httpCors: config.Network.HTTPCors, httpModules: config.Network.HTTPModules, httpVirtualHosts:config.Network.HTTPVirtualHosts, httpTimeouts: config.Network.HTTPTimeouts, wsOrigins: config.Network.WSOrigins, wsModules: config.Network.WSModules, wsExposeAll: config.Network.WSExposeAll, &#125; if err := prm.rpcmgr.startRPC(apis); err != nil &#123; log.Error("start rpc error","reason",err) &#125; return nil&#125; startRPC方法中按照先后顺序分别启动了四种形式的服务，多了一种InProc，这个是进程内通信（具体使用还没研究）。这里我们就看一下startHTTP的启动过程。 1234567891011121314151617181920212223242526272829// startRPC is a helper method to start all the various RPC endpoint during node// startup. It's not meant to be called at any time afterwards as it makes certain// assumptions about the state of the node.func (n *RpcMgr) startRPC(apis []API) error &#123; // Gather all the possible APIs to surface n.rpcAPIs = apis // Start the various API endpoints, terminating all in case of errors if err := n.startInProc(apis); err != nil &#123; return err &#125; if err := n.startIPC(apis); err != nil &#123; n.stopInProc() return err &#125; if err := n.startHTTP(n.httpEndpoint, apis, n.httpModules, n.httpCors, n.httpVirtualHosts, n.httpTimeouts); err != nil &#123; n.stopIPC() n.stopInProc() return err &#125; if err := n.startWS(n.wsEndpoint, apis, n.wsModules, n.wsOrigins, n.wsExposeAll); err != nil &#123; n.stopHTTP() n.stopIPC() n.stopInProc() return err &#125; // All API endpoints started successfully return nil&#125; 在StartHTTPEndpoint方法中，modules就是在启动的时候通过参数–rpcapi hpb,web3,admin,txpool,debug,personal,net指定的，表示启动的模块，RPC在启动的时候会检查程序所定的API是否在modules中，只有在的才会启动，另外还有个条件就是api是Public的。NewHTTPServer方法启动服务，其中cors参数是跨域域名 12345678910111213141516171819202122232425262728// StartHTTPEndpoint starts the HTTP RPC endpoint, configured with cors/vhosts/modulesfunc StartHTTPEndpoint(endpoint string, apis []API, modules []string, cors []string, vhosts []string, timeouts config.HTTPTimeouts) (net.Listener, *Server, error) &#123; // Generate the whitelist based on the allowed modules whitelist := make(map[string]bool) for _, module := range modules &#123; whitelist[module] = true &#125; // Register all the APIs exposed by the services handler := NewServer() for _, api := range apis &#123; if whitelist[api.Namespace] || (len(whitelist) == 0 &amp;&amp; api.Public) &#123; if err := handler.RegisterName(api.Namespace, api.Service); err != nil &#123; return nil, nil, err &#125; log.Debug("HTTP registered", "namespace", api.Namespace) &#125; &#125; // All APIs registered, start the HTTP listener var ( listener net.Listener err error ) if listener, err = net.Listen("tcp", endpoint); err != nil &#123; return nil, nil, err &#125; go NewHTTPServer(cors, vhosts, timeouts, handler).Serve(listener) return listener, handler, err&#125;]]></content>
      <categories>
        <category>HPB源码解读</category>
      </categories>
      <tags>
        <tag>HPB</tag>
        <tag>区块链</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GO-HPB源码解读--P2P启动]]></title>
    <url>%2F2019%2F07%2F21%2FGO-HPB%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB-P2P%E5%90%AF%E5%8A%A8%2F</url>
    <content type="text"><![CDATA[P2P启动是在节点启动的时候进行的，启动代码是hpbnode.Hpbpeermanager.Start(hpbnode.hpberbase) 123456789101112131415161718192021222324252627282930func (hpbnode *Node) Start(conf *config.HpbConfig) error &#123; if config.GetHpbConfigInstance().Node.TestCodeParam == 1 &#123; consensus.SetTestParam() &#125; hpbnode.startBloomHandlers() err := hpbnode.WorkerInit(conf) if err != nil &#123; log.Error("Worker init failed", ":", err) return err &#125; if hpbnode.Hpbsyncctr == nil &#123; log.Error("syncctrl is nil") return errors.New("synctrl is nil") &#125; hpbnode.Hpbsyncctr.Start() retval := hpbnode.Hpbpeermanager.Start(hpbnode.hpberbase) if retval != nil &#123; log.Error("Start hpbpeermanager error") return errors.New(`start peermanager error ".ipc"`) &#125; hpbnode.SetNodeAPI() hpbnode.Hpbrpcmanager.Start(hpbnode.RpcAPIs) hpbnode.Hpbtxpool.Start() return nil&#125; 在Start方法中 配置网络启动参数信息 注册NodeMsg消息处理函数 设置本地节点的类型分别是候选节点、引导节点、同步节点 启动服务(prm.server.Start()) 检查本地节点是不是在BootstrapNodes列表中，也就是程序首次安装的时候连接的节点。 启动iperf带宽测试服务，该端口是peer的端口加100。iperf的启动是通过调用shell命令来启来的，iperf应用包就在ghpb-bin安装目录下。命令是：bin/bash iperf3 -s -p port 如果是挖矿节点的话，异步启动iperf带宽测试客户端 如果boot节点的话，需要解析一下binding.json文件，这个用来指定启动时可以连接的peer地址1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677func (prm *PeerManager) Start(coinbase common.Address) error &#123; config := config.GetHpbConfigInstance() prm.server.Config = Config&#123; NAT: config.Network.NAT, Name: config.Network.Name, TestMode: config.Node.TestMode == 1, PrivateKey: config.Node.PrivateKey, NetworkId: config.Node.NetworkId, ListenAddr: config.Network.ListenAddr, NetRestrict: config.Network.NetRestrict, NodeDatabase: config.Network.NodeDatabase, BootstrapNodes: config.Network.BootstrapNodes, EnableMsgEvents: config.Network.EnableMsgEvents, Protocols: prm.hpbpro.Protocols(), &#125; prm.server.Config.CoinBase = coinbase log.Info("Set coinbase address by start", "address", coinbase.String()) if coinbase.String() == "0x0000000000000000000000000000000000000000" &#123; panic("coinbase address is nil.") &#125; prm.hpbpro.networkId = prm.server.NetworkId prm.hpbpro.regMsgProcess(ReqNodesMsg, HandleReqNodesMsg) prm.hpbpro.regMsgProcess(ResNodesMsg, HandleResNodesMsg) prm.hpbpro.regMsgProcess(ReqBWTestMsg, prm.HandleReqBWTestMsg) prm.hpbpro.regMsgProcess(ResBWTestMsg, prm.HandleResBWTestMsg) copy(prm.server.Protocols, prm.hpbpro.Protocols()) localType := discover.PreNode if config.Network.RoleType == "bootnode" &#123; localType = discover.BootNode &#125; else if config.Network.RoleType == "synnode" &#123; localType = discover.SynNode &#125; prm.SetLocalType(localType) log.Info("Set Init Local Type by p2p", "type", localType.ToString()) if err := prm.server.Start(); err != nil &#123; log.Error("Hpb protocol", "error", err) return err &#125; //////////////////////////////////////////////////////////////////////////////////////// //for bootnode check self := prm.server.Self() for _, n := range config.Network.BootstrapNodes &#123; if self.ID == n.ID &amp;&amp; prm.server.localType != discover.BootNode &#123; panic("Need BOOTNODE flag.") &#125; &#125; ///////////////////////////////////////////////////////////////////////////////////////// add, _ := net.ResolveUDPAddr("udp", prm.server.ListenAddr) prm.iport = add.Port + 100 log.Debug("Iperf server start", "port", prm.iport) prm.startServerBW(strconv.Itoa(prm.iport)) if prm.server.localType != discover.BootNode &amp;&amp; prm.server.localType != discover.SynNode &#123; go prm.startClientBW() &#125; ///////////////////////////////////////////////////////////////////////////////////////// //for bing info if prm.server.localType == discover.BootNode &#123; filename := filepath.Join(config.Node.DataDir, bindInfoFileName) log.Debug("bootnode load bindings", "filename", filename) prm.parseBindInfo(filename) &#125; return nil&#125; prm.server.Start()方法是用来启动P2P服务的。 判断服务是否启动 创建RLPX，实现网络数据传输加密，这里有个翻译文档可以详细了解下 初始化一些Server的属性 启动UDP服务，主要是用来发现节点的 设置boot节点地址，添加到table中 指定自己的握手协议 srv.startListening()启动TCP服务 创建newDialState对象，并异步运行123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172// Start starts running the server.// Servers can not be re-used after stopping.func (srv *Server) Start() (err error) &#123; srv.lock.Lock() defer srv.lock.Unlock() if srv.running &#123; return errors.New("server already running") &#125; srv.running = true log.Info("Starting P2P networking") rand.Seed(time.Now().Unix()) // static fields if srv.PrivateKey == nil &#123; return fmt.Errorf("Server.PrivateKey must be set to a non-nil key") &#125; if srv.newTransport == nil &#123; srv.newTransport = newRLPX &#125; srv.quit = make(chan struct&#123;&#125;) srv.addpeer = make(chan *conn) srv.delpeer = make(chan peerDrop) srv.posthandshake = make(chan *conn) srv.addstatic = make(chan *discover.Node) srv.removestatic = make(chan *discover.Node) srv.peerOp = make(chan peerOpFunc) srv.peerOpDone = make(chan struct&#123;&#125;) srv.peerEvent = event.NewEvent() srv.delHist = new(dialHistory) srv.dialer = TCPDialer&#123;&amp;net.Dialer&#123;Timeout: defaultDialTimeout&#125;&#125; // node table ntab, ourend, err := discover.ListenUDP(srv.PrivateKey, srv.localType, srv.ListenAddr, srv.NAT, srv.NodeDatabase, srv.NetRestrict) if err != nil &#123; return err &#125; if err := ntab.SetFallbackNodes(srv.BootstrapNodes); err != nil &#123; return err &#125; srv.ntab = ntab // handshake srv.ourHandshake = &amp;protoHandshake&#123;Version: MsgVersion, Name: srv.Name, ID: discover.PubkeyID(&amp;srv.PrivateKey.PublicKey), End:ourend&#125; for _, p := range srv.Protocols &#123; srv.ourHandshake.Caps = append(srv.ourHandshake.Caps, p.cap()) &#125; srv.ourHandshake.CoinBase = srv.CoinBase if srv.ListenAddr == "" &#123; log.Error("P2P server start, listen address is nil") &#125; if err := srv.startListening(); err != nil &#123; return err &#125; ////////////////////////////////////////////////////////////////////////////////////////////// if srv.TestMode &#123; srv.parseSynnode() &#125; ////////////////////////////////////////////////////////////////////////////////////////////// log.Info("Server start with type.","NodeType",srv.localType.ToString()) dialer := newDialState(srv.StaticNodes, srv.BootstrapNodes, srv.ntab, srv.NetRestrict) srv.loopWG.Add(1) go srv.run(dialer) srv.running = true return nil&#125; 在startListening方法中，首先开始监听端口，然后进行接收连接处理，主要看下srv.listenLoop()方法，另外还进行了NAT转换。 maxAcceptConns=100参数表示的是最大可握手连接数，并不是实际连接数，比如节点可以同时和200个peer建立连接，但在同一时间点，只能和100peer进行握手。所以看到代码创建了100个slot“信号”，接着for不断的取slot“信号”，相当于消耗了一个，但是在创建完连接之的又创建了一个slot“信号” for循环中主要是获取了连接，然后判断一下是不是受限地址（黑名单），如果不是就异步进行SetupConn1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980func (srv *Server) startListening() error &#123; // Launch the TCP listener. listener, err := net.Listen("tcp", srv.ListenAddr) if err != nil &#123; return err &#125; laddr := listener.Addr().(*net.TCPAddr) srv.ListenAddr = laddr.String() srv.listener = listener srv.loopWG.Add(1) go srv.listenLoop() // Map the TCP listening port if NAT is configured. if !laddr.IP.IsLoopback() &amp;&amp; srv.NAT != nil &#123; srv.loopWG.Add(1) go func() &#123; nat.Map(srv.NAT, srv.quit, "tcp", laddr.Port, laddr.Port, "hpb p2p") srv.loopWG.Done() &#125;() &#125; return nil&#125;// listenLoop runs in its own goroutine and accepts// inbound connections.func (srv *Server) listenLoop() &#123; defer srv.loopWG.Done() //log.Info("RLPx listener up", "self", srv.makeSelf(srv.listener)) // This channel acts as a semaphore limiting // active inbound connections that are lingering pre-handshake. // If all slots are taken, no further connections are accepted. tokens := maxAcceptConns slots := make(chan struct&#123;&#125;, tokens) for i := 0; i &lt; tokens; i++ &#123; slots &lt;- struct&#123;&#125;&#123;&#125; &#125; for &#123; // Wait for a handshake slot before accepting. &lt;-slots var ( fd net.Conn err error ) for &#123; fd, err = srv.listener.Accept() if tempErr, ok := err.(tempError); ok &amp;&amp; tempErr.Temporary() &#123; log.Debug("Temporary read error", "err", err) continue &#125; else if err != nil &#123; log.Debug("Read error", "err", err) return &#125; break &#125; // Reject connections that do not match NetRestrict. if srv.NetRestrict != nil &#123; if tcp, ok := fd.RemoteAddr().(*net.TCPAddr); ok &amp;&amp; !srv.NetRestrict.Contains(tcp.IP) &#123; log.Debug("Rejected conn (not whitelisted in NetRestrict)", "addr", fd.RemoteAddr()) fd.Close() slots &lt;- struct&#123;&#125;&#123;&#125; continue &#125; &#125; fd = newMeteredConn(fd, true) log.Info("Accepted connection", "addr", fd.RemoteAddr()) // Spawn the handler. It will give the slot back when the connection // has been established. go func() &#123; srv.SetupConn(fd, inboundConn, nil) slots &lt;- struct&#123;&#125;&#123;&#125; &#125;() &#125;&#125; 在SetupConn中 判断服务是不是启动 这行代码中c := &amp;conn{fd: fd, transport: srv.newTransport(fd), flags: flags, cont: make(chan error)}可以看到srv.newTransport这个参数的传入，其实就是上边的RLPX。 c.doEncHandshake进行ENC握手，具体实现都是RLPX做的 c.doProtoHandshake进行协议握手，具体实现都是RLPX做的 之的的有关BOE的逻辑没太看明白 最后srv.checkpoint是将连接对象conn发送给通道stage123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131// SetupConn runs the handshakes and attempts to add the connection// as a peer. It returns when the connection has been added as a peer// or the handshakes have failed.func (srv *Server) SetupConn(fd net.Conn, flags connFlag, dialDest *discover.Node) &#123; // Prevent leftover pending conns from entering the handshake. srv.lock.Lock() running := srv.running srv.lock.Unlock() c := &amp;conn&#123;fd: fd, transport: srv.newTransport(fd), flags: flags, cont: make(chan error)&#125; if !running &#123; c.close(errServerStopped) return &#125; srv.setupLock.Lock() defer srv.setupLock.Unlock() // Run the encryption handshake. var err error var ourRand, theirRand []byte if c.id, ourRand, theirRand, err = c.doEncHandshake(srv.PrivateKey, dialDest); err != nil &#123; log.Debug("Failed RLPx handshake", "addr", c.fd.RemoteAddr(), "conn", c.flags, "reason", err) c.close(err) return &#125; clog := log.New("id", c.id, "addr", c.fd.RemoteAddr(), "conn", c.flags) // For dialed connections, check that the remote public key matches. if dialDest != nil &amp;&amp; c.id != dialDest.ID &#123; c.close(DiscUnexpectedIdentity) clog.Error("Dialed identity mismatch", "want", c, dialDest.ID) return &#125; if err := srv.checkpoint(c, srv.posthandshake); err != nil &#123; clog.Trace("Rejected peer before protocol handshake", "err", err) c.close(err) return &#125; log.Debug("Do enc handshake OK.","id",c.id) ///////////////////////////////////////////////////////////////////////////////// // Run the protocol handshake c.our = *srv.ourHandshake c.our.RandNonce = ourRand if c.our.Sign, err = boe.BoeGetInstance().HW_Auth_Sign(theirRand); err!=nil&#123; clog.Debug("Do hardware sign error.","err",err) //todo close and return &#125; clog.Debug("Hardware has signed remote rand.","rand",theirRand,"sign",c.our.Sign) their, err := c.doProtoHandshake(&amp;c.our) if err != nil &#123; clog.Debug("Failed proto handshake", "err", err) c.close(err) return &#125; if their.ID != c.id &#123; clog.Error("Wrong devp2p handshake identity", "err", their.ID) c.close(DiscUnexpectedIdentity) return &#125; c.their = *their clog.Debug("Do protocol handshake OK.","id",c.id) clog.Trace("Do protocol handshake.","our",c.our,"their",c.their) ///////////////////////////////////////////////////////////////////////////////// isRemoteBoot := false hdtab := srv.getHdtab() for _, n := range srv.BootstrapNodes &#123; if c.id == n.ID &#123; clog.Info("Remote node is boot.","id",c.id) c.isboe = true isRemoteBoot = true &#125; &#125; if !c.isboe &#123; remoteCoinbase := strings.ToLower(c.their.CoinBase.String()) clog.Trace("Remote coinbase","address",remoteCoinbase) if len(hdtab) == 0 &#123; clog.Debug("Do not ready for connected.","id",c.id.TerminalString()) c.close(DiscHwSignError) return &#125; for _,hw := range hdtab &#123; if hw.Adr == remoteCoinbase &#123; clog.Debug("Input to boe paras","rand",c.our.RandNonce,"hid",hw.Hid,"cid",hw.Cid,"sign",c.their.Sign) c.isboe = boe.BoeGetInstance().HW_Auth_Verify(c.our.RandNonce,hw.Hid,hw.Cid,c.their.Sign) clog.Info("Boe verify the remote.","id",c.id.TerminalString(),"result",c.isboe) &#125; &#125; &#125; clog.Info("Verify the remote hardware.","id",c.id.TerminalString(),"result",c.isboe) if !srv.TestMode &amp;&amp; srv.localType == discover.SynNode &amp;&amp; c.isboe == false &#123; clog.Debug("SynNode peer SynNode, dorp peer.") c.close(DiscHwSignError) return &#125; if isRemoteBoot || srv.localType == discover.BootNode &#123; ourHdtable := &amp;hardwareTable&#123;Version:0x00,Hdtab:hdtab&#125; theirHdtable, err := c.doHardwareTable(ourHdtable) if err != nil &#123; clog.Debug("Failed hardware table handshake", "reason", err) c.close(err) return &#125; clog.Trace("Exchange hardware table.","our",ourHdtable, "their",theirHdtable) if isRemoteBoot&#123; srv.updateHdtab(theirHdtable.Hdtab,true) clog.Trace("Update hardware table from boot.","srv hdtab", srv.getHdtab() ) &#125; &#125; ///////////////////////////////////////////////////////////////////////////////// if err := srv.checkpoint(c, srv.addpeer); err != nil &#123; clog.Warn("Rejected peer", "err", err, "dialDest",dialDest) c.close(err) return &#125;&#125; 当接收到的连接发送到stage通道后，那么通道的处理是在srv.run进行处理的，也就是prm.server.Start()最后一步代码srv.run。其中分支case c := &lt;-srv.addpeer:中的go srv.runPeer(p)方法开启了对连接的心跳检测，同时进行了节点广播。上边分析的都是本节点作为服务监听者被动接收建立的连接，而节点主动连接其他节点的动作是在也是在srv.run(dialer)中进行的，其参数dialer包含有对方节点连接信息，包括boot节点地址。 首先创建了三个任务方法delTask、startTasks和scheduleTasks，同时创建了两个数组，一个是保存正在运行的task，一个缓存将被运行的task。删除的时候只能从正在运行的数组中删除，运行的时候最大运行个数不能超过maxActiveDialTasks=16个，其中scheduleTasks用来创建待运行的task，主动连接的节点分boot节点、静态节点和动态节点，其中静态节点就是手动配置的，动态节点是程序KAD算法计算得到的。 在startTasks方法中通过t.Do(srv)进行节点的连接操作，最终还是会执行srv.SetupConn方法，也就是上边分析的建立连接的过程。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166func (srv *Server) run(dialstate dialer) &#123; defer srv.loopWG.Done() var ( peers = make(map[discover.NodeID]*PeerBase) taskdone = make(chan task, maxActiveDialTasks) runningTasks []task queuedTasks []task // tasks that can't run yet ) // removes t from runningTasks delTask := func(t task) &#123; for i := range runningTasks &#123; if runningTasks[i] == t &#123; runningTasks = append(runningTasks[:i], runningTasks[i+1:]...) break &#125; &#125; &#125; // starts until max number of active tasks is satisfied startTasks := func(ts []task) (rest []task) &#123; i := 0 for ; len(runningTasks) &lt; maxActiveDialTasks &amp;&amp; i &lt; len(ts); i++ &#123; t := ts[i] go func() &#123; //log.Error("###### start task.","task",t) //time.Sleep(time.Second*time.Duration(rand.Intn(3))) t.Do(srv) //time.Sleep(time.Second*time.Duration(rand.Intn(3))) //log.Error("###### task done.") taskdone &lt;- t &#125;() runningTasks = append(runningTasks, t) &#125; return ts[i:] &#125; scheduleTasks := func() &#123; // Start from queue first. queuedTasks = append(queuedTasks[:0], startTasks(queuedTasks)...) // Query dialer for new tasks and start as many as possible now. if len(runningTasks) &lt; maxActiveDialTasks &#123; var nt []task if srv.localType == discover.BootNode &#123; nt = append(nt, &amp;waitExpireTask&#123;time.Second&#125;) &#125;else&#123; nt = dialstate.newTasks(len(runningTasks)+len(queuedTasks), peers, time.Now()) &#125; queuedTasks = append(queuedTasks, startTasks(nt)...) &#125; &#125;running: for &#123; scheduleTasks() srv.delHist.expire(time.Now()) log.Trace("###### Server running: expire node from history.","DelHist",srv.delHist.Len()) select &#123; case &lt;-srv.quit: // The server was stopped. Run the cleanup logic. break running case n := &lt;-srv.addstatic: // This channel is used by AddPeer to add to the // ephemeral static peer list. Add it to the dialer, // it will keep the node connected. log.Debug("Adding static node", "node", n) dialstate.addStatic(n) case n := &lt;-srv.removestatic: // This channel is used by RemovePeer to send a // disconnect request to a peer and begin the // stop keeping the node connected log.Debug("Removing static node", "node", n) dialstate.removeStatic(n) if p, ok := peers[n.ID]; ok &#123; p.Disconnect(DiscRequested) &#125; case op := &lt;-srv.peerOp: // This channel is used by Peers and PeerCount. op(peers) srv.peerOpDone &lt;- struct&#123;&#125;&#123;&#125; case t := &lt;-taskdone: // A task got done. Tell dialstate about it so it // can update its state and remove it from the active // tasks list. //log.Error("###### Dial task done", "task", t) dialstate.taskDone(t, time.Now()) delTask(t) case c := &lt;-srv.posthandshake: // A connection has passed the encryption handshake so // the remote identity is known (but hasn't been verified yet). // TODO: track in-progress inbound node IDs (pre-Peer) to avoid dialing them. select &#123; case c.cont &lt;- srv.encHandshakeChecks(peers, c): case &lt;-srv.quit: break running &#125; case c := &lt;-srv.addpeer: // At this point the connection is past the protocol handshake. // Its capabilities are known and the remote identity is verified. err := srv.protoHandshakeChecks(peers, c) if err == nil &#123; // The handshakes are done and it passed all checks. p := newPeerBase(c, srv.Protocols[0], srv.ntab) // If message events are enabled, pass the peerFeed // to the peer if srv.EnableMsgEvents &#123; p.events = srv.peerEvent &#125; p.beatStart = time.Now() srv.setPeerInitType(p, c.isboe) ////////////////////////////////////////////////////////// log.Debug("Server add peer base to run.", "id", c.id, "raddr", c.fd.RemoteAddr()) peers[c.id] = p go srv.runPeer(p) &#125; // The dialer logic relies on the assumption that // dial tasks complete after the peer has been added or // discarded. Unblock the task last. select &#123; case c.cont &lt;- err: case &lt;-srv.quit: break running &#125; case pd := &lt;-srv.delpeer: // A peer disconnected. nid := pd.ID() d := common.PrettyDuration(mclock.Now() - pd.created) pd.log.Info("Removing p2p peer", "duration", d) pd.log.Debug("Removing p2p peer", "duration", d, "req", pd.requested, "err", pd.err) delete(peers, nid) shortid := fmt.Sprintf("%x", nid[0:8]) if err := PeerMgrInst().unregister(shortid); err != nil &#123; log.Debug("Peer removal failed", "peer", shortid, "err", err) &#125; srv.ntab.RemoveNode(nid) expire := time.Second*time.Duration(10+rand.Intn(20)) srv.delHist.add(nid, time.Now().Add(expire)) log.Debug("Server running: add node to history.","expire",expire) &#125; &#125; log.Debug("P2P networking is spinning down") // Terminate discovery. If there is a running lookup it will terminate soon. if srv.ntab != nil &#123; srv.ntab.Close() &#125; // Disconnect all peers. for _, p := range peers &#123; p.Disconnect(DiscQuitting) &#125; // Wait for peers to shut down. Pending connections and tasks are // not handled here and will terminate soon-ish because srv.quit // is closed. for len(peers) &gt; 0 &#123; p := &lt;-srv.delpeer p.log.Trace("&lt;-delpeer (spindown)", "remainingTasks", len(runningTasks)) delete(peers, p.ID()) &#125;&#125; 这块代码挺复杂的，各种go routine和chan的使用。😂😂😂😂😂😂😂😂]]></content>
      <categories>
        <category>HPB源码解读</category>
      </categories>
      <tags>
        <tag>HPB</tag>
        <tag>区块链</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GO-HPB源码解读--交易入池（二）]]></title>
    <url>%2F2019%2F07%2F21%2FGO-HPB%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB-%E4%BA%A4%E6%98%93%E5%85%A5%E6%B1%A0%EF%BC%88%E4%BA%8C%EF%BC%89%2F</url>
    <content type="text"><![CDATA[上一节看到交易通过pool.promoteTx(addr, hash, tx)方法进行了传递，在该方法的最后一步通过pool.txFeed.Send(bc.TxPreEvent{tx})，将交易封装成bc.TxPreEvent发送了出去。而这个Feed实现了订阅发布模式，Send方法是发布消息，SubscribeTxPreEvent是订阅消息，订单的时候只需要把订单者的chan发进来就可以了。 （Feed通过反射包reflect中的selectcase、trySend和tryReceive方法进行的，操作包装在Feed文件中，golang的源码包中有all_test.go测试文件可以详细看下）订阅这个消费的一共有三个地方，分中在api_backend.go、synctrl.go、worker.go中。这里主要看一下广播和evn执行。 api_backend.go中只是订单并没处理 synctrl.go中进行消费的广播 worker.go中进行了evn执行 123func (pool *TxPool) SubscribeTxPreEvent(ch chan&lt;-bc.TxPreEvent) sub.Subscription &#123; return pool.scope.Track(pool.txFeed.Subscribe(ch))&#125; 在synctrl.go的调用顺序是–&gt;main–&gt;ghpb–&gt;startNode–&gt;–&gt;utils.StartNode(stack)–&gt;hpbnode.Start()–&gt;–&gt;hpbnode.Hpbsyncctr.Start() 在Start方法中初始化this.txCh，并进行消息订单 消息的消费是在txRoutingLoop协程中 在routTx方法中，找出不知道该交易的peer，然后逐个发出去了123456789101112131415161718192021222324func (this *SynCtrl) Start() &#123; // broadcast transactions this.txCh = make(chan bc.TxPreEvent, txChanSize) this.txSub = this.txpool.SubscribeTxPreEvent(this.txCh) go this.txRoutingLoop() // broadcast mined blocks this.minedBlockSub = this.newBlockMux.Subscribe(bc.NewMinedBlockEvent&#123;&#125;) go this.minedRoutingLoop() // start sync handlers go this.sync() go this.txsyncLoop()&#125;func (this *SynCtrl) txRoutingLoop() &#123; for &#123; select &#123; case event := &lt;-this.txCh: routTx(event.Tx.Hash(), event.Tx) &#125; &#125;&#125; 在worker.go的调用顺序是–&gt;main–&gt;ghpb–&gt;startNode–&gt;–&gt;hpbnode.WorkerInit–&gt;worker.New–&gt;newWorker在newWorker中初始化worker.txCh，并订阅消息，消息的处理是在协程worker.eventListener()中进行的。在系统没有挖矿的状态下，把消息发送到commitTransactions进行处理。commitTransactions会把交易提交到evm进行执行，这个单独解析下吧。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768func newWorker(config *config.ChainConfig, engine consensus.Engine, coinbase common.Address, /*eth Backend,*/ mux *sub.TypeMux) *worker &#123; worker := &amp;worker&#123; config: config, engine: engine, mux: mux, /*txCh: make(chan bc.TxPreEvent, txChanSize),*/ chainHeadCh: make(chan bc.ChainHeadEvent, chainHeadChanSize), chainSideCh: make(chan bc.ChainSideEvent, chainSideChanSize), chainDb: nil,//hpbdb.ChainDbInstance(), recv: make(chan *Result, resultQueueSize), chain: bc.InstanceBlockChain(), proc: bc.InstanceBlockChain().Validator(), possibleUncles: make(map[common.Hash]*types.Block), coinbase: coinbase, producers: make(map[Producer]struct&#123;&#125;), unconfirmed: newUnconfirmedBlocks(bc.InstanceBlockChain(), miningLogAtDepth), &#125; worker.pool = txpool.GetTxPool() worker.txCh = make(chan bc.TxPreEvent, txChanSize) worker.txSub = worker.pool.SubscribeTxPreEvent(worker.txCh) worker.chainHeadSub = bc.InstanceBlockChain().SubscribeChainHeadEvent(worker.chainHeadCh) worker.chainSideSub = bc.InstanceBlockChain().SubscribeChainSideEvent(worker.chainSideCh) //对以上事件的监听 go worker.eventListener() go worker.handlerSelfMinedBlock() return worker&#125;func (self *worker) eventListener() &#123; defer self.txSub.Unsubscribe() defer self.chainHeadSub.Unsubscribe() defer self.chainSideSub.Unsubscribe() for &#123; // A real event arrived, process interesting content select &#123; // Handle ChainHeadEvent case &lt;-self.chainHeadCh: self.startNewMinerRound() // Handle ChainSideEvent case ev := &lt;-self.chainSideCh: self.uncleMu.Lock() self.possibleUncles[ev.Block.Hash()] = ev.Block self.uncleMu.Unlock() // Handle TxPreEvent case ev := &lt;-self.txCh: // Apply transaction to the pending state if we're not mining if atomic.LoadInt32(&amp;self.mining) == 0 &amp;&amp; self.current != nil &#123; self.currentMu.Lock() acc, _ := types.Sender(self.current.signer, ev.Tx) txs := map[common.Address]types.Transactions&#123;acc: &#123;ev.Tx&#125;&#125; txset := types.NewTransactionsByPriceAndNonce(self.current.signer, txs) self.current.commitTransactions(self.mux, txset, self.coinbase) self.currentMu.Unlock() &#125; case &lt;-self.chainHeadSub.Err(): return case &lt;-self.chainSideSub.Err(): return &#125; &#125;&#125;]]></content>
      <categories>
        <category>HPB源码解读</category>
      </categories>
      <tags>
        <tag>HPB</tag>
        <tag>区块链</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GO-HPB源码解读--交易入池（一）]]></title>
    <url>%2F2019%2F07%2F21%2FGO-HPB%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB-%E4%BA%A4%E6%98%93%E5%85%A5%E6%B1%A0%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[在本地启动节点后，通过控制台输入命令hpb.sendTransaction({from:&quot;db3cf5c98af974d3cccdc8662f1ab3c27c6e47ee&quot;,to:&quot;742c8a59152a397ad09f7fb280c4fc378598a4ba&quot;,value:web3.toWei(10000,&quot;hpb&quot;)})来完成转账交易。交易内容最初始会进入到SendTransaction。 打印了一下传进来的参数args{From:[219 60 245 201 138 249 116 211 204 205 200 102 47 26 179 194 124 110 71 238] To:[116 44 138 89 21 42 57 122 208 159 127 178 128 196 252 55 133 152 164 186] Gas: GasPrice: Value:0x21e19e0c9bab2400000 Data:0x Nonce:} 首先检查一下from地址是不是存在钱包中，如果不存在就返回错误 锁定交易的nonce，因为nonce是唯一的，防止交易的重播攻击 对交易需要的其他参数进行设置，Gas默认值为90000，GasPrice和Nonce经由计算获得，这个后续再分析 创建一个交易对象，将以上参数进行赋值 使用from的帐户钱包对交易进行签名，来证明这签交易确实是from发出的。签名过程：(1). 首先使用from的私钥对nonce、price、gaslimit、recipient、amount、payload进行secp256k1签名(2). 然后签名结果分解成R、S、V，并赋给交易对象，注意这个时候交易对象中并没有from地址 最后提交交易 123456789101112131415161718192021222324252627282930313233343536// SendTransaction creates a transaction for the given argument, sign it and submit it to the// transaction pool.func (s *PublicTransactionPoolAPI) SendTransaction(ctx context.Context, args SendTxArgs) (common.Hash, error) &#123; // Look up the wallet containing the requested signer account := accounts.Account&#123;Address: args.From&#125; wallet, err := s.b.AccountManager().Find(account) if err != nil &#123; return common.Hash&#123;&#125;, err &#125; if args.Nonce == nil &#123; // Hold the addresse's mutex around signing to prevent concurrent assignment of // the same nonce to multiple accounts. s.nonceLock.LockAddr(args.From) defer s.nonceLock.UnlockAddr(args.From) &#125; // Set some sanity defaults and terminate on failure if err := args.setDefaults(ctx, s.b); err != nil &#123; return common.Hash&#123;&#125;, err &#125; // Assemble the transaction and sign with the wallet tx := args.toTransaction() var chainID *big.Int if config := s.b.ChainConfig(); true &#123; chainID = config.ChainId &#125; signed, err := wallet.SignTx(account, tx, chainID) if err != nil &#123; return common.Hash&#123;&#125;, err &#125; return submitTransaction(ctx, s.b, signed)&#125; submitTransaction方法把交易提交到交易池txpool 首先计算交易的hash，这个交易在输入交易命令后显示的那个hash值 判断交易池中是否包含该交易，包含的话就直接回退失败 验证交易 锁定交易，也就是把交易保存到交易池的过程123456789101112131415161718// AddTx attempts to queue a transactions if valid.func (pool *TxPool) AddTx(tx *types.Transaction) error &#123; pool.mu.Lock() defer pool.mu.Unlock() hash := tx.Hash() if pool.all[hash] != nil &#123; log.Trace("Discarding already known transaction", "hash", hash) return fmt.Errorf("known transaction: %x", hash) &#125; // If the transaction fails basic validation, discard it if err := pool.validateTx(tx); err != nil &#123; log.Trace("Discarding invalid transaction", "hash", hash, "err", err) return err &#125; return pool.addTxLocked(tx)&#125; validateTx对交易进行验证 交易的大小是否超过32k，其中的tx.Size主要计算的是交易的data部分的数据大小 交易金额不能小于0 当前交易的gasLimit是否大于当前区块的最大gas值，每个区块块都有一个总的gas限制，也就是一个区块中的所有交易的gas总和不能超过区块的gas限制 验证签名是否有效，并还原出地址from（这块没细看，之后再看下） 交易给出的gas价格必须大于txpool的最低价格，要不然挖工收益会少 当前交易的nonce必须要大于上一次的交易nonce。帐户信息直接保存在stateDB中，可以从中获取 交易花费gasprice*gasLimit必须大于帐户余额 如果交易是创建合约或者调用合约，需要计算一下需要多少gas，如果交易支付的最大gas不够多也是拒绝的（这块没细看，之后再看下）123456789101112131415161718192021222324252627282930313233343536373839404142434445464748// validateTx checks whether a transaction is valid according to the consensus// rules and adheres to some heuristic limits of the local node (price and size).func (pool *TxPool) validateTx(tx *types.Transaction) error &#123; // Heuristic limit, reject transactions over 32KB to prevent DOS attacks if tx.Size() &gt; maxTransactionSize &#123; log.Trace("ErrOversizedData maxTransactionSize", "ErrOversizedData",ErrOversizedData) return ErrOversizedData &#125; // Transactions can't be negative. This may never happen using RLP decoded // transactions but may occur if you create a transaction using the RPC. if tx.Value().Sign() &lt; 0 &#123; log.Trace("ErrNegativeValue", "ErrNegativeValue",ErrNegativeValue) return ErrNegativeValue &#125; // Ensure the transaction doesn't exceed the current block limit gas. if pool.currentMaxGas.Cmp(tx.Gas()) &lt; 0 &#123; log.Trace("ErrGasLimit", "ErrGasLimit",ErrGasLimit) return ErrGasLimit &#125; // Call BOE recover sender. from, err := types.Sender(pool.signer, tx) if err != nil &#123; log.Trace("ErrInvalidSender", "ErrInvalidSender",ErrInvalidSender) return ErrInvalidSender &#125; // Check gasPrice. if pool.gasPrice.Cmp(tx.GasPrice()) &gt; 0 &#123; log.Trace("ErrUnderpriced", "ErrUnderpriced",ErrUnderpriced) return ErrUnderpriced &#125; // Ensure the transaction adheres to nonce ordering if pool.currentState.GetNonce(from) &gt; tx.Nonce() &#123; log.Trace("ErrNonceTooLow", "tx.Nonce()",tx.Nonce()) return ErrNonceTooLow &#125; // Transactor should have enough funds to cover the costs // cost == V + GP * GL if pool.currentState.GetBalance(from).Cmp(tx.Cost()) &lt; 0 &#123; log.Trace("ErrInsufficientFunds", "ErrInsufficientFunds",ErrInsufficientFunds) return ErrInsufficientFunds &#125; intrGas := types.IntrinsicGas(tx.Data(), tx.To() == nil) if tx.Gas().Cmp(intrGas) &lt; 0 &#123; log.Trace("ErrIntrinsicGas", "ErrIntrinsicGas",ErrIntrinsicGas) return ErrIntrinsicGas &#125; return nil&#125; 1234567891011121314// addTx enqueues a single transaction into the pool if it is valid.func (pool *TxPool) addTxLocked(tx *types.Transaction) error &#123; // Try to inject the transaction and update any state replace, err := pool.add(tx) if err != nil &#123; return err &#125; // If we added a new transaction, run promotion checks and return if !replace &#123; from, _ := types.Sender(pool.signer, tx) // already validated pool.promoteExecutables([]common.Address&#123;from&#125;) &#125; return nil&#125; pool.add方法中 首先计算交易的hash，并获取from地址 判断交易池是否满了，如果满了就返回失败。这里需要注意一下交易池维护着两个集合一个是pending，一个是queue，pending存放的是可以处理的交易，queue存放的是不可以处理的交易。 把交易池中pending所有from地址的交易都取出来赋到list，看看是不是包含相同的nonce的交易。（上边在创建交易的时候判断了nonce大于当前的，什么情况下会重复呢？）如果包含的话就往list里插入，但是插入的时候要判断一下这笔交易值不值替换上一笔相同nonce的交易。交易池有个参数priceBump，表示上浮价格，比如是20，当旧交易的old_gasprice*(100+20)/100=1.2倍的old_gaspreice，如果当前交易的价格大于1.2倍的old_gaspreice，则进行替换。同时list也会更新一下最大交易额和最大gas这时txpool才会把当前交易缓存起来 如果list也就是pending中没有重复的交易，那么对于queue也做同样的替换操作。注意如果queue中不存在该交易是会插入的，pending是不会的。（txpool.queue是个map，key是from地址，value是个list，保存着所有from地址的交易信息，也就是上边提到的list） 12345678910111213141516171819202122232425262728293031323334353637383940414243func (pool *TxPool) add(tx *types.Transaction) (bool, error) &#123; // If the transaction is already known, discard it hash := tx.Hash() from, _ := types.Sender(pool.signer, tx) // already validated // If the transaction pool is full, reject if uint64(len(pool.all)) &gt;= pool.config.GlobalSlots+pool.config.GlobalQueue &#123; log.Warn("TxPool is full, reject tx", "current size", len(pool.all), "max size", pool.config.GlobalSlots+pool.config.GlobalQueue, "hash", hash, "from", from, "to", tx.To()) return false, ErrTxPoolFull &#125; // If the transaction is replacing an already pending one, do directly if list := pool.pending[from]; list != nil &amp;&amp; list.Overlaps(tx) &#123; // Nonce already pending, check if required price bump is met inserted, old := list.Add(tx, pool.config.PriceBump) if !inserted &#123; return false, ErrReplaceUnderpriced &#125; // New transaction is better, replace old one if old != nil &#123; delete(pool.all, old.Hash()) &#125; pool.all[tx.Hash()] = tx pool.tmpqueue[tx.Hash()] = tx log.Trace("Pooled new executable transaction", "hash", hash, "from", from, "to", tx.To()) // We've directly injected a replacement transaction, notify subsystems //TODO why inject event here //event.FireEvent(&amp;event.Event&#123;Trigger: pool.txPreTrigger, Payload: event.TxPreEvent&#123;tx&#125;, Topic: event.TxPreTopic&#125;) return old != nil, nil &#125; // New transaction isn't replacing a pending one, push into queue replace, err := pool.enqueueTx(hash, tx) if err != nil &#123; return false, err &#125; log.Trace("Pooled new future transaction", "hash", hash, "from", from, "to", tx.To()) return replace, nil&#125; 如果交易池中的queue插入成功的话，queue数据发生变化，接下来promoteExecutables方法就是要把queue中某些交易移到pending中，从不可以处理的状态变成可处理的状态 删除所有nonce太低的交易 删除帐户余额太低或gas超过交易池限制的交易 将queue交易添加到pending中，同时会把交易发送到chan通道，chan接收之后广播到网络中的其他peer节点 删除超过queue容量限制的交易 最后keepFit处理超过pending容量限制的交易123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263func (pool *TxPool) promoteExecutables(accounts []common.Address) &#123; // Gather all the accounts potentially needing updates if accounts == nil &#123; accounts = make([]common.Address, 0, len(pool.queue)) for addr := range pool.queue &#123; accounts = append(accounts, addr) &#125; &#125; // Iterate over all accounts and promote any executable transactions for _, addr := range accounts &#123; list := pool.queue[addr] if list == nil &#123; continue // Just in case someone calls with a non existing account &#125; // Drop all transactions that are deemed too old (low nonce) for _, tx := range list.Forward(pool.currentState.GetNonce(addr)) &#123; hash := tx.Hash() log.Trace("Removed old queued transaction", "hash", hash) delete(pool.all, hash) &#125; // Drop all transactions that are too costly (low balance or out of gas) drops, _ := list.Filter(pool.currentState.GetBalance(addr), pool.currentMaxGas) for _, tx := range drops &#123; hash := tx.Hash() log.Trace("Removed unpayable queued transaction", "hash", hash) delete(pool.all, hash) &#125; // Gather all executable transactions and promote them for _, tx := range list.Ready(pool.pendingState.GetNonce(addr)) &#123; hash := tx.Hash() log.Trace("Promoting queued transaction", "hash", hash,"pool.pendingState.GetNonce(addr)",pool.pendingState.GetNonce(addr)) pool.promoteTx(addr, hash, tx) // Delete a single queue transaction if list != nil &#123; list.Remove(tx) &#125; &#125; // Drop all transactions over the allowed limit for _, tx := range list.Cap(int(pool.config.AccountQueue)) &#123; hash := tx.Hash() delete(pool.all, hash) log.Trace("Removed cap-exceeding queued transaction", "hash", hash) &#125; // Delete the entire queue entry if it became empty. if list.Empty() &#123; log.Trace("promoteExecutables list.Empty()") delete(pool.queue, addr) &#125; &#125; pool.keepFit()&#125;]]></content>
      <categories>
        <category>HPB源码解读</category>
      </categories>
      <tags>
        <tag>HPB</tag>
        <tag>区块链</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GO-HPB源码解读--投票机制]]></title>
    <url>%2F2019%2F07%2F21%2FGO-HPB%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB-%E6%8A%95%E7%A5%A8%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[在挖矿流程的最近一节中，提到了voting.GetHpbNodeSnap的投票机制。投票的目的就是来计算出本节点是否能够签名区块，所以每次在组装区块的时候都会获取上一次的投票结果，如果出现异常或者投票周期到了，则重新计算投票结果。投票结果是通过结构体进行保存的。CandAddress 节点地址(当前的授权用户)VoteNumbers 获得票数VoteIndexs 获胜者的指标总和VotePercent 占比 12345678910111213141516171819type Tally struct &#123; CandAddress common.Address `json:"candAddress"` // 通过投票的个数 VoteNumbers *big.Int `json:"voteNumbers"` // 通过投票的个数 VoteIndexs *big.Int `json:"voteIndexs"` // 通过投票的个数 VotePercent *big.Int `json:"votePercent"` // 通过投票的个数&#125;&lt;!-- more --&gt;type HpbNodeSnap struct &#123; config *config.PrometheusConfig sigcache *lru.ARCCache //Number uint64 `json:"number"` // 生成快照的时间点 CheckPointNum uint64 `json:"checkPointNum"` // 最近的检查点 CheckPointHash common.Hash `json:"checkPointHash"` // 生成快照的Block hash Signers map[common.Address]struct&#123;&#125; `json:"signers"` // 当前的授权用户 Recents map[uint64]common.Address `json:"recents"` // 最近签名者 spam Tally map[common.Address]Tally `json:"tally"` // 目前的计票情况&#125; 接下来看一下代码实现，其中HpbNodeCheckpointInterval==200 如果number==0，就先生成一个初始快照并返回 如果number&lt;200，就从缓存/数据库中取出初始快照，如果取出失败，则生成一个初始快照并返回 其他情况就是number&gt;=200，如果number正好是200的整数倍数的话，则生成快照，否则从缓存/数据库中获取上一次的快照，如果获取失败则重新生成上一次的快照。举个栗子，number=666，则获取number=600的快照，如果number=800，则生成新的快照。很明显间隔相当于从0开始算的，并不是最近的200个块。但是。。。往下看number是怎么使用的12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364func GetHpbNodeSnap(db hpbdb.Database, recents *lru.ARCCache, signatures *lru.ARCCache, config *config.PrometheusConfig, chain consensus.ChainReader, number uint64, hash common.Hash, parents []*types.Header) (*snapshots.HpbNodeSnap, error) &#123; // 首次要创建 if number == 0 &#123; if snapg, err := GenGenesisSnap(db, recents, signatures, config, chain); err == nil &#123; return snapg, err &#125; &#125; //前十轮不会进行投票，前10轮采用区块0时候的数据 //先获取缓存，如果缓存中没有则获取数据库，为了提升速度 //if(true)&#123; if number &lt; consensus.HpbNodeCheckpointInterval &#123; genesis := chain.GetHeaderByNumber(0) hash := genesis.Hash() // 从缓存中获取 if snapcd, err := GetDataFromCacheAndDb(db, recents, signatures, config, hash); err == nil &#123; log.Debug("HPB_VOTING： Loaded voting Hpb Node Snap form cache and db", "number", number, "hash", hash) return snapcd, err &#125; else &#123; if snapg, err := GenGenesisSnap(db, recents, signatures, config, chain); err == nil &#123; log.Debug("HPB_VOTING： Loaded voting Hpb Node Snap form genesis snap", "number", number, "hash", hash) return snapg, err &#125; &#125; &#125; // 开始考虑10轮之后的情况，往前回溯3轮，以保证一致性。 // 开始计算最后一次的确认区块 latestCheckPointNumber := uint64(math.Floor(float64(number/consensus.HpbNodeCheckpointInterval))) * consensus.HpbNodeCheckpointInterval //log.Error("Current latestCheckPointNumber in hpb voting:",strconv.FormatUint(latestCheckPointNumber, 10)) header := chain.GetHeaderByNumber(uint64(latestCheckPointNumber)) latestCheckPointHash := header.Hash() if number%consensus.HpbNodeCheckpointInterval != 0 &#123; if snapcd, err := GetDataFromCacheAndDb(db, recents, signatures, config, latestCheckPointHash); err == nil &#123; //log.Info("##########################HPB_VOTING： Loaded voting Hpb Node Snap form cache and db", "number", number, "latestCheckPointNumber", latestCheckPointNumber) return snapcd, err &#125; else &#123; if snapa, err := snapshots.CalculateHpbSnap(uint64(1), signatures, config, number, latestCheckPointNumber, latestCheckPointHash, chain); err == nil &#123; //log.Info("@@@@@@@@@@@@@@@@@@@@@@@@HPB_VOTING： CalculateHpbSnap", "number", number, "latestCheckPointNumber", latestCheckPointNumber) if err := StoreDataToCacheAndDb(recents, db, snapa, latestCheckPointHash); err != nil &#123; return nil, err &#125; return snapa, err &#125; &#125; &#125; else &#123; if snapa, err := snapshots.CalculateHpbSnap(uint64(1), signatures, config, number, latestCheckPointNumber, latestCheckPointHash, chain); err == nil &#123; //log.Info("@@@@@@@@@@@@@@@@@@@@@@@@HPB_VOTING： CalculateHpbSnap", "number", number, "latestCheckPointNumber", latestCheckPointNumber) //新轮次计算完高性能节点立即更新节点类型 //prometheus.SetNetNodeType(snapa) if err := StoreDataToCacheAndDb(recents, db, snapa, latestCheckPointHash); err != nil &#123; return nil, err &#125; return snapa, err &#125; else &#123; return nil, err &#125; &#125; return nil, nil&#125; 具体生成快照的算法是在CalculateHpbSnap中实现的，也就是区块链核的共识算法。先看一下参数含意：字段|类型|含义|备注-|-|-|-index | |投票轮次，CalculateHpbSnap调用时是第一次，所以传1 |*lru | |最近的签名，使用ARC算法实现 |config | |共识配置，Prometheus的属性 |number | |区块序号 |latestCheckPointNum |最近应该生成快照对应的区块序号，也就是200的整数倍 | |latestCheckPointHash |最近应该生成快照对应的区块哈希 | |chain |区块链指针 | | 快照生成主要通过number参数选举出一定的区块生成节点，这块要主算法实现，为了方便理解，假设在生成区块时的number为210、650、1875，也就是调用GetHpbNodeSnap方法传入的number，表示为{210|650|1875}，最后计算得到latestCheckPointNum是{200|600|1800}，将这两个参数传入CalculateHpbSnap，注意此时index传入的是1 选出一定范围内的区块头集合，区间界线为from到latestCheckPointNum-100，from计算方法是latestCheckPointNum - index*consensus.HpbNodeCheckpointInterval，所以可以得到的范围是{0-100|400-500|1600-1700} 通过chain取出{0-100|400-500|1600-1700}范围内所有区块头，赋给headers变量，一共100个区块头（理想情况下）。如果在获取头的时候累计出了20次没取到，直接返回异常errors.New(“get hpb snap but missing header”) 对区块头集合headers进行连续性检查，也就是所有区块头的number必须是连续的，否则返回异常 初始化快照对象snap，并填装snap的Tally属性，注意snap的Tally是map[common.Address]Tally类型的，key是add，value是Tally，而value的类型Tally本身又是一个结构体。填装过程就是把header对应的所有address作为键put到map中，value是Tally结构体。 *Tally初始值是VoteNumbers: 1, VoteIndexs: header.VoteIndex, VotePercent: header.VoteIndex, *如果key重复出现，则需要把VoteNumbers和VoteIndexs对应的新旧值进行累加，重新计算VotePercent=VoteIndexs/VoteNumbers并赋值这样就得到了100一个header对应的address的Tally，当然结果可能会少于100个，因为有重复的。 将map再复制到临时变量tallytemp中，分别按照CandAddress和百分比VotePercent从小到大进行排序，排序结果保存到变更finaltally中 接下来通过当前高性能节点数量来解决是否需要再次进行获取一些headers来进行投票计算，也就是上边1-5步骤 系统默认的高性能节点个数是consensus.HpbNodenumber=31个，如果finaltally长度大等于31，则把排序后的后边的31个节点地址添加到snap.Signers中，即授权用户，表示可以进行挖矿。 如果finaltally小于31，而且已经进行了4次投票计算（1-5步骤），就把finaltally中所有的地址进行授权 如果finaltally小于31，而且进行了不到4次投票计算，则往前回溯再取出一些区块头（地址）进行投票。但是往前回溯有个条件，就是前边有足够的区块头可以获取，如果前边的区块头不够充足了，则只能把当前finaltally的地址全部授权了。是否可以往前回溯的判断条件是index&lt;number/200，比如第一轮投票的时候number={210|650|1875}，投了{0-100|400-500|1600-1700}区间的节点地址，最终结果不够31个高性能节点，那么进行第二轮投票。2&lt;210/200为false，这种情况就不能往前回溯了；2&lt;650/200为true，则可以回溯，然后递归调用CalculateHpbSnap方法，这时传入的index=2，number和latestCheckPointNum分别向前移200个单位，即number={-|450|1675}，latestCheckPointNum={-|400|1600}，递归后可得范围为 {-|200-300|1400-1500}。可以发现每次中间隔100个单位。 在进行了下一投票计算（递归调用）之后，得到新的节点地址集合，把其中已经存在于上一次finaltally中的地址删除掉，此时如果新的节点地址一个也没有，则结束投票，如果还有的话就对新的节点地址集合进行排序 排序完了之后，如果新旧集合的长度和小等于31，就把新旧集合合并一下，否则的话把新集合的数据补充到旧集合中，直到旧集合够31个节点了。 最后把zeroaddr地址删除掉。（不是很清楚，什么情况下会有存在zeroaddr地址） 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179func CalculateHpbSnap(index uint64, signatures *lru.ARCCache, config *config.PrometheusConfig, number uint64, latestCheckPointNum uint64, latestCheckPointHash common.Hash, chain consensus.ChainReader) (*HpbNodeSnap, error) &#123; // Allow passing in no headers for cleaner code var headers []*types.Header // 开始获取之前的所有header var from = latestCheckPointNum - index*consensus.HpbNodeCheckpointInterval if from == 0 &#123; from = from + 1 &#125; for i := from; i &lt; latestCheckPointNum-100; i++ &#123; loopcount := 0 GETCOUNT: header := chain.GetHeaderByNumber(uint64(i)) if header != nil &#123; headers = append(headers, header) &#125; else &#123; if loopcount &gt; 20 &#123; return nil, errors.New("get hpb snap but missing header") &#125; loopcount += 1 goto GETCOUNT //log.Error("get hpb snap but missing header", "number", i) &#125; &#125; // 如果头部为空，直接返回 if len(headers) == 0 &#123; return nil, errors.New("Calculate Hpb Snap headers is 0 ") &#125; // 检查所有的头部，检查连续性 for i := 0; i &lt; len(headers)-1; i++ &#123; if headers[i+1].Number.Uint64() != headers[i].Number.Uint64()+1 &#123; return nil, consensus.ErrInvalidVotingChain &#125; &#125; //signers := make([]common.Address, 0, consensus.HpbNodenumber) snap := NewHistorysnap(config, signatures, number, latestCheckPointNum, latestCheckPointHash, nil) snap.Tally = make(map[common.Address]Tally) for _, header := range headers &#123; VoteNumberstemp := big.NewInt(0) VoteIndexstemp := big.NewInt(0) VotePercenttemp := big.NewInt(0) //票的数量与性能之间的关系，获取票的数量表示在线时间长度，所以应该选择在线时间长性能又好的节点。 if old, ok := snap.Tally[header.CandAddress]; ok &#123; VoteNumberstemp.Add(old.VoteNumbers, big.NewInt(1)) VoteIndexstemp.Add(old.VoteIndexs, header.VoteIndex) VotePercenttemp.Div(VoteIndexstemp, VoteNumberstemp) snap.Tally[header.CandAddress] = Tally&#123; VoteNumbers: VoteNumberstemp, VoteIndexs: VoteIndexstemp, VotePercent: VotePercenttemp, CandAddress: header.CandAddress, &#125; &#125; else &#123; snap.Tally[header.CandAddress] = Tally&#123; VoteNumbers: big.NewInt(1), VoteIndexs: header.VoteIndex, VotePercent: header.VoteIndex, CandAddress: header.CandAddress, &#125; &#125; &#125; var tallytemp []Tally for _, v := range snap.Tally &#123; tallytemp = append(tallytemp, v) &#125; for i := 0; i &lt; len(snap.Tally); i++ &#123; for j := 0; j &lt; len(snap.Tally)-i-1; j++ &#123; if bytes.Compare(tallytemp[j].CandAddress[:], tallytemp[j+1].CandAddress[:]) &gt; 0 &#123; tallytemp[j], tallytemp[j+1] = tallytemp[j+1], tallytemp[j] &#125; &#125; &#125; for i := 0; i &lt; len(snap.Tally); i++ &#123; for j := 0; j &lt; len(snap.Tally)-i-1; j++ &#123; if tallytemp[j].VotePercent.Cmp(tallytemp[j+1].VotePercent) &gt; 0 &#123; tallytemp[j], tallytemp[j+1] = tallytemp[j+1], tallytemp[j] &#125; else if (tallytemp[j].VotePercent.Cmp(tallytemp[j+1].VotePercent) == 0) &amp;&amp; (bytes.Compare(tallytemp[j].CandAddress[:], tallytemp[j+1].CandAddress[:]) &gt; 0) &#123; tallytemp[j], tallytemp[j+1] = tallytemp[j+1], tallytemp[j] &#125; &#125; &#125; finaltally := make([]common.Address, 0, len(tallytemp)) for _, v := range tallytemp &#123; finaltally = append(finaltally, v.CandAddress) &#125; var hpnodeNO int if len(finaltally) &gt;= consensus.HpbNodenumber &#123; hpnodeNO = consensus.HpbNodenumber goto END &#125; else &#123; if index == consensus.Hpcalclookbackround+1 &#123; //look back round is consensus.Hpcalclookbackround hpnodeNO = len(finaltally) goto END &#125; index = index + 1 if index &lt; uint64(math.Floor(float64(number/consensus.HpbNodeCheckpointInterval))) &#123; // 往前回溯 //log.Error("-------- go back for last snap------------", "index", index) header := chain.GetHeaderByNumber(uint64(latestCheckPointNum - consensus.HpbNodeCheckpointInterval)) latestCheckPointHash := header.Hash() snaptemp, err := CalculateHpbSnap(index, signatures, config, number-consensus.HpbNodeCheckpointInterval, latestCheckPointNum-consensus.HpbNodeCheckpointInterval, latestCheckPointHash, chain) if err != nil &#123; log.Debug("recursive call CalculateHpbSnap fail", "err", err) hpnodeNO = len(finaltally) goto END &#125; //get last snap hp nodes, set in map hpsmaptemp := make(map[common.Address]struct&#123;&#125;) lastsnap := snaptemp.GetHpbNodes() for _, v := range lastsnap &#123; hpsmaptemp[v] = struct&#123;&#125;&#123;&#125; &#125; //delete tallytemp.CandAddress in the map for _, v := range finaltally &#123; if _, ok := hpsmaptemp[v]; ok &#123; delete(hpsmaptemp, v) &#125; &#125; if 0 == len(hpsmaptemp) &#123; hpnodeNO = len(finaltally) goto END &#125; //order the hpsmaptemp by put it into []common.address delhpsmap := make([]common.Address, len(hpsmaptemp)) for key, _ := range hpsmaptemp &#123; delhpsmap = append(delhpsmap, key) &#125; //sort by addr if 1 &lt; len(delhpsmap) &#123; for i := 0; i &lt; len(delhpsmap); i++ &#123; for j := 0; j &lt; len(delhpsmap)-i-1; j++ &#123; if bytes.Compare(delhpsmap[j][:], delhpsmap[j+1][:]) &gt; 0 &#123; delhpsmap[j], delhpsmap[j+1] = delhpsmap[j+1], delhpsmap[j] &#125; &#125; &#125; &#125; //calc how many last snap hps needing to add the latest snap if len(finaltally)+len(delhpsmap) &gt; consensus.HpbNodenumber &#123; for i := 0; i &lt; consensus.HpbNodenumber-len(finaltally); i++ &#123; finaltally = append(finaltally, delhpsmap[i]) &#125; &#125; else &#123; for i := 0; i &lt; len(delhpsmap); i++ &#123; finaltally = append(finaltally, delhpsmap[i]) &#125; &#125; &#125; hpnodeNO = len(finaltally) &#125;END: for i := len(finaltally) - 1; i &gt; len(finaltally)-hpnodeNO-1; i-- &#123; snap.Signers[finaltally[i]] = struct&#123;&#125;&#123;&#125; &#125; zeroaddr := common.HexToAddress("0x0000000000000000000000000000000000000000") if _, ok := snap.Signers[zeroaddr]; ok &#123; delete(snap.Signers, zeroaddr) &#125; return snap, nil&#125; 在确定节点地址区间的逻辑比较简单,就是从前往后，隔100,标记100个为可取的,然后从后往前取倒数第一个100，去重后够31个就可以了，不够了再取倒数第2个100。代码算法写的复杂了，还用了递归。。。。。VoteIndexs这个是从区块头中取出来的，没找到最初是在哪儿set进去的。真累人………]]></content>
      <categories>
        <category>HPB源码解读</category>
      </categories>
      <tags>
        <tag>HPB</tag>
        <tag>区块链</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GO-HPB源码解读--挖矿流程（四）]]></title>
    <url>%2F2019%2F07%2F21%2FGO-HPB%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB-%E6%8C%96%E7%9F%BF%E6%B5%81%E7%A8%8B%EF%BC%88%E5%9B%9B%EF%BC%89%2F</url>
    <content type="text"><![CDATA[接着上一章，我们看到了这章来看了go self.mine(work, self.quitCurrentOp)这部分代码，现在来看下具体挖矿算法的流程。mine方法中调用engine.GenBlockWithSig方法，返回的result结果传递给returnCh通道，而returnCh通道的获取工作是在worker中进行处理的。上一节我们理了一下producer绑定CpuAgent的流程，在worker.New的时候，通过go worker.handlerSelfMinedBlock()这行代码启了一个协程去获取通道里的挖矿结果。 1234567891011func (self *CpuAgent) mine(work *Work, stop &lt;-chan struct&#123;&#125;) &#123; if result, err := self.engine.GenBlockWithSig(self.chain, work.Block, stop); result != nil &#123; log.Info("Successfully sealed new block", "number -&gt; ", result.Number(), "hash -&gt; ", result.Hash(),"difficulty -&gt; ",result.Difficulty()) self.returnCh &lt;- &amp;Result&#123;work, result&#125; &#125; else &#123; if err != nil &#123; log.Warn("Block sealing failed", "err", err) &#125; self.returnCh &lt;- nil &#125;&#125; 生成区块的过程： 数据合法性校验 获取签名者signer和签名方法signFn，这两个数据是在挖矿流程（二）中的StartMining方法中设置的，代码是promeengine.Authorize(eb, wallet.SignHash)，即signer是当前节点的挖矿地址coinbase，signFn是对应钱包的签名方法，即keystoreWallet类的签名方法 voting.GetHpbNodeSnap是获取高性能节点列表，其中有重新投票节点的过程，投票这个机制单独解读，这里就先不说了。 设置本地节点类型，是高性能节点还是候选节点 如果自己的当前节点不是包含在高性能节点中，则返回错误consensus.ErrUnauthorized 接着要判断一下自己当前节点是否轮到进行签名（挖矿），如果没轮到，需要通过高性能节点列表中自己的位置和正在挖矿的位置两个关键参数计算出自己需要等待的一个时间段， 时间到了的话就进行签名，签名方法为signFn,这个方法直接使用coinbase对应的私钥进行ECDSA签名 签名完了之后，把签名结果放置到header.Extra里，并返回最终block 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182//生成区块func (c *Prometheus) GenBlockWithSig(chain consensus.ChainReader, block *types.Block, stop &lt;-chan struct&#123;&#125;) (*types.Block, error) &#123; header := block.Header() log.Info("HPB Prometheus Seal is starting") number := header.Number.Uint64() if number == 0 &#123; return nil, consensus.ErrUnknownBlock &#125; // For 0-period chains, refuse to seal empty blocks (no reward but would spin sealing) if c.config.Period == 0 &amp;&amp; len(block.Transactions()) == 0 &#123; return nil, consensus.ErrWaitTransactions &#125; c.lock.RLock() signer, signFn := c.signer, c.signFn log.Debug("GenBlockWithSig-------------+++++ signer's address", "signer", signer.Hex(), "number", number) c.lock.RUnlock() snap, err := voting.GetHpbNodeSnap(c.db, c.recents, c.signatures, c.config, chain, number, header.ParentHash, nil) SetNetNodeType(snap) if err != nil &#123; return nil, err &#125; if _, authorized := snap.Signers[signer]; !authorized &#123; return nil, consensus.ErrUnauthorized &#125; // 轮到我们的签名 delay := time.Unix(header.Time.Int64(), 0).Sub(time.Now()) if delay &lt; 0 &#123; delay = 0 header.Time = big.NewInt(time.Now().Unix()) &#125; // 比较难度值，确定是否为适合的时间 if header.Difficulty.Cmp(diffNoTurn) == 0 &#123; // // It's not our turn explicitly to sign, delay it a bit wiggle := time.Duration(len(snap.Signers)/2+1) * wiggleTime currentminer := new(big.Int).SetBytes(header.HardwareRandom).Uint64() % uint64(len(snap.Signers)) //miner position //log.Error("-----genblocksig---------test for waiting 8 minutes--------------", "primemineraddr", primemineraddr, "primeoffset", currentminer, "number", number) myoffset := snap.GetOffset(header.Number.Uint64(), signer) distance := int(math.Abs(float64(int64(myoffset) - int64(currentminer)))) if distance &gt; len(snap.Signers)/2 &#123; distance = len(snap.Signers) - distance &#125; if distance &gt; len(snap.Signers)/consensus.StepLength &#123; //if signers length is smaller than 3, it means myoffset smaller than currentminer have high priority delay += time.Duration(len(snap.Signers)-distance+10+rand.Intn(5)) * wiggleTime &#125; else &#123; wiggle = time.Duration(1000+rand.Intn(len(snap.Signers))) * wiggleTime delay += wiggle &#125; &#125; log.Debug("Waiting for slot to sign and propagate", "delay", common.PrettyDuration(delay), "number", number) select &#123; case &lt;-stop: return nil, nil case &lt;-time.After(delay): &#125; // 地址赋值 header.Coinbase = signer // 签名交易，signFn为回掉函数 sighash, err := signFn(accounts.Account&#123;Address: signer&#125;, consensus.SigHash(header).Bytes()) if err != nil &#123; return nil, err &#125; //将签名后的结果返给到Extra中 copy(header.Extra[len(header.Extra)-consensus.ExtraSeal:], sighash) return block.WithSeal(header), nil&#125; 整个挖矿流程就到此结束了，当然其中会涉及一些其他的功能点，比如P2P，投票机制等，后续单独解读。这段代码读了很久，被投票那块搞死了，说好的POW呢？怎么没看到呢😭😭😭😭😭😭😭😭😭😭😭😭😭😭😭😭😭😭😭😭😭😭😭😭😭😭😭😭]]></content>
      <categories>
        <category>HPB源码解读</category>
      </categories>
      <tags>
        <tag>HPB</tag>
        <tag>区块链</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GO-HPB源码解读--挖矿流程（三）]]></title>
    <url>%2F2019%2F07%2F21%2FGO-HPB%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB-%E6%8C%96%E7%9F%BF%E6%B5%81%E7%A8%8B%EF%BC%88%E4%B8%89%EF%BC%89%2F</url>
    <content type="text"><![CDATA[在挖矿流程（三）的最后，看到在go self.mine(work, self.quitCurrentOp)中要传递一个work对象进去。因为挖矿流程需要使用到大量的work数据，所以单独分析一下work的数据结构和初始化流程 1234567891011121314151617181920// Work is the workers current environment and holds// all of the current state informationtype Work struct &#123; config *config.ChainConfig signer types.Signer state *state.StateDB // apply state changes here ancestors *set.Set // ancestor set (used for checking uncle parent validity) family *set.Set // family set (used for checking uncle invalidity) uncles *set.Set // uncle set tcount int // tx count in cycle Block *types.Block // the new block header *types.Header txs []*types.Transaction receipts []*types.Receipt createdAt time.Time&#125; 字段 类型 含义 备注 config *config.ChainConfig chain的配置参数 signer types.Signer 签名 state *state.StateDB ancestors *set.Set 祖先哈希集合，也就是最近的7个区块的哈希， family *set.Set 家族哈希集合，也就是最近的7个区块的哈希以及每个区块的叔区块集合的哈希 uncles *set.Set 叔块集合 tcount int 交易周期内的交易数量 Block *types.Block header *types.Header txs []*types.Transaction receipts []*types.Receipt createdAt time.Time startNewMinerRound()方法主要是创建了一个work并push到workch通道中，大至流程是： 确定区块的时间戳，因为上一区块可能来自节点同步，所以时间可能存在差异，这里确保了两个点，一是新块的时间一定要比上一区块的时间大，至少1；二是新块的时间和自己系统时间差不要超过1，也就是说计算出来的新块时间戳比当前时间加1s还大，那就只能等一会儿再执行了。比如当前时间是1，新区时间戳是8，那么就需要等7s了。 组织新块的header 初始化当前work对象 把appending的交易打包进来 使用共识引擎组装成一个完整的区块 提交挖矿任务work1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495func (self *worker) startNewMinerRound() &#123; self.mu.Lock() defer self.mu.Unlock() self.uncleMu.Lock() defer self.uncleMu.Unlock() self.currentMu.Lock() defer self.currentMu.Unlock() tstart := time.Now() parent := self.chain.CurrentBlock() tstamp := tstart.Unix() if parent.Time().Cmp(new(big.Int).SetInt64(tstamp)) &gt;= 0 &#123; tstamp = parent.Time().Int64() + 1 &#125; // this will ensure we're not going off too far in the future if now := time.Now().Unix(); tstamp &gt; now+1 &#123; wait := time.Duration(tstamp-now) * time.Second log.Info("Mining too far in the future", "wait", common.PrettyDuration(wait)) time.Sleep(wait) &#125; num := parent.Number() header := &amp;types.Header&#123; ParentHash: parent.Hash(), Number: num.Add(num, common.Big1), GasLimit: bc.CalcGasLimit(parent), GasUsed: new(big.Int), Extra: self.extra, Time: big.NewInt(tstamp), &#125; // Only set the coinbase if we are mining (avoid spurious block rewards) if atomic.LoadInt32(&amp;self.mining) == 1 &#123; header.Coinbase = self.coinbase &#125; pstate, _ := self.chain.StateAt(parent.Root()) if err := self.engine.PrepareBlockHeader(self.chain, header,pstate); err != nil &#123; log.Error("Failed to prepare header for mining", "err", err) return &#125; err := self.makeCurrent(parent, header) if err != nil &#123; log.Error("Failed to create mining context", "err", err) return &#125; // Create the current work task and check any fork transitions needed work := self.current //if self.config.DAOForkSupport &amp;&amp; self.config.DAOForkBlock != nil &amp;&amp; self.config.DAOForkBlock.Cmp(header.Number) == 0 &#123; // misc.ApplyDAOHardFork(work.state) //&#125; pending, err := txpool.GetTxPool().Pending() if err != nil &#123; log.Error("Failed to fetch pending transactions", "err", err) return &#125; //log.Error("----read tx from pending is ", "number is", len(pending)) txs := types.NewTransactionsByPriceAndNonce(self.current.signer, pending) work.commitTransactions(self.mux, txs, self.coinbase) // compute uncles for the new block. var ( uncles []*types.Header badUncles []common.Hash ) for hash, uncle := range self.possibleUncles &#123; if len(uncles) == 2 &#123; break &#125; if err := self.commitUncle(work, uncle.Header()); err != nil &#123; log.Trace("Bad uncle found and will be removed", "hash", hash) log.Trace(fmt.Sprint(uncle)) badUncles = append(badUncles, hash) &#125; else &#123; log.Debug("Committing new uncle to block", "hash", hash) uncles = append(uncles, uncle.Header()) &#125; &#125; for _, hash := range badUncles &#123; delete(self.possibleUncles, hash) &#125; // Create the new block to seal with the consensus engine if work.Block, err = self.engine.Finalize(self.chain, header, work.state, work.txs, uncles, work.receipts); err != nil &#123; log.Error("Failed to finalize block for sealing", "err", err) return &#125; // We only care about logging if we're actually mining. if atomic.LoadInt32(&amp;self.mining) == 1 &#123; log.Info("Commit new mining work", "number", work.Block.Number(), "txs", work.tcount, "uncles", len(uncles), "elapsed", common.PrettyDuration(time.Since(tstart))) self.unconfirmed.Shift(work.Block.NumberU64() - 1) &#125; self.push(work)&#125; 1234567891011121314151617181920212223242526272829303132makeCurrent(...)方法即初始化了一个work对象，之后会设置work的tcount、uncles等其他属性// makeCurrent creates a new environment for the current cycle.func (self *worker) makeCurrent(parent *types.Block, header *types.Header) error &#123; state, err := self.chain.StateAt(parent.Root()) if err != nil &#123; return err &#125; work := &amp;Work&#123; config: self.config, signer: types.NewBoeSigner(self.config.ChainId), state: state, ancestors: set.New(), family: set.New(), uncles: set.New(), header: header, createdAt: time.Now(), &#125; // when 08 is processed ancestors contain 07 (quick block) for _, ancestor := range self.chain.GetBlocksFromHash(parent.Hash(), 7) &#123; for _, uncle := range ancestor.Uncles() &#123; work.family.Add(uncle.Hash()) &#125; work.family.Add(ancestor.Hash()) work.ancestors.Add(ancestor.Hash()) &#125; // Keep track of transactions which return errors so they can be removed work.tcount = 0 self.current = work return nil&#125;]]></content>
      <categories>
        <category>HPB源码解读</category>
      </categories>
      <tags>
        <tag>HPB</tag>
        <tag>区块链</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GO-HPB源码解读--挖矿流程（二）]]></title>
    <url>%2F2019%2F07%2F21%2FGO-HPB%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB-%E6%8C%96%E7%9F%BF%E6%B5%81%E7%A8%8B%EF%BC%88%E4%BA%8C%EF%BC%89%2F</url>
    <content type="text"><![CDATA[这章来看下HPB的挖矿流程。在节点启动的时候通过flag参数mine指定是否进行挖矿，当然也可以在节点启动后通过API来调用，启动流程代码调用顺序是go-hpb/cmd/ghpb/main.go-main-&gt;ghpb-&gt;startNode`。在startNode方法最后部署代码可以看到，首先判断MiningEnabledFlag和RoleType两个参数后，设置交易的GasPrice后（系统默认为defaultGasPrice = 50 * config.Shannon），开启挖矿。 123456if ctx.GlobalBool(utils.MiningEnabledFlag.Name) &amp;&amp; (conf.Network.RoleType == "") &#123; stack.TxPool().SetGasPrice(utils.GlobalBig(ctx, utils.GasPriceFlag.Name)) if err := stack.StartMining(true); err != nil &#123; utils.Fatalf("Failed to start mining: %v", err) &#125; &#125; 在StartMining方法中 设置挖矿地址coinbase，这个地址是在HpbConfig初始化的时候设置的，取的是钱包中第一个帐户地址 获挖矿引擎Prometheus，并把coinbase和所在钱包的签名方法传递给引擎。这个操作主要是为了从wallet中取出coinbase的私钥，然后进行挖矿签名 开启接收交易的flag miner协程启动12345if wallets := hpbnode.AccountManager().Wallets(); len(wallets) &gt; 0 &#123; if account := wallets[0].Accounts(); len(account) &gt; 0 &#123; hpbnode.hpberbase = account[0].Address &#125; &#125; 123456789101112131415161718192021222324func (s *Node) StartMining(local bool) error &#123; //read coinbase from node eb := s.hpberbase if promeengine, ok := s.Hpbengine.(*prometheus.Prometheus); ok &#123; wallet, err := s.accman.Find(accounts.Account&#123;Address: eb&#125;) if wallet == nil || err != nil &#123; log.Error("Hpberbase account unavailable locally", "err", err) return fmt.Errorf("signer missing: %v", err) &#125; promeengine.Authorize(eb, wallet.SignHash) &#125; else &#123; log.Error("Cannot start mining without prometheus", "err", s.Hpbengine) &#125; if local &#123; // If local (CPU) mining is started, we can disable the transaction rejection // mechanism introduced to speed sync times. CPU mining on mainnet is ludicrous // so noone will ever hit this path, whereas marking sync done on CPU mining // will ensure that private networks work in single miner mode too. atomic.StoreUint32(&amp;s.Hpbsyncctr.AcceptTxs, 1) &#125; go s.miner.Start(eb) return nil&#125; 在Start方法中， 执行miner.update()方法 设置状态为shouldStart==1，表示不允许再次挖矿了，因为已经开始了。 设置挖矿地址coinbase 判断能否进行挖矿，如果不能则返回，不启动挖矿 worker.start()开使用挖矿，worker.startNewMinerRound()尝试再次启动挖工worker123456789101112131415161718func (self *Miner) Start(coinbase common.Address) &#123; // go self.update() atomic.StoreInt32(&amp;self.shouldStart, 1) self.worker.setHpberbase(coinbase) self.coinbase = coinbase if atomic.LoadInt32(&amp;self.canStart) == 0 &#123; log.Info("Network syncing, will start miner afterwards") return &#125; atomic.StoreInt32(&amp;self.mining, 1) log.Info("Starting mining operation") self.worker.start() self.worker.startNewMinerRound()&#125; 在miner.update()方法中，miner.mux订阅了三个事件，分别是下载开始事件，下载结束事件，下载失败事件，这个和以太坊的源码有些不同，以太坊是downloader.StartEvent{}, downloader.DoneEvent{}, downloader.FailedEvent{}，作用的是一样，在HPB源码中可以看下三个事件的发出都是和信息同步有关的,比如在synfast.go、synfull.go、synlight.go中的syncWithPeer方法中进行事件发布 如果收到下载开始事件，则停止当前的挖矿工作 如查收到下载完成或失败事件，则开启挖矿工作，同时取消事件订阅可以看到update中也有可能启动挖矿行为的，所以使用atomic来进行状态管理，实现线程安全。 12345678910111213141516171819202122232425262728293031// update keeps track of the synctrl events. Please be aware that this is a one shot type of update loop.// It's entered once and as soon as `Done` or `Failed` has been broadcasted the events are unregistered and// the loop is exited. This to prevent a major security vuln where external parties can DOS you with blocks// and halt your mining operation for as long as the DOS continues.func (self *Miner) update() &#123; events := self.mux.Subscribe(synctrl.StartEvent&#123;&#125;, synctrl.DoneEvent&#123;&#125;, synctrl.FailedEvent&#123;&#125;)out: for ev := range events.Chan() &#123; switch ev.Data.(type) &#123; case synctrl.StartEvent: atomic.StoreInt32(&amp;self.canStart, 0) if self.Mining() &#123; self.Stop() atomic.StoreInt32(&amp;self.shouldStart, 1) log.Info("Mining aborted due to sync") &#125; case synctrl.DoneEvent, synctrl.FailedEvent: shouldStart := atomic.LoadInt32(&amp;self.shouldStart) == 1 atomic.StoreInt32(&amp;self.canStart, 1) atomic.StoreInt32(&amp;self.shouldStart, 0) if shouldStart &#123; self.Start(self.coinbase) &#125; // unsubscribe. we're only interested in this event once events.Unsubscribe() // stop immediately and ignore all further pending events break out &#125; &#125;&#125; 在worker.start()方法中，首先设置了worker的状态，然后再启动producer.Start()。这里producer是接口类，其实现类只有一个，是CpuAgent。producer绑定CpuAgent是通过这行代码进行注册的miner.Register(NewCpuAgent(bc.InstanceBlockChain(), engine))。代码调用顺序是–&gt;ghpb–&gt;startNode–&gt;utils.StartNode(stack)–&gt;stack.Start(stack.Hpbconfig)–&gt;hpbnode.WorkerInit(conf)–&gt;hpbnode.miner = worker.New(&amp;conf.BlockChain, hpbnode.NewBlockMux(), hpbnode.Hpbengine, hpbnode.hpberbase)–&gt;miner.Register(NewCpuAgent(bc.InstanceBlockChain(), engine)) 1234567891011func (self *worker) start() &#123; self.mu.Lock() defer self.mu.Unlock() atomic.StoreInt32(&amp;self.mining, 1) // spin up agents for producer := range self.producers &#123; producer.Start() &#125;&#125; 接下来直接看下CpuAgent.Start()方法 首先进行CAS状态判断 协程启动update方法，这个类似于miner的update方法 123456func (self *CpuAgent) Start() &#123; if !atomic.CompareAndSwapInt32(&amp;self.isMining, 0, 1) &#123; return // producer already started &#125; go self.update()&#125; update方法中，在死循环中不断从chan中获取数据，如果数据类型是stop，则退出循环，如果是workCh则开始挖矿。stop事件是在miner.update方法中会传递。work的传递是在miner.Start()方法中startNewMinerRound()&lt;-makeCurrent()传递进去的。 123456789101112131415161718192021222324func (self *CpuAgent) update() &#123;out: for &#123; select &#123; case work := &lt;-self.workCh: self.mu.Lock() if self.quitCurrentOp != nil &#123; close(self.quitCurrentOp) &#125; self.quitCurrentOp = make(chan struct&#123;&#125;) go self.mine(work, self.quitCurrentOp) self.mu.Unlock() case &lt;-self.stop: self.mu.Lock() if self.quitCurrentOp != nil &#123; close(self.quitCurrentOp) self.quitCurrentOp = nil &#125; self.mu.Unlock() break out &#125; &#125;&#125; go self.mine(work, self.quitCurrentOp)才开始真正的挖矿计算，，下一章节再详细分析。]]></content>
      <categories>
        <category>HPB源码解读</category>
      </categories>
      <tags>
        <tag>HPB</tag>
        <tag>区块链</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GO-HPB源码解读--挖矿流程（一）]]></title>
    <url>%2F2019%2F07%2F21%2FGO-HPB%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB-%E6%8C%96%E7%9F%BF%E6%B5%81%E7%A8%8B%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[在开析流程前先看下主要的数据结构，挖矿工作主要由三个对象来完成的，miner、worker、cpuAgent，其中cpuAgent实现Producer接口类 miner是入口，负责与外部交互，控制挖矿流程的启停操作 worker管理Work任务，他代理着Producer接口类，也就是代理着具体挖矿执行着 cpuAgent负责具体挖矿计算工作 1234567891011// Miner creates blocks and searches for proof-of-work values.type Miner struct &#123; mux *sub.TypeMux worker *worker coinbase common.Address mining int32 engine consensus.Engine canStart int32 // can start indicates whether we can start the mining operation shouldStart int32 // should start indicates whether we should start after sync&#125; 字段 类型 含义 备注 mux *sub.TypeMux 接收来自同步模块的StartEvent DoneEvent FailedEvent事件通知。在网络中，不可能只有一个矿工节点,当节点开始从其他节点同步Block时，我们就没有必要再继续挖矿了 worker *worker 具体执行挖矿的工人 coinbase common.Address 挖矿地址，挖矿所得的收入将计入该账户 mining int32 挖矿状态 engine consensus.Engine 共识引擎 canStart int32 是否可以开始挖矿 shouldStart int32 quitCurrentOp 1234567891011121314151617181920212223242526272829303132// worker is the main object which takes care of applying messages to the new statetype worker struct &#123; config *config.ChainConfig engine consensus.Engine mu sync.Mutex // update loop mux *sub.TypeMux pool *txpool.TxPool txCh chan bc.TxPreEvent txSub sub.Subscription //txSub sub.Subscription chainHeadCh chan bc.ChainHeadEvent chainHeadSub sub.Subscription chainSideCh chan bc.ChainSideEvent chainSideSub sub.Subscription wg sync.WaitGroup producers map[Producer]struct&#123;&#125; recv chan *Result chain *bc.BlockChain proc bc.Validator chainDb hpbdb.Database coinbase common.Address extra []byte currentMu sync.Mutex current *Work uncleMu sync.Mutex possibleUncles map[common.Hash]*types.Block unconfirmed *unconfirmedBlocks // set of locally mined blocks pending canonicalness confirmations // atomic status counters mining int32 atWork int32&#125; 字段 类型 含义 备注 config *config.ChainConfig engine consensus.Engine mu sync.Mutex mux *sub.TypeMux 注意与miner.mux属性不同，这里是向外部发布已经挖到新Block pool *txpool.TxPool txCh chan bc.TxPreEvent 接收txPool中tx的通道 txSub sub.Subscription chainHeadCh chan bc.ChainHeadEvent 接收区块头的通道 chainHeadSub sub.Subscription chainSideCh chan bc.ChainSideEvent 接收主备链变更通道 chainSideSub sub.Subscription wg sync.WaitGroup producers map[Producer]struct{} worker拥有一个Producer的map集合 recv chan *Result Producer结果发送通道，每个管理的Producer都可能将挖出的Block发到该Channel,也就是说,这个收方向Channel是一对多的 chain *bc.BlockChain proc bc.Validator chainDb hpbdb.Database 存储数据库 coinbase common.Address 挖矿地址 extra []byte currentMu sync.Mutex current *Work uncleMu sync.Mutex possibleUncles map[common.Hash]*types.Block unconfirmed *unconfirmedBlocks 本地挖出的待确认的块 mining int32 atWork int32 1234567// Agent can register themself with the workertype Producer interface &#123; Work() chan&lt;- *Work SetReturnCh(chan&lt;- *Result) Stop() Start()&#125; Producer是个接口类，主要定义了一些操作方法，在HPB中，该接口类只有CpuAgent这一个实现类 12345678910111213type CpuAgent struct &#123; mu sync.Mutex workCh chan *Work stop chan struct&#123;&#125; quitCurrentOp chan struct&#123;&#125; returnCh chan&lt;- *Result chain consensus.ChainReader engine consensus.Engine isMining int32 // 正在挖矿&#125; 字段 类型 含义 备注 mu sync.Mutex workCh chan *Work 接收来自worker下发的工作任务Work stop chan struct{} 使该CpuAgent停止工作的信号 quitCurrentOp chan struct{} 退出当前操作通道 returnCh chan&lt;- *Result 向worker反馈工作任务的完成情况,实际上就是挖出的新Block chain consensus.ChainReader 用于访问本地节点BlockChain数据的接口 engine consensus.Engine 计算所采用的共识引擎 isMining int32 是否正在挖矿]]></content>
      <categories>
        <category>HPB源码解读</category>
      </categories>
      <tags>
        <tag>HPB</tag>
        <tag>区块链</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GO-HPB源码解读--LevelDB操作]]></title>
    <url>%2F2019%2F07%2F21%2FGO-HPB%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB-LevelDB%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[HPB使用LevelDB存储数据。go-hpb/blockchain/database_util.go文件封装了LevelDB的操作。因为LevelDB是&lt;k, v&gt;数据库，所以所有数据的存储都需要指定k。以下代码列出了所有需要保存的数据的k或者k的前缀。 ··· voteResultKey = []byte(“vote-result-key”) headHeaderKey = []byte(&quot;LastHeader&quot;) headBlockKey = []byte(&quot;LastBlock&quot;) headFastKey = []byte(&quot;LastFast&quot;) // Data item prefixes (use single byte to avoid mixing data types, avoid `i`). headerPrefix = []byte(&quot;h&quot;) // headerPrefix + num (uint64 big endian) + hash -&gt; header tdSuffix = []byte(&quot;t&quot;) // headerPrefix + num (uint64 big endian) + hash + tdSuffix -&gt; td numSuffix = []byte(&quot;n&quot;) // headerPrefix + num (uint64 big endian) + numSuffix -&gt; hash blockHashPrefix = []byte(&quot;H&quot;) // blockHashPrefix + hash -&gt; num (uint64 big endian) bodyPrefix = []byte(&quot;b&quot;) // bodyPrefix + num (uint64 big endian) + hash -&gt; block body blockReceiptsPrefix = []byte(&quot;r&quot;) // blockReceiptsPrefix + num (uint64 big endian) + hash -&gt; block receipts lookupPrefix = []byte(&quot;l&quot;) // lookupPrefix + hash -&gt; transaction/receipt lookup metadata bloomBitsPrefix = []byte(&quot;B&quot;) // bloomBitsPrefix + bit (uint16 big endian) + section (uint64 big endian) + hash -&gt; bloom bits randomPrefix = []byte(&quot;random&quot;) // randomPrefix + num (uint64 big endian) + hash -&gt; header preimagePrefix = &quot;secure-key-&quot; // preimagePrefix + hash -&gt; preimage configPrefix = []byte(&quot;hpb-config-&quot;) // config prefix for the db BloomBitsIndexPrefix = []byte(&quot;iB&quot;) // BloomBitsIndexPrefix is the data table of a chain indexer to track its progress oldReceiptsPrefix = []byte(&quot;receipts-&quot;) oldTxMetaSuffix = []byte{0x01} 这里对主要数据的k前缀整理下,其中hash指的是区块的hash，等于header中的hash，代码中称canonical hash。num是指区块的高度或者位置，表示第几个区块 key|Value -|- h+num+hash|header h+num+hash+t|tdh+num+n |hashH+hash | numb+num+hash |block bodyr+num+hash |block receiptsl+hash | transaction/receipt lookup metadataB+bit+section+hash |bloom bits database_util.go文件大部分内容是write和get方法，以前对前缀的拼接 以下内容转自网络，作个备注 StateObject: 是一个账号(地址)的状态信息 对于普通账号，这个对象保存了balance, nonce等信息 对于智能合约账号，还额外保留了智能合约的状态，这个状态就是智能合约里的定义的各种变量的值。以太坊虚拟机的变量是以&lt;k, v&gt;存储的，所以这个状态就是大量&lt;k, v&gt;对象。]]></content>
      <categories>
        <category>HPB源码解读</category>
      </categories>
      <tags>
        <tag>HPB</tag>
        <tag>区块链</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GO-HPB源码解读--多帐号解锁]]></title>
    <url>%2F2019%2F07%2F21%2FGO-HPB%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB-%E5%A4%9A%E5%B8%90%E5%8F%B7%E8%A7%A3%E9%94%81%2F</url>
    <content type="text"><![CDATA[在启动节点时，解锁参数可以同时指定多个帐号，格式为--unlock &quot;addr1,addr2,addr3...&quot; --password &quot;pwd&quot;,其中unlock参数为多个帐号的地址，用逗号分隔；password参数为口令文件，文件中的口令每行一个口令。在创建帐号时，命令./ghpb --datadir node/data account init可以多次执行，每次执行后，会在路径node/data/keystore下生成多个帐号文件，比如UTC–2018-11-29T08-21-25.565157387Z–3e8aadb68222c70b309e87cd5c27e97950879076。当节点启动指定多个帐号时，会加载对应的帐号文件，并解锁。下边看一下解锁的代码。 启动节点入口main.go的init方法，调用过程为init()–&gt;ghpb–&gt;startNode() 1234567func init() &#123; // Initialize the CLI app and start Geth app.Action = ghpb app.HideVersion = true // we have a command to print the version app.Copyright = "Copyright 2013-2018 The go-hpb Authors " app.Commands = []cli.Command&#123; ...省略... 1234567891011121314// ghpb is the main entry point into the system if no special subcommand is ran.// It creates a default node based on the command line arguments and runs it in// blocking mode, waiting for it to be shut down.func ghpb(ctx *cli.Context) error &#123; cfg := MakeConfigNode(ctx) hpbnode, err := createNode(cfg) if err != nil &#123; utils.Fatalf("Failed to create node") return err &#125; startNode(ctx, hpbnode, cfg) hpbnode.Wait() return nil&#125; 在startNode方法中 首先获取keyStore的指针 MakePasswordList方法解析–password参数指定的口令文件，文件中的内容每一行对应一个口令 获取帐号列表，进行遍历解锁 后边是启动节点，并启动一个协程，开启钱包事件监听。这部分内容后续章节中再进行解读。下边看下遍历时，每个帐号是怎么使用口令解锁的。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667// startNode boots up the system node and all registered protocols, after which// it unlocks any requested accounts, and starts the RPC/IPC interfaces and the// miner.func startNode(ctx *cli.Context, stack *node.Node, conf *config.HpbConfig) &#123; // Unlock any account specifically requested ks := stack.AccountManager().KeyStore().(*keystore.KeyStore) passwords := utils.MakePasswordList(ctx) unlocks := strings.Split(ctx.GlobalString(utils.UnlockedAccountFlag.Name), ",") for i, account := range unlocks &#123; if trimmed := strings.TrimSpace(account); trimmed != "" &#123; unlockAccount(ctx, ks, trimmed, i, passwords) &#125; &#125; if unlocks[0] != "" &#123; account, err := utils.MakeAddress(ks, strings.TrimSpace(unlocks[0])) if err != nil &#123; utils.Fatalf("Could not list accounts: %v", err) &#125; conf.Node.DefaultAddress = account.Address &#125; //set rpc aii //utils.SetNodeAPI(&amp;conf.Node, stack) // Start up the node itself utils.StartNode(stack) // Register wallet event handlers to open and auto-derive wallets events := make(chan accounts.WalletEvent, 16) stack.AccountManager().Subscribe(events) go func() &#123; // Open any wallets already attached for _, wallet := range stack.AccountManager().Wallets() &#123; if err := wallet.Open(""); err != nil &#123; log.Warn("Failed to open wallet", "url", wallet.URL(), "err", err) &#125; &#125; // Listen for wallet event till termination for event := range events &#123; switch event.Kind &#123; case accounts.WalletArrived: if err := event.Wallet.Open(""); err != nil &#123; log.Warn("New wallet appeared, failed to open", "url", event.Wallet.URL(), "err", err) &#125; case accounts.WalletOpened: status, _ := event.Wallet.Status() log.Info("New wallet appeared", "url", event.Wallet.URL(), "status", status) case accounts.WalletDropped: log.Info("Old wallet dropped", "url", event.Wallet.URL()) event.Wallet.Close() &#125; &#125; &#125;() // Start auxiliary services if enabled if ctx.GlobalBool(utils.MiningEnabledFlag.Name) &amp;&amp; (conf.Network.RoleType == "") &#123; // Set the gas price to the limits from the CLI and start mining stack.TxPool().SetGasPrice(utils.GlobalBig(ctx, utils.GasPriceFlag.Name)) if err := stack.StartMining(true); err != nil &#123; utils.Fatalf("Failed to start mining: %v", err) &#125; &#125;&#125; 在unlockAccount方法中，每个帐号会进行尝试3次解锁。每次会从口令列表中取出一个口令进行解锁帐号，如果解锁成功则返回，失败则继续。方法getPassPhrase每次从众多口令中取一个口令的方式是以下部分代码实现的 ，如果口令个数大于3个的话，则每次都会取最后一个。不是很理解为何要这样做，按理说应该每个帐号对应一个口令的。😂😂😂 123456if len(passwords) &gt; 0 &#123; if i &lt; len(passwords) &#123; return passwords[i] &#125; return passwords[len(passwords)-1] &#125;]]></content>
      <categories>
        <category>HPB源码解读</category>
      </categories>
      <tags>
        <tag>HPB</tag>
        <tag>区块链</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GO-HPB源码解读--数据结构]]></title>
    <url>%2F2019%2F07%2F21%2FGO-HPB%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[区块链本身就是通过特定的机制来生成和维护数据，使数据具有极高的稳定性和可靠性。所以了解区块链，首先要必须熟悉其数据结构，然后才能更好的理解数据运算机制也就是区块链的运行原理。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849// BlockChain represents the canonical chain given a database with a genesis// block. The Blockchain manages chain imports, reverts, chain reorganisations.//// Importing blocks in to the block chain happens according to the set of rules// defined by the two stage Validator. Processing of blocks is done using the// Processor which processes the included transaction. The validation of the state// is done in the second part of the Validator. Failing results in aborting of// the import.//// The BlockChain also helps in returning blocks from **any** chain included// in the database as well as blocks that represents the canonical chain. It's// important to note that GetBlock can return any block and does not need to be// included in the canonical one where as GetBlockByNumber always represents the// canonical chain.&lt;!-- more --&gt;type BlockChain struct &#123; config *config.ChainConfig // chain &amp; network configuration hc *HeaderChain chainDb hpbdb.Database rmLogsFeed sub.Feed chainFeed sub.Feed chainSideFeed sub.Feed chainHeadFeed sub.Feed logsFeed sub.Feed scope sub.SubscriptionScope genesisBlock *types.Block mu sync.RWMutex // global mutex for locking chain operations chainmu sync.RWMutex // blockchain insertion lock procmu sync.RWMutex // block processor lock checkpoint int // checkpoint counts towards the new checkpoint currentBlock *types.Block // Current head of the block chain currentFastBlock *types.Block // Current head of the fast-sync chain (may be above the block chain!) stateCache state.Database // State database to reuse between imports (contains state cache) bodyCache *lru.Cache // Cache for the most recent block bodies bodyRLPCache *lru.Cache // Cache for the most recent block bodies in RLP encoded format blockCache *lru.Cache // Cache for the most recent entire blocks futureBlocks *lru.Cache // future blocks are blocks added for later processing quit chan struct&#123;&#125; // blockchain quit channel running int32 // running must be called atomically // procInterrupt must be atomically called procInterrupt int32 // interrupt signaler for block processing wg sync.WaitGroup // chain processing wait group for shutting down engine consensus.Engine processor Processor // block processor interface validator Validator // block and state validator interface badBlocks *lru.Cache // Bad block cache&#125; 字段 类型 含义 备注 config *config.ChainConfig 定义了chainID和监控参数 hc *HeaderChain 区块头组成的链 chainDb hpbdb.Database 数据库 rmLogsFeed sub.Feed chainFeed sub.Feed chainSideFeed sub.Feed chainHeadFeed sub.Feed logsFeed sub.Feed scope sub.SubscriptionScope genesisBlock *types.Block mu sync.RWMutex 区块链的全局锁 chainmu sync.RWMutex 区块链插入锁 procmu sync.RWMutex 区块处理的锁 checkpoint int currentBlock *types.Block 主链的头区块 currentFastBlock *types.Block 快速同步模式下链的头区块，这种情况下可能比主链长 stateCache state.Database bodyCache *lru.Cache 最近区块体的缓存信息 bodyRLPCache *lru.Cache 最近区块体的RLP格式的缓存信息 blockCache *lru.Cache 最近区块的缓存 futureBlocks *lru.Cache 将来等待上链的区块 quit chan struct{} running int32 procInterrupt int32 wg sync.WaitGroup engine consensus.Engine 验证区块的引擎 processor Processor 执行区块交易的接口 validator Validator 验证区块和state有效性的接口 badBlocks *lru.Cache 验证失败的区块缓存，来自DAO事件 关键的元素： db：连接到底层数据储存，即leveldb； hc：headerchain区块头链，由blockchain额外维护的另一条链，由于Header和Block的储存空间是有很大差别的，但同时Block的Hash值就是Header（RLP）的Hash值，所以维护一个headerchain可以用于快速延长链，验证通过后再下载blockchain，或者可以与blockchain进行相互验证； genesisBlock：创始区块； currentBlock：当前区块，blockchain中并不是储存链所有的block，而是通过currentBlock向前回溯直到genesisBlock，这样就构成了区块链。 bodyCache、bodyRLPCache、blockCache、futureBlocks：区块链中的缓存结构，用于加快区块链的读取和构建； engine：是consensus模块中的接口，用来验证block的接口； processor：执行区块链交易的接口，收到一个新的区块时，要对区块中的所有交易执行一遍，一方面是验证，一方面是更新worldState； validator：验证数据有效性的接口 futureBlocks：收到的区块时间大于当前头区块时间15s而小于30s的区块，可作为当前节点待处理的区块。 下边是区块的数据结构 12345678910111213141516171819// Block represents an entire block in the Hpb blockchain.type Block struct &#123; header *Header uncles []*Header transactions Transactions // caches hash atomic.Value size atomic.Value // Td is used by package core to store the total difficulty // of the chain up to and including the block. td *big.Int // These fields are used by package eth to track // inter-peer block relay. ReceivedAt time.Time ReceivedFrom interface&#123;&#125;&#125; 字段 类型 含义 备注 header *Header 当前区块头 uncles []*Header 叔区块，因出块速度快，导致分叉概率高，为了增加矿工挖矿积极性，对于分叉后的无用区块也进行打包，奖励矿工，那么这些无用区块就是叔区块。同时为了为了抵消整个Ethereum网络中那些计算能力特别强大的节点会对区块的产生有过大的影响力，防止这些节点破坏“去中心化”这个根本宗旨 transactions Transactions 交易集合 hash atomic.Value 区块的哈希，是从Header中缓存下来的，等于Header中的哈希值，是header中除nonce和mixDigest数据外的rlp的hash，这样相同的交易内容的相同该区块hash是一样，哪怕是由不同的节点创建出来的。区块的header和body是分开存储的，key都是前缀加上当前hash size atomic.Value td *big.Int td是totalDifficulty的缩写，表示从创世区块到当前区块的所有Difficulty之和，而每个区块的Difficulty是保存在header中的 ReceivedAt time.Time 区块生成时间 ReceivedFrom interface{} 区块生成来源 12345678910111213141516171819202122// Header represents a block header in the Hpb blockchain.type Header struct &#123; ParentHash common.Hash `json:"parentHash" ` UncleHash common.Hash `json:"sha3Uncles" ` Coinbase common.Address `json:"miner" ` CandAddress common.Address `json:"candAddress" ` ComdAddress common.Address `json:"comdAddress" ` VoteIndex *big.Int `json:"voteIndex" ` Root common.Hash `json:"stateRoot" ` TxHash common.Hash `json:"transactionsRoot" ` ReceiptHash common.Hash `json:"receiptsRoot" ` Bloom Bloom `json:"logsBloom" ` Difficulty *big.Int `json:"difficulty" ` Number *big.Int `json:"number" ` GasLimit *big.Int `json:"gasLimit" ` GasUsed *big.Int `json:"gasUsed" ` Time *big.Int `json:"timestamp" ` Extra []byte `json:"extraData" ` MixDigest common.Hash `json:"mixHash" ` Nonce BlockNonce `json:"nonce" ` HardwareRandom []byte `json:"hardwareRandom" `&#125; 字段 类型 含义 备注 ParentHash common.Hash 父区块的hash UncleHash common.Hash 叔区块的hash Coinbase common.Address 挖矿生成该区块的地址，挖矿是由节点来完成的，每个full节点都个默认的Coinbase地址，用来接收挖矿（矿工费和打包区块的奖金）奖励 CandAddress common.Address ？ ComdAddress common.Address ？ VoteIndex *big.Int 投票索引 Root common.Hash 存储账户（合约帐户和用户帐户）状态的Merkle树的根节点的哈希,StateDB中的“state Trie”的根节点的RLP哈希值。Block中，每个账户以stateObject对象表示，账户以Address为唯一标示，其信息在相关交易(Transaction)的执行中被修改。所有账户对象可以逐个插入一个Merkle-PatricaTrie(MPT)结构里，形成“state Trie”。 TxHash common.Hash Block中交易树 “tx Trie”的根节点的RLP哈希值。Block的成员变量transactions中所有的tx对象，被逐个插入一个MPT结构，形成“tx Trie”。 ReceiptHash common.Hash “Receipt Trie”的根节点的RLP哈希值。Block的所有Transaction执行完后会生成一个Receipt数组，这个数组中的所有Receipt被逐个插入一个MPT结构中，最后形成”Receipt Trie” Bloom Bloom Bloom过滤器(Filter)，用来快速判断一个参数Log对象是否存在于一组已知的Log集合中。 Difficulty *big.Int 区块的难度。Block的Difficulty由共识算法基于parentBlock的Time和Difficulty计算得出，它会应用在区块的‘挖掘’阶段。 Number *big.Int 区块的序号。Block的Number等于其父区块Number +1。 GasLimit *big.Int 区块内所有Gas消耗的上限。该数值在区块创建时赋值，与父区块的数据相关。具体来说，根据父区块的GasUsed同创世块的GasLimit * 2/3的大小关系来计算得出。 GasUsed *big.Int 区块内所有Transaction执行时所实际消耗的Gas总和。 Time *big.Int 区块“应该”被创建的时间。由共识算法确定，一般来说，要么等于parentBlock.Time + 10s，要么等于当前系统时间。区块开始打包时间戳（调用Engine.Prepare函数的时候设置） Extra []byte 扩展信息 MixDigest common.Hash 区块头除去Nonce, mixDigest数据的hash+nonce的RLP的hash值 Nonce BlockNonce 一个64bit的哈希数，它被用于POW等挖块算法，暴力碰撞得出,该哈希值与MixDigest哈希值一起证明该区块上已经进行了足够的计算，用于证明挖矿成功 HardwareRandom []byte BOE硬件随机数 1234type Body struct &#123; Transactions []*Transaction Uncles []*Header&#125; 字段 类型 含义 备注 Transactions []*Transaction 交易集合 Uncles []*Header 叔区块头集合 12345678type Transaction struct &#123; data txdata // caches hash atomic.Value size atomic.Value from atomic.Value fromP2P bool&#125; 字段 类型 含义 备注 data txdata 交易数据 hash atomic.Value size atomic.Value from atomic.Value tx的转帐转出方地址，就是对该tx对象作ECDSA签名计算时所用的公钥publicKey fromP2P bool 1234567891011121314type txdata struct &#123; AccountNonce uint64 `json:"nonce" gencodec:"required"` Price *big.Int `json:"gasPrice" gencodec:"required"` GasLimit *big.Int `json:"gas" gencodec:"required"` Recipient *common.Address `json:"to" rlp:"nil"` // nil means contract creation Amount *big.Int `json:"value" gencodec:"required"` Payload []byte `json:"input" gencodec:"required"` // Signature values V *big.Int `json:"v" gencodec:"required"` R *big.Int `json:"r" gencodec:"required"` S *big.Int `json:"s" gencodec:"required"` // This is only used when marshaling to JSON. Hash *common.Hash `json:"hash" rlp:"-"`&#125; 字段 类型 含义 备注 AccountNonce uint64 发送者发起的交易总数 Price *big.Int 交易的Gas价格 GasLimit *big.Int 交易允许消耗的最大Gas Recipient *common.Address 交易接收者地址， Amount *big.Int 交易额 Payload []byte 它既可以作为所创建合约的指令数组，其中每一个byte作为一个单独的虚拟机指令；也可以作为数据数组，由合约指令进行操作。合约由以太坊虚拟机(Ethereum Virtual Machine, EVM)创建并执行。 V *big.Int tx的数字签名（ECDSA）,是一个长度为65bytes的字节数组，它被截成三段放进tx中，前32bytes赋值给成员变量R, 再32bytes赋值给S，末1byte赋给V R *big.Int 同上 S *big.Int 同上 Hash *common.Hash 交易HAsh，只在JSON转换时使用 以上便是区块链中最主要的“区块链”数据结构，有些字段描述不是很清楚，后续再逐步完善。]]></content>
      <categories>
        <category>HPB源码解读</category>
      </categories>
      <tags>
        <tag>HPB</tag>
        <tag>区块链</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GO-HPB源码解读--节点初始化]]></title>
    <url>%2F2019%2F07%2F21%2FGO-HPB%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB-%E8%8A%82%E7%82%B9%E5%88%9D%E5%A7%8B%E5%8C%96%2F</url>
    <content type="text"><![CDATA[HPB在创建帐号时使用的命令是 ./ghpb --datadir node/data init gensis.json通过代码看下节点初始化做了什么事情 init命令定义在chaincmd.go文件中，关于urfave和utils.MigrateFlags在创建帐号中做过说明，这里直接看下initGenesis做了什么事情。 initGenesis方法流程： MakeConfigNode方法配置节点的默认参数信息，这个时候如果很多参数没有通过命令很输入进来，程序会把所有的参数信息设置为默认值 加载文件gensis.json文件，文件名通过init的flag参数输入进行。后边我们对gensis.json文件解读一下。 创建bc.Genesis对象，然后通过gensis.json文件的信息进行赋值 db.OpenDatabase创建数据库 bc.SetupGenesisBlockf进行初始块的生成和写入文件 github.com\hpb-project\go-hpb\cmd\chaincmd.go 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051 initCommand = cli.Command&#123; Action: utils.MigrateFlags(initGenesis), Name: "init", Usage: "Bootstrap and initialize a new genesis block", ArgsUsage: "&lt;genesisPath&gt;", Flags: []cli.Flag&#123; utils.DataDirFlag, utils.LightModeFlag, &#125;, Category: "BLOCKCHAIN COMMANDS", Description: ``, &#125; // initGenesis will initialise the given JSON format genesis file and writes it as// the zero'd block (i.e. genesis) or will fail hard if it can't succeed.func initGenesis(ctx *cli.Context) error &#123; // Open an initialise both full and light databases //stack, _ := MakeConfigNode(ctx) MakeConfigNode(ctx) // Make sure we have a valid genesis JSON genesisPath := ctx.Args().First() if len(genesisPath) == 0 &#123; utils.Fatalf("Must supply path to genesis JSON file") &#125; file, err := os.Open(genesisPath) if err != nil &#123; log.Warn("genesis path is %s", genesisPath) utils.Fatalf("Failed to read genesis file: %v", err) &#125; defer file.Close() genesis := new(bc.Genesis) if err := json.NewDecoder(file).Decode(genesis); err != nil &#123; utils.Fatalf("invalid genesis file: %v", err) &#125; for _, name := range []string&#123;"chaindata"&#125; &#123; chaindb, err := db.OpenDatabase(name, 0, 0) if err != nil &#123; utils.Fatalf("Failed to open database: %v", err) &#125; _, hash, err := bc.SetupGenesisBlock(chaindb, genesis) if err != nil &#123; utils.Fatalf("Failed to write genesis block: %v", err) &#125; log.Info("Successfully wrote genesis state", "database", name, "hash", hash) &#125; return nil&#125; 看下创建数据库的代码，数据库实例通过atomic.Value{}来实现线程安全操作。当没有传入–datadir参数时，会直接返回内存数据库,否则会创建chaindata数据库文件。ResolvePath方法会在chaindata路径前加个ghpb路径。数据库使用的是Google的levelDB, 123456789101112131415161718192021// OpenDatabase opens an existing database with the given name (or creates one// if no previous can be found) from within the node's data directory. If the// node is an ephemeral one, a memory database is returned.func OpenDatabase(name string, cache int, handles int) (hpbdb.Database, error) &#123; if DBINSTANCE.Load() != nil &#123; return DBINSTANCE.Load().(*hpbdb.LDBDatabase),nil &#125; var cfg = config.GetHpbConfigInstance() if cfg.Node.DataDir == ""&#123; return hpbdb.NewMemDatabase() &#125; db, err := hpbdb.NewLDBDatabase(cfg.Node.ResolvePath(name), cache, handles) if err != nil &#123; return nil, err &#125; DBINSTANCE.Store(db) return db, nil&#125; SetupGenesisBlock方法主要是对初始区块的文件写入。 GetCanonicalHash(db, 0)首先从数据库获取第0个hash，如果没有则返回一个初始hash，即[32]byte{0} 把初始的genesis信息生成初始区块提交到数据库 … … …后续再读 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758func SetupGenesisBlock(db hpbdb.Database, genesis *Genesis) (*config.ChainConfig, common.Hash, error) &#123; if genesis != nil &amp;&amp; genesis.Config == nil &#123; return config.MainnetChainConfig, common.Hash&#123;&#125;, errGenesisNoConfig &#125; // Just commit the new block if there is no stored genesis block. stored := GetCanonicalHash(db, 0) if (stored == common.Hash&#123;&#125;) &#123; if genesis == nil &#123; genesis = DefaultGenesisBlock() &#125; else &#123; log.Info("Writing custom genesis block") &#125; block, err := genesis.Commit(db) return genesis.Config, block.Hash(), err &#125; // Check whether the genesis block is already written. if genesis != nil &#123; block, _ := genesis.ToBlock() hash := block.Hash() if hash != stored &#123; return genesis.Config, block.Hash(), &amp;GenesisMismatchError&#123;stored, hash&#125; &#125; &#125; // Get the existing chain configuration. newcfg := genesis.configOrDefault(stored) storedcfg, err := GetChainConfig(db, stored) if err != nil &#123; if err == ErrChainConfigNotFound &#123; // This case happens if a genesis write was interrupted. log.Warn("Found genesis block without chain config") err = WriteChainConfig(db, stored, newcfg) &#125; return newcfg, stored, err &#125; // Special case: don't change the existing config of a non-mainnet chain if no new // config is supplied. These chains would get AllProtocolChanges (and a compat error) // if we just continued here. if genesis == nil &amp;&amp; stored != config.MainnetGenesisHash &#123; return storedcfg, stored, nil &#125; // Check config compatibility and write the config. Compatibility errors // are returned to the caller unless we're already at block zero. height := GetBlockNumber(db, GetHeadHeaderHash(db)) if height == missingNumber &#123; return newcfg, stored, fmt.Errorf("missing block number for head header hash") &#125; compatErr := storedcfg.CheckCompatible(newcfg, height) if compatErr != nil &amp;&amp; height != 0 &amp;&amp; compatErr.RewindTo != 0 &#123; return newcfg, stored, compatErr &#125; return newcfg, stored, WriteChainConfig(db, stored, newcfg)&#125; genesis.Commit(db)方法中，首先将genesis转化成一个区块，然后再将区块信息写入数据库，同时包含其他一些数据内容，比如blockReceipts、GetCanonicalHash,WriteHeadBlockHash等等。此时已接触到初始block，后续文章我们对相关数据结构进行详细说明 1234567891011121314151617181920212223242526272829303132333435// Commit writes the block and state of a genesis specification to the database.// The block is committed as the canonical head block.func (g *Genesis) Commit(db hpbdb.Database) (*types.Block, error) &#123; block, statedb := g.ToBlock() if block.Number().Sign() != 0 &#123; return nil, fmt.Errorf("can't commit genesis block with number &gt; 0") &#125; if _, err := statedb.CommitTo(db, false); err != nil &#123; return nil, fmt.Errorf("cannot write state: %v", err) &#125; if err := WriteTd(db, block.Hash(), block.NumberU64(), g.Difficulty); err != nil &#123; return nil, err &#125; if err := WriteBlock(db, block); err != nil &#123; return nil, err &#125; if err := WriteBlockReceipts(db, block.Hash(), block.NumberU64(), nil); err != nil &#123; return nil, err &#125; if err := WriteCanonicalHash(db, block.Hash(), block.NumberU64()); err != nil &#123; return nil, err &#125; if err := WriteHeadBlockHash(db, block.Hash()); err != nil &#123; return nil, err &#125; if err := WriteHeadHeaderHash(db, block.Hash()); err != nil &#123; return nil, err &#125; configtemp := g.Config if configtemp == nil &#123; configtemp = config.MainnetChainConfig &#125; return block, WriteChainConfig(db, block.Hash(), configtemp)&#125;]]></content>
      <categories>
        <category>HPB源码解读</category>
      </categories>
      <tags>
        <tag>HPB</tag>
        <tag>区块链</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GO-HPB源码解读--创建帐号]]></title>
    <url>%2F2019%2F07%2F21%2FGO-HPB%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB-%E5%88%9B%E5%BB%BA%E5%B8%90%E5%8F%B7%2F</url>
    <content type="text"><![CDATA[HPB在创建帐号时使用的命令是 ./ghpb --datadir node/data account init通过代码看下创建流程 go-hpb源码命令架构使用的是urfave/cli，不知道是不是这样读这个名称：you are 废物，这里有个不错的帖子介绍，可以学习下。主要对命令进行了封装，我们主要关心命令所对应的业务实现逻辑即可，使用起来非常方便。阅读也从这个地方开始。 account命令定义在accountcmd.go文件中，通过源码可以看到account命令有list、new、update、import四个子命令。每一个命令都有flags参数。 github.com\hpb-project\go-hpb\cmd\accountcmd.go 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556accountCommand = cli.Command&#123; Name: "account", Usage: "Manage accounts", Category: "ACCOUNT COMMANDS", Description: ``, Subcommands: []cli.Command&#123; &#123; Name: "list", Usage: "Print summary of existing accounts", Action: utils.MigrateFlags(accountList), Flags: []cli.Flag&#123; utils.DataDirFlag, utils.KeyStoreDirFlag, &#125;, Description: `Print a short summary of all accounts`, &#125;, &#123; Name: "new", Usage: "Create a new account", Action: utils.MigrateFlags(accountCreate), Flags: []cli.Flag&#123; utils.DataDirFlag, utils.KeyStoreDirFlag, utils.PasswordFileFlag, utils.LightKDFFlag, &#125;, Description: ``, &#125;, &#123; Name: "update", Usage: "Update an existing account", Action: utils.MigrateFlags(accountUpdate), ArgsUsage: "&lt;address&gt;", Flags: []cli.Flag&#123; utils.DataDirFlag, utils.KeyStoreDirFlag, utils.LightKDFFlag, &#125;, Description: ``, &#125;, &#123; Name: "import", Usage: "Import a private key into a new account", Action: utils.MigrateFlags(accountImport), Flags: []cli.Flag&#123; utils.DataDirFlag, utils.KeyStoreDirFlag, utils.PasswordFileFlag, utils.LightKDFFlag, &#125;, ArgsUsage: "&lt;keyFile&gt;", Description: `, &#125;, &#125;, &#125;) 现在主要看一下new这个子命令，Action属性主要用来指定new命令的所需要执行的动作。这里可以看到是utils.MigrateFlags(accountCreate)， MigrateFlags方法是把account命令的flag参数设置到全局参数里。比如命令hpb account new –keystore /tmp/mykeystore –lightkdf是等价于hpb –keystore /tmp/mykeystore –lightkdf account new。主要的业务实现需要查看accountCreate 123456789101112&#123; Name: "new", Usage: "Create a new account", Action: utils.MigrateFlags(accountCreate), Flags: []cli.Flag&#123; utils.DataDirFlag, utils.KeyStoreDirFlag, utils.PasswordFileFlag, utils.LightKDFFlag, &#125;, Description: ``,&#125;, accountCreate方法首先初始化节点配置对象，并实例化一下节点对象,getPassPhrase接收一个用户输入的口令。接下来通过口令参数生成用户帐户信息. 12345678910111213141516171819202122// accountCreate creates a new account into the keystore defined by the CLI flags.func accountCreate(ctx *cli.Context) error &#123; //进行节点参数配置 cfg := MakeConfigNode(ctx) //创建节点实例 stack, err := createNode(cfg) if err != nil &#123; utils.Fatalf("Failed to create node") return err &#125; //接收用户输入的口令 password := getPassPhrase("Your new account is locked with a password. Please give a password. Do not forget this password.", true, 0, utils.MakePasswordList(ctx)) //创建一个keyStore ks := stack.AccountManager().KeyStore().(*keystore.KeyStore) //使用口令对keyStore信息进行加密，并返回一个帐户地址 account, err := ks.NewAccount(password) if err != nil &#123; utils.Fatalf("Failed to create account: %v", err) &#125; fmt.Printf("Address: &#123;%x&#125;\n", account.Address) return nil&#125; NewAccount方法用来生成一个密钥，并把他保存在文件中，也就是命令执行后生成的文件，比如node/data/keystore/UTC–2018-11-25T14-05-44.446434210Z–a0603b3443c89a6e2eff7614acec5a59f9f70ebb。生成之后返回的account需要加载到当前cache里，并刷新wallet信息 1234567891011121314// NewAccount generates a new key and stores it into the key directory,// encrypting it with the passphrase.func (ks *KeyStore) NewAccount(passphrase string) (accounts.Account, error) &#123; _, account, err := storeNewKey(ks.storage, crand.Reader, passphrase) if err != nil &#123; return accounts.Account&#123;&#125;, err &#125; // Add the account to the cache immediately rather // than waiting for file system notifications to pick it up. ks.cache.add(account) ks.refreshWallets() return account, nil&#125; 关键方法storeNewKey，第一步newKey会随机生成非对称密钥，使用的是大名顶顶的ECDSA算法。然后创建 一个account对象，并进行保存。保存完成需要把当前内存信息进行清除，以防安全隐患。 123456789101112func storeNewKey(ks keyStore, rand io.Reader, auth string) (*Key, accounts.Account, error) &#123; key, err := newKey(rand) if err != nil &#123; return nil, accounts.Account&#123;&#125;, err &#125; a := accounts.Account&#123;Address: key.Address, URL: accounts.URL&#123;Scheme: KeyStoreScheme, Path: ks.JoinPath(keyFileName(key.Address))&#125;&#125; if err := ks.StoreKey(a.URL.Path, key, auth); err != nil &#123; zeroKey(key.PrivateKey) return nil, a, err &#125; return key, a, err&#125; newKey方法生成非对称密钥，并转成一个用户帐户信息，主要是需要通过公钥生成一个用户帐户地址，在newKeyFromECDSA方法里，可以看到的是ECDSA.PublicKey生成Address 1234567891011121314151617func newKey(rand io.Reader) (*Key, error) &#123; privateKeyECDSA, err := ecdsa.GenerateKey(crypto.S256(), rand) if err != nil &#123; return nil, err &#125; return newKeyFromECDSA(privateKeyECDSA), nil&#125;func newKeyFromECDSA(privateKeyECDSA *ecdsa.PrivateKey) *Key &#123; id := uuid.NewRandom() key := &amp;Key&#123; Id: id, Address: crypto.PubkeyToAddress(privateKeyECDSA.PublicKey), PrivateKey: privateKeyECDSA, &#125; return key&#125; StoreKey主要完成非对称密钥通过用户输入口令进行加密保存到文件 1234567func (ks keyStorePassphrase) StoreKey(filename string, key *Key, auth string) error &#123; keyjson, err := EncryptKey(key, auth, ks.scryptN, ks.scryptP) if err != nil &#123; return err &#125; return writeKeyFile(filename, keyjson)&#125; 文件保存后，业务就基本完成，程序退出执行。]]></content>
      <categories>
        <category>HPB源码解读</category>
      </categories>
      <tags>
        <tag>HPB</tag>
        <tag>区块链</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2019%2F07%2F20%2Fhello-world%2F</url>
    <content type="text"><![CDATA[摘要显示 Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
</search>
